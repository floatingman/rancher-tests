#!/usr/bin/env groovy

/**
 * Ansible Airgap Setup Jenkinsfile
 * Based on Jenkinsfile.recurring but adapted for airgap RKE2 infrastructure setup
 *
 * This pipeline sets up airgap RKE2 infrastructure using Ansible and OpenTofu
 * with enhanced error handling and proper workspace management.
 */

pipeline {
    agent any

    // Global pipeline options
    options {
        buildDiscarder(logRotator(numToKeepStr: '10'))
        timeout(time: 3, unit: 'HOURS')
        timestamps()
        ansiColor('xterm')
        skipStagesAfterUnstable()
        retry(1)
    }

    // Environment-specific parameters
    parameters {
        string(
            name: 'RKE2_VERSION',
            defaultValue: 'v1.28.8+rke2r1',
            description: 'RKE2 version to deploy (e.g., v1.28.8+rke2r1, v1.29.5+rke2r1, v1.30.2+rke2r1)'
        )
        string(
            name: 'RANCHER_VERSION',
            defaultValue: 'v2.10-head',
            description: 'Rancher version to deploy (e.g., head, v2.10-head, v2.11.0, v2.9-head)'
        )
        string(
            name: 'RANCHER_TEST_REPO_URL',
            defaultValue: 'https://github.com/rancher/tests',
            description: 'URL of rancher/tests repository'
        )
        string(
            name: 'RANCHER_TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of rancher/tests repository'
        )
        string(
            name: 'QA_INFRA_REPO_URL',
            defaultValue: 'https://github.com/rancher/qa-infra-automation',
            description: 'URL of qa-infra-automation repository'
        )
        string(
            name: 'QA_INFRA_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of qa-infra-automation repository'
        )
        string(
            name: 'PRIVATE_REGISTRY_URL',
            defaultValue: '',
            description: 'Private registry URL for airgap deployment'
        )
        string(
            name: 'PRIVATE_REGISTRY_USERNAME',
            defaultValue: 'default-user',
            description: 'Private registry username for airgap deployment'
        )
        password(
            name: 'PRIVATE_REGISTRY_PASSWORD',
            defaultValue: '',
            description: 'Private registry password for airgap deployment'
        )
        text(
            name: 'S3_BACKEND_CONFIG',
            defaultValue: '',
            description: 'S3 backend configuration content (required for Terraform state storage)'
        )
        string(
            name: 'HOSTNAME_PREFIX',
            defaultValue: 'ansible-airgap',
            description: 'Hostname prefix for *.qa.rancher.space and other AWS resources'
        )
        booleanParam(
            name: 'DESTROY_ON_FAILURE',
            defaultValue: true,
            description: 'Destroy infrastructure when Ansible playbooks fail (automatic cleanup)'
        )
    }

    // Global environment variables
    environment {
        // Repository configurations
        RANCHER_TEST_REPO_URL = "${params.RANCHER_TEST_REPO_URL ?: 'https://github.com/rancher/tests'}"
        QA_INFRA_REPO = "${params.QA_INFRA_REPO_URL ?: 'https://github.com/rancher/qa-infra-automation'}"

        // Private registry configurations
        PRIVATE_REGISTRY_URL = "${params.PRIVATE_REGISTRY_URL ?: ''}"
        PRIVATE_REGISTRY_USERNAME = "${params.PRIVATE_REGISTRY_USERNAME ?: 'default-user'}"
        PRIVATE_REGISTRY_PASSWORD = "${params.PRIVATE_REGISTRY_PASSWORD ?: ''}"

        // Path configurations
        ROOT_PATH = '/root/go/src/github.com/rancher/tests/'
        QA_INFRA_WORK_PATH = '/root/go/src/github.com/rancher/qa-infra-automation'

        // Cleanup configurations
        DESTROY_ON_FAILURE = "${params.DESTROY_ON_FAILURE}"

        // Computed values
        JOB_SHORT_NAME = "${getShortJobName()}"
        BUILD_CONTAINER_NAME = "${JOB_SHORT_NAME}${BUILD_NUMBER}-airgap-ansible"
        IMAGE_NAME = "rancher-ansible-airgap-setup-${JOB_SHORT_NAME}${BUILD_NUMBER}"
        VALIDATION_VOLUME = "AnsibleAirgapSharedVolume-${JOB_SHORT_NAME}${BUILD_NUMBER}"

        // Configuration files
        ANSIBLE_VARS_FILENAME = 'vars.yaml'
        TERRAFORM_VARS_FILENAME = 'cluster.tfvars'
        TERRAFORM_BACKEND_VARS_FILENAME = 'backend.tfvars'
        ENV_FILE = '.env'

        // Terraform workspace
        TF_WORKSPACE = "jenkins_airgap_ansible_workspace_${BUILD_NUMBER}"

        // Timeouts (in minutes)
        TERRAFORM_TIMEOUT = '30'
        ANSIBLE_TIMEOUT = '45'
        VALIDATION_TIMEOUT = '15'

        // Backend configuration
        S3_BACKEND_CONFIG = "${params.S3_BACKEND_CONFIG ?: ''}"

        // Hostname prefix
        HOSTNAME_PREFIX = "${params.HOSTNAME_PREFIX ?: 'ansible-airgap'}"
    }

    stages {
        stage('Initialize Pipeline') {
            steps {
                script {
                    logWarning('⚠️ IMPORTANT: No concurrent state locking available')
                    logWarning('⚠️ Ensure only ONE instance of this pipeline runs at a time')
                    logWarning('⚠️ Manual coordination required to prevent state conflicts')

                    // Validate parameters and environment
                    validateParameters()

                    // Set up dynamic variables
                    setupDynamicEnvironment()

                    // Clean workspace
                    deleteDir()

                    logInfo('Pipeline initialized successfully')
                    logInfo("Build container: ${env.BUILD_CONTAINER_NAME}")
                    logInfo("Docker image: ${env.IMAGE_NAME}")
                    logInfo("Volume: ${env.VALIDATION_VOLUME}")
                }
            }
        }

        stage('Checkout Repositories') {
            steps {
                script {
                    logInfo('Checking out source repositories')

                    // Checkout Rancher Tests Repository
                    dir('./tests') {
                        logInfo("Cloning rancher tests repository from ${env.RANCHER_TEST_REPO_URL}")
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.RANCHER_TEST_REPO_BRANCH}"]],
                            extensions: [
                                [$class: 'CleanCheckout'],
                                [$class: 'CloneOption', depth: 1, shallow: true]
                            ],
                            userRemoteConfigs: [[
                                url: env.RANCHER_TEST_REPO_URL,
                            ]]
                        ])
                    }

                    // Checkout QA Infrastructure Repository
                    dir('./qa-infra-automation') {
                        logInfo("Cloning qa-infra-automation repository from ${env.QA_INFRA_REPO}")
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.QA_INFRA_REPO_BRANCH}"]],
                            extensions: [
                                [$class: 'CleanCheckout'],
                                [$class: 'CloneOption', depth: 1, shallow: true]
                            ],
                            userRemoteConfigs: [[
                                url: env.QA_INFRA_REPO,
                            ]]
                        ])
                    }

                    logInfo('Repository checkout completed successfully')
                }
            }
        }

        stage('Configure Environment') {
            steps {
                script {
                    logInfo('Configuring deployment environment')

                    // Configure credentials and environment files
                    withCredentials(getCredentialsList()) {
                        // Generate configuration files
                        generateConfigurationFiles()

                        // Setup SSH keys securely
                        setupSSHKeys()

                        // Build Docker image with proper tagging
                        buildDockerImage()

                        // Create shared volume
                        createSharedVolume()
                    }
                }
            }
        }

        stage('Deploy Infrastructure') {
            steps {
                script {
                    logInfo('Initializing airgap infrastructure deployment with OpenTofu')

                    // Configuration validation
                    def requiredVars = [
                        'QA_INFRA_WORK_PATH',
                        'TF_WORKSPACE',
                        'TERRAFORM_VARS_FILENAME',
                        'TERRAFORM_BACKEND_VARS_FILENAME',
                        'TERRAFORM_TIMEOUT'
                    ]

                    validateRequiredVariables(requiredVars)

                    // Enhanced timeout with reasonable defaults
                    def timeoutMinutes = env.TERRAFORM_TIMEOUT ?
                        Integer.parseInt(env.TERRAFORM_TIMEOUT) : 30

                    timeout(time: timeoutMinutes, unit: 'MINUTES') {
                        try {
                            // Pre-flight checks
                            validateInfrastructurePrerequisites()

                            // Infrastructure deployment with enhanced error handling
                            deployInfrastructure()

                            // Post-deployment validation
                            validateInfrastructureState()

                            logInfo('Infrastructure provisioned and validated successfully')
                        } catch (org.jenkinsci.plugins.workflow.steps.FlowInterruptedException e) {
                            logError("Infrastructure deployment timed out after ${timeoutMinutes} minutes")
                            logError("Timeout exception details: ${e.message}")
                            try {
                                archiveInfrastructureFailureArtifacts()
                                if (env.DESTROY_ON_FAILURE.toBoolean()) {
                                    logInfo('DESTROY_ON_FAILURE is true - attempting infrastructure cleanup for timeout')
                                    def cleanupScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE="${env.TF_WORKSPACE}"

echo 'Performing infrastructure cleanup due to timeout...'
tofu -chdir=tofu/aws/modules/airgap init -backend-config="${env.TERRAFORM_BACKEND_VARS_FILENAME}" -input=false -upgrade || echo 'Init failed during cleanup - manual intervention required'

tofu -chdir=tofu/aws/modules/airgap destroy -auto-approve -var-file="${env.TERRAFORM_VARS_FILENAME}" || echo 'Destroy command failed - manual cleanup may be required'
echo 'Cleanup attempt completed'
                                    """
                                    executeScriptInContainer(cleanupScript)
                                    logInfo('Infrastructure cleanup attempted for timeout')
                                } else {
                                    logWarning('DESTROY_ON_FAILURE is false - manual cleanup required for timeout')
                                    logWarning('Please run the destroy pipeline or manually clean up resources in workspace: ${env.TF_WORKSPACE}')
                                }
                                cleanupContainersAndVolumes()
                            } catch (cleanupException) {
                                logError("Cleanup during timeout handling failed: ${cleanupException.message}")
                            }
                            throw e
                        } catch (Exception e) {
                            logError("Infrastructure setup failed: ${e.message}")
                            logError("Deployment failure exception details: ${e.message}")
                            try {
                                archiveInfrastructureFailureArtifacts()
                                if (env.DESTROY_ON_FAILURE.toBoolean()) {
                                    logInfo('DESTROY_ON_FAILURE is true - attempting infrastructure cleanup for deployment failure')
                                    def cleanupScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE="${env.TF_WORKSPACE}"

echo 'Performing infrastructure cleanup due to deployment failure...'

tofu -chdir=tofu/aws/modules/airgap init -backend-config="${env.TERRAFORM_BACKEND_VARS_FILENAME}" -input=false -upgrade || echo 'Init failed during cleanup - manual intervention required'

tofu -chdir=tofu/aws/modules/airgap destroy -auto-approve -var-file="${env.TERRAFORM_VARS_FILENAME}" || echo 'Destroy command failed - manual cleanup may be required'
echo 'Cleanup attempt completed'
                                    """
                                    executeScriptInContainer(cleanupScript)
                                    logInfo('Infrastructure cleanup attempted for deployment failure')
                                } else {
                                    logWarning('DESTROY_ON_FAILURE is false - manual cleanup required for deployment failure')
                                    logWarning('Please run the destroy pipeline or manually clean up resources in workspace: ${env.TF_WORKSPACE}')
                                }
                                cleanupContainersAndVolumes()
                            } catch (cleanupException) {
                                logError("Cleanup during deployment failure handling failed: ${cleanupException.message}")
                            }
                            throw e
                        }
                    }
                }
            }
            post {
                success {
                    script {
                        logInfo('Infrastructure deployment succeeded - archiving state')
                        archiveInfrastructureState()
                        // Additional immediate state backup for successful deployments
                        backupTerraformStateImmediately()
                    }
                }
                failure {
                    script {
                        logError('Infrastructure operations failed')
                        archiveInfrastructureFailureArtifacts()
                        // Still try to archive any partial state
                        archiveInfrastructureState()
                    }
                }
                always {
                    script {
                        // Final comprehensive state archival attempt
                        finalStateArchival()
                    }
                }
            }
        }
    }

    post {
        always {
            script {
                logInfo('Starting post-build cleanup')

                // Archive important artifacts including comprehensive tfstate backups
                archiveBuildArtifacts([
                    'kubeconfig.yaml',
                    'terraform.tfstate',
                    'terraform-state.tfstate',
                    'terraform-state-backup-*.tfstate',
                    'tfstate-backup-*.tfstate',
                    'terraform-state-build-*.tfstate',
                    'terraform-vars.tfvars',
                    'infrastructure-outputs.json',
                    'ansible-inventory.yml',
                    'ansible-logs.txt',
                    'deployment-summary.json'
                ])

                // Always cleanup containers and volumes
                try {
                    node {
                        cleanupContainersAndVolumes()
                    }
                } catch (Exception e) {
                    logError("Node context not available for cleanup: ${e.message}")
                    try {
                        cleanupContainersAndVolumes()
                    } catch (Exception cleanupException) {
                        logError("Cleanup failed: ${cleanupException.message}")
                    }
                }
            }
        }

        success {
            script {
                logInfo('Pipeline completed successfully')
                sendSlackNotification([
                    color: 'good',
                    message: "✅ Ansible Airgap setup succeeded for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }

        failure {
            script {
                logError('Pipeline failed')
                sendSlackNotification([
                    color: 'danger',
                    message: "❌ Ansible Airgap setup failed for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }

        unstable {
            script {
                logWarning('Pipeline completed with warnings')
                sendSlackNotification([
                    color: 'warning',
                    message: "⚠️ Ansible Airgap setup completed with warnings for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
    }
}

/**
 * HELPER FUNCTIONS
 * These functions are adapted from both Jenkinsfile.recurring and Jenkinsfile.airgap.rke2.improved
 */

// Logging utility functions
def logInfo(msg) {
    echo "[INFO] ${msg}"
}

def logError(msg) {
    echo "[ERROR] ${msg}"
}

def logWarning(msg) {
    echo "[WARNING] ${msg}"
}

// State extraction utility functions for backup
def extractStateFromVolume() {
    logInfo('Extracting terraform state from shared volume')
    sh """
    if [ -f /root/terraform.tfstate ]; then
        cp /root/terraform.tfstate ./terraform.tfstate || echo 'No state file in volume or copy failed'
        echo 'State extraction from volume attempted'
    else
        echo 'No state file found in shared volume'
    fi
    """
}

def extractStateFromContainer() {
    logInfo('Extracting terraform state from container backup')
    sh """
    if [ -f /root/terraform-state-primary.tfstate ]; then
        cp /root/terraform-state-primary.tfstate ./terraform-state.tfstate || echo 'Fallback state copy failed'
        echo 'Fallback state extraction from container attempted'
    else
        echo 'No fallback state found in container'
    fi
    """
}

def getShortJobName() {
    def jobName = "${env.JOB_NAME}"
    if (jobName.contains('/')) {
        def lastSlashIndex = jobName.lastIndexOf('/')
        return jobName.substring(lastSlashIndex + 1)
    }
    return jobName
}

def validateParameters() {
    // Validate required parameters
    if (!params.RKE2_VERSION) {
        error('RKE2_VERSION parameter is required')
    }
    if (!params.RANCHER_VERSION) {
        error('RANCHER_VERSION parameter is required')
    }
    if (!params.RANCHER_TEST_REPO_URL) {
        error('RANCHER_TEST_REPO_URL parameter is required')
    }
    if (!params.QA_INFRA_REPO_URL) {
        error('QA_INFRA_REPO_URL parameter is required')
    }

    logInfo('Parameters validated successfully')
}

def setupDynamicEnvironment() {
    env.RKE2_VERSION = params.RKE2_VERSION
    env.RANCHER_VERSION = params.RANCHER_VERSION

    logInfo('Dynamic environment configured')
    logInfo("RKE2 Version: ${env.RKE2_VERSION}")
    logInfo("Rancher Version: ${env.RANCHER_VERSION}")
}

def getCredentialsList() {
    return [
        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
        string(credentialsId: 'AWS_SSH_PEM_KEY', variable: 'AWS_SSH_PEM_KEY'),
        string(credentialsId: 'AWS_SSH_KEY_NAME', variable: 'AWS_SSH_KEY_NAME'),
        string(credentialsId: 'SLACK_WEBHOOK', variable: 'SLACK_WEBHOOK')
    ]
}

def generateConfigurationFiles() {
    logInfo('Generating configuration files for infrastructure deployment')

    // Load configuration templates if not already set
    if (!env.TERRAFORM_CONFIG) {
        try {
            env.TERRAFORM_CONFIG = readFile('validation/pipeline/configs/airgap-rke2-terraform.tfvars.template')
            logInfo('Loaded TERRAFORM_CONFIG from template file')
        } catch (Exception e) {
            logError("Failed to load TERRAFORM_CONFIG template: ${e.message}")
            error('TERRAFORM_CONFIG is required - either set the environment variable or provide the template file')
        }
    }

    if (!env.S3_BACKEND_CONFIG) {
        try {
            env.S3_BACKEND_CONFIG = readFile('validation/pipeline/configs/backend.tfvars.template')
            logInfo('Loaded S3_BACKEND_CONFIG from template file')
        } catch (Exception e) {
            logError("Failed to load S3_BACKEND_CONFIG template: ${e.message}")
            error('S3_BACKEND_CONFIG is required - either set the environment variable or provide the template file with valid S3 bucket/key')
        }
    }

    if (!env.ANSIBLE_VARIABLES) {
        try {
            env.ANSIBLE_VARIABLES = readFile('validation/pipeline/configs/airgap-rke2-ansible-vars.yaml.template')
            logInfo('Loaded ANSIBLE_VARIABLES from template file')
        } catch (Exception e) {
            logError("Failed to load ANSIBLE_VARIABLES template: ${e.message}")
            error('ANSIBLE_VARIABLES is required - either set the environment variable or provide the template file')
        }
    }

    // No interpolation for S3_BACKEND_CONFIG - assume user provides complete config in parameter
    // Validate required environment variables
    validateConfigurationEnvironmentVariables()

    // Generate Terraform configuration
    generateTerraformConfiguration()

    // Generate Ansible configuration
    generateAnsibleConfiguration()

    // Generate environment file for containers
    generateEnvironmentFile()

    logInfo('Configuration files generated successfully')
}

def validateConfigurationEnvironmentVariables() {
    logInfo('Validating configuration environment variables')

    def requiredVars = [
        'TERRAFORM_CONFIG': 'Terraform configuration content',
        'S3_BACKEND_CONFIG': 'S3 backend configuration content',
        'ANSIBLE_VARIABLES': 'Ansible configuration content',
        'RKE2_VERSION': 'RKE2 version for deployment',
        'RANCHER_VERSION': 'Rancher version for deployment'
    ]

    def missingVars = []
    requiredVars.each { varName, description ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add("${varName} (${description})")
        }
    }

    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables for configuration:\n- ${missingVars.join('\n- ')}"
        logError(errorMsg)
        throw new IllegalArgumentException(errorMsg)
    }

    logInfo('All required environment variables validated successfully')
}

def generateTerraformConfiguration() {
    logInfo('Generating Terraform configuration')

    if (!env.TERRAFORM_CONFIG) {
        throw new RuntimeException('TERRAFORM_CONFIG environment variable is not set')
    }

    if (!env.S3_BACKEND_CONFIG) {
        throw new RuntimeException('S3_BACKEND_CONFIG environment variable is not set')
    }

    sh 'mkdir -p qa-infra-automation/tofu/aws/modules/airgap'

    def terraformConfig = env.TERRAFORM_CONFIG

    // Replace variables in config (similar to Jenkinsfile.recurring pattern)
    terraformConfig = terraformConfig.replace('${AWS_SECRET_ACCESS_KEY}', env.AWS_SECRET_ACCESS_KEY ?: '')
    terraformConfig = terraformConfig.replace('${AWS_ACCESS_KEY_ID}', env.AWS_ACCESS_KEY_ID ?: '')
    terraformConfig = terraformConfig.replace('${AWS_REGION}', env.AWS_REGION ?: '')
    terraformConfig = terraformConfig.replace('${AWS_IAM_PROFILE}', env.AWS_IAM_PROFILE ?: '')
    terraformConfig = terraformConfig.replace('${AWS_VPC}', env.AWS_VPC ?: '')
    terraformConfig = terraformConfig.replace('${AWS_SECURITY_GROUPS}', env.AWS_SECURITY_GROUPS ?: '')
    terraformConfig = terraformConfig.replace('${HOSTNAME_PREFIX}', env.HOSTNAME_PREFIX ?: '')

    // Write the configuration file
    dir('./qa-infra-automation') {
        dir('./tofu/aws/modules/airgap') {
            writeFile file: env.TERRAFORM_VARS_FILENAME, text: terraformConfig
            logInfo("Terraform configuration written to: ${env.TERRAFORM_VARS_FILENAME}")

            writeFile file: env.TERRAFORM_BACKEND_VARS_FILENAME, text: env.S3_BACKEND_CONFIG
            logInfo("S3 backend configuration written to: ${env.TERRAFORM_BACKEND_VARS_FILENAME}")
        }
    }
}

def generateAnsibleConfiguration() {
    logInfo('Generating Ansible configuration')

    if (!env.ANSIBLE_VARIABLES) {
        throw new RuntimeException('ANSIBLE_VARIABLES environment variable is not set')
    }

    def ansibleVars = env.ANSIBLE_VARIABLES

    // Replace variables in config
    ansibleVars = ansibleVars.replace('${ADMIN_PASSWORD}', env.ADMIN_PASSWORD ?: '')
    ansibleVars = ansibleVars.replace('${HOSTNAME_PREFIX}', env.HOSTNAME_PREFIX ?: '')
    ansibleVars = ansibleVars.replace('${PRIVATE_REGISTRY_USERNAME}', env.PRIVATE_REGISTRY_USERNAME ?: '')
    ansibleVars = ansibleVars.replace('${PRIVATE_REGISTRY_PASSWORD}', env.PRIVATE_REGISTRY_PASSWORD ?: '')

    // Write the Ansible configuration file to the correct location for airgap deployment
    dir('./qa-infra-automation') {
        // Ensure the directory structure exists
        sh 'mkdir -p ansible/rke2/airgap/inventory/group_vars'

        // Write the group_vars/all.yml file
        writeFile file: 'ansible/rke2/airgap/inventory/group_vars/all.yml', text: ansibleVars
        logInfo('Ansible configuration written to: ansible/rke2/airgap/inventory/group_vars/all.yml')

        // Also create a copy in the original location for backward compatibility
        sh 'mkdir -p ansible'
        writeFile file: "ansible/${env.ANSIBLE_VARS_FILENAME}", text: ansibleVars
        logInfo("Ansible configuration also written to: ansible/${env.ANSIBLE_VARS_FILENAME} (backward compatibility)")
    }
}

def generateEnvironmentFile() {
    logInfo('Generating environment file for container execution')

    // Build environment content securely without direct interpolation of secrets
    def envLines = [
        '# Environment variables for infrastructure deployment containers',
        "TF_WORKSPACE=${env.TF_WORKSPACE}",
        "BUILD_NUMBER=${env.BUILD_NUMBER}",
        "JOB_NAME=${env.JOB_NAME}",
        "TERRAFORM_TIMEOUT=${env.TERRAFORM_TIMEOUT}",
        "ANSIBLE_TIMEOUT=${env.ANSIBLE_TIMEOUT}",
        "QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH}",
        "TERRAFORM_VARS_FILENAME=${env.TERRAFORM_VARS_FILENAME}",
        "ANSIBLE_VARS_FILENAME=${env.ANSIBLE_VARS_FILENAME}",
        "RKE2_VERSION=${env.RKE2_VERSION}",
        "RANCHER_VERSION=${env.RANCHER_VERSION}",
        "PRIVATE_REGISTRY_URL=${env.PRIVATE_REGISTRY_URL}",
        "PRIVATE_REGISTRY_USERNAME=${env.PRIVATE_REGISTRY_USERNAME}",
        '',
        '# AWS Credentials for OpenTofu (Standard AWS environment variables)'
    ]

    // Add credentials securely
    envLines.add('AWS_ACCESS_KEY_ID=' + env.AWS_ACCESS_KEY_ID)
    envLines.add('AWS_SECRET_ACCESS_KEY=' + env.AWS_SECRET_ACCESS_KEY)
    envLines.add('AWS_REGION=' + env.AWS_REGION)
    envLines.add('')
    envLines.add('# Terraform Variables for OpenTofu (TF_VAR_ prefix for automatic variable population)')
    envLines.add('TF_VAR_aws_access_key=' + env.AWS_ACCESS_KEY_ID)
    envLines.add('TF_VAR_aws_secret_access_key=' + env.AWS_SECRET_ACCESS_KEY)
    envLines.add('TF_VAR_aws_region=' + env.AWS_REGION)
    def envContent = envLines.join('\n')
    writeFile file: env.ENV_FILE, text: envContent
    logInfo("Environment file created: ${env.ENV_FILE}")
}

def setupSSHKeys() {
    if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
        logInfo('Setting up SSH keys')

        dir('./tests/.ssh') {
            def decodedKey = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
            writeFile file: env.AWS_SSH_KEY_NAME, text: decodedKey
            sh "chmod 600 ${env.AWS_SSH_KEY_NAME}"
        }

        logInfo('SSH keys configured successfully')
    }
}

def buildDockerImage() {
    logInfo("Building Docker image: ${env.IMAGE_NAME}")

    dir('./') {
        sh './tests/validation/configure.sh'
        sh """
            docker build . \
                -f ./tests/validation/Dockerfile.tofu.e2e \
                -t ${env.IMAGE_NAME} \
                --build-arg BUILD_DATE=\$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
                --build-arg VCS_REF=\$(git rev-parse --short HEAD) \
                --label "pipeline.build.number=${env.BUILD_NUMBER}" \
                --label "pipeline.job.name=${env.JOB_NAME}"
        """
    }

    logInfo('Docker image built successfully')
}

def createSharedVolume() {
    logInfo("Creating shared volume: ${env.VALIDATION_VOLUME}")
    sh "docker volume create --name ${env.VALIDATION_VOLUME}"
}

def executeScriptInContainer(scriptContent, extraEnv = [:], skipWorkspaceEnv = false) {
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-script-${timestamp}"
    def scriptFile = "docker-script-${timestamp}.sh"

    writeFile file: scriptFile, text: scriptContent

    def envVars = ''
    extraEnv.each { key, value ->
        envVars += " -e ${key}=${value}"
    }

    def workspaceEnv = skipWorkspaceEnv ? '' : " -e TF_WORKSPACE=${env.TF_WORKSPACE}"

    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            -v ${pwd()}/qa-infra-automation:/root/go/src/github.com/rancher/qa-infra-automation \
            -v ${pwd()}/${scriptFile}:/tmp/script.sh \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=/root/go/src/github.com/rancher/qa-infra-automation${workspaceEnv} \
            ${envVars} \
            ${env.IMAGE_NAME} \
            sh /tmp/script.sh
    """

    sh "rm -f ${scriptFile}"
}

def cleanupContainersAndVolumes() {
    logInfo('Cleaning up Docker containers and volumes')

    try {
        if (env.NODE_NAME) {
            sh """
                # Stop and remove any containers with our naming pattern
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker stop || true
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker rm -v || true

                # Remove the Docker image
                docker rmi -f ${env.IMAGE_NAME} || true

                # Remove the shared volume
                docker volume rm -f ${env.VALIDATION_VOLUME} || true

                # Clean up any dangling images and volumes
                docker system prune -f || true
            """
        } else {
            logWarning('No node context available for Docker cleanup')
        }
    } catch (Exception e) {
        logError("Docker cleanup failed: ${e.message}")
    }
}

def archiveBuildArtifacts(artifacts) {
    try {
        archiveArtifacts artifacts: artifacts.join(','), allowEmptyArchive: true
        logInfo("Artifacts archived: ${artifacts.join(', ')}")
    } catch (Exception e) {
        logError("Failed to archive artifacts: ${e.message}")
    }
}

def sendSlackNotification(config) {
    if (env.SLACK_WEBHOOK) {
        try {
            def payload = [
                channel: '#rancher-qa',
                username: 'Jenkins',
                color: config.color,
                title: 'Ansible Airgap Setup Pipeline',
                message: config.message,
                fields: [
                    [title: 'Job', value: env.JOB_NAME, short: true],
                    [title: 'Build', value: env.BUILD_NUMBER, short: true],
                    [title: 'RKE2 Version', value: env.RKE2_VERSION, short: true],
                    [title: 'Rancher Version', value: env.RANCHER_VERSION, short: true]
                ]
            ]

            httpRequest(
                httpMode: 'POST',
                url: env.SLACK_WEBHOOK,
                contentType: 'APPLICATION_JSON',
                requestBody: groovy.json.JsonOutput.toJson(payload)
            )

            logInfo('Slack notification sent successfully')
        } catch (Exception e) {
            logError("Failed to send Slack notification: ${e.message}")
        }
    }
}

/**
 * INFRASTRUCTURE MANAGEMENT FUNCTIONS
 * These are adapted from Jenkinsfile.airgap.rke2.improved
 */

def validateRequiredVariables(requiredVars) {
    logInfo('Validating required environment variables')

    def missingVars = []
    requiredVars.each { varName ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add(varName)
        }
    }

    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables: ${missingVars.join(', ')}"
        logError(errorMsg)
        throw new IllegalArgumentException(errorMsg)
    }

    logInfo('All required variables validated successfully')
}

def validateInfrastructurePrerequisites() {
    logInfo('Validating infrastructure prerequisites')

    def prerequisiteScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Checking OpenTofu installation...'
tofu version

echo 'Checking workspace directory...'
test -d ${env.QA_INFRA_WORK_PATH}

echo 'Validating terraform vars file...'
test -f ${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/${env.TERRAFORM_VARS_FILENAME}

echo 'All infrastructure prerequisites validated successfully'
"""

    try {
        executeScriptInContainer(prerequisiteScript)
        logInfo('All infrastructure prerequisites validated')
    } catch (Exception e) {
        def errorMsg = "Infrastructure prerequisites validation failed: ${e.message}"
        logError(errorMsg)
        throw new RuntimeException(errorMsg, e)
    }
}

def deployInfrastructure() {
    logInfo('Starting infrastructure deployment process')

    // Step 1: Initialize OpenTofu
    initializeOpenTofu()

    // Step 2: Manage workspace
    manageWorkspace()

    // Step 3: Plan infrastructure changes
    planInfrastructure()

    // Step 4: Apply infrastructure
    applyInfrastructure()

    logInfo('Infrastructure deployment completed successfully')
}

def validateInfrastructureState() {
    logInfo('Validating infrastructure state after deployment')

    def validationScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE="${env.TF_WORKSPACE}"

echo 'Validating remote terraform state via tofu commands (S3 backend)...'

echo 'Checking key infrastructure resources from remote state...'
tofu -chdir=/root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap state list > /root/state-list.txt 2>&1
STATE_RC=\$?
echo "State list command completed with return code: \$STATE_RC"
if [ \$STATE_RC -ne 0 ]; then
    echo 'ERROR: Failed to retrieve state from remote backend'
    cat /root/state-list.txt
    exit 1
fi

echo 'State retrieval passed'

echo 'Checking if state has resources...'
STATE_COUNT=\$(wc -l < /root/state-list.txt)
if [ "\$STATE_COUNT" -eq 0 ] || [ "\$STATE_COUNT" -eq 1 ]; then  # 1 line for empty or header
    echo 'WARNING: No resources found in state - this may indicate no changes were applied'
    cat /root/state-list.txt
else
    echo "SUCCESS: State contains \$((STATE_COUNT - 1)) resources"
    echo 'Sample state resources:'
    head -5 /root/state-list.txt
fi

echo 'Generating and validating outputs from remote state...'
tofu -chdir=/root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap output -json > /root/infrastructure-outputs.json 2>&1
OUTPUT_RC=\$?
if [ \$OUTPUT_RC -ne 0 ]; then
    echo 'ERROR: Failed to generate terraform outputs from remote state'
    cat /root/infrastructure-outputs.json
    exit 1
fi

OUTPUT_SIZE=\$(stat -c%s /root/infrastructure-outputs.json 2>/dev/null || echo 0)
if [ "\$OUTPUT_SIZE" -eq 0 ]; then
    echo 'WARNING: Outputs file is empty'
else
    echo 'SUCCESS: Outputs generated successfully (\$OUTPUT_SIZE bytes)'
fi

echo 'Infrastructure state validation completed successfully'
    """

    executeScriptInContainer(validationScript)
    logInfo('Infrastructure state validated successfully')
}

def initializeOpenTofu() {
    logInfo('Initializing OpenTofu with S3 backend')

    def initScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Unsetting TF_WORKSPACE to allow default workspace selection...'
unset TF_WORKSPACE

echo 'Selecting default workspace before initialization...'
tofu -chdir=tofu/aws/modules/airgap workspace select default || true

echo 'Initializing OpenTofu backend...'
tofu -chdir=tofu/aws/modules/airgap init -input=false -upgrade

echo 'Verifying initialization success...'
tofu -chdir=tofu/aws/modules/airgap providers

echo 'OpenTofu initialization with S3 backend completed successfully'
tofu -chdir=tofu/aws/modules/airgap init -backend-config="${env.TERRAFORM_BACKEND_VARS_FILENAME}" -input=false
    """

    executeScriptInContainer(initScript, [:], true)
}

def manageWorkspace() {
    logInfo("Managing OpenTofu workspace: ${env.TF_WORKSPACE}")

    def workspaceScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Managing workspace state...'
unset TF_WORKSPACE

echo 'Current workspaces:'
tofu -chdir=tofu/aws/modules/airgap workspace list

echo 'Creating or selecting workspace: ${env.TF_WORKSPACE}'
if ! tofu -chdir=tofu/aws/modules/airgap workspace select "${env.TF_WORKSPACE}" 2>/dev/null; then
    echo 'Workspace does not exist, creating new workspace...'
    tofu -chdir=tofu/aws/modules/airgap workspace new "${env.TF_WORKSPACE}"

    if ! tofu -chdir=tofu/aws/modules/airgap workspace select "${env.TF_WORKSPACE}"; then
        echo 'ERROR: Failed to create and select workspace'
        exit 1
    fi
fi

# Verify workspace selection
CURRENT_WORKSPACE=\$(tofu -chdir=tofu/aws/modules/airgap workspace show)
echo "Current workspace: \$CURRENT_WORKSPACE"

# Strip whitespace and handle empty responses
CURRENT_WORKSPACE=\$(echo "\$CURRENT_WORKSPACE" | xargs)

if [ "\$CURRENT_WORKSPACE" = "" ]; then
    echo 'ERROR: Workspace show command returned empty response'
    tofu -chdir=tofu/aws/modules/airgap workspace list
    exit 1
fi

if [ "\$CURRENT_WORKSPACE" != "${env.TF_WORKSPACE}" ]; then
    echo "ERROR: Expected workspace ${env.TF_WORKSPACE}, but got '\$CURRENT_WORKSPACE'"
    echo 'Available workspaces:'
    tofu -chdir=tofu/aws/modules/airgap workspace list
    exit 1
fi

export TF_WORKSPACE="${env.TF_WORKSPACE}"
echo "Workspace management completed: \$TF_WORKSPACE"

tofu -chdir=tofu/aws/modules/airgap init -input=false -upgrade
    """

    executeScriptInContainer(workspaceScript)
}

def planInfrastructure() {
    logInfo('Planning infrastructure changes')

    def planScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE="${env.TF_WORKSPACE}"

echo 'Generating infrastructure plan for validation...'
tofu -chdir=tofu/aws/modules/airgap plan -input=false -var-file="${env.TERRAFORM_VARS_FILENAME}" -out=tfplan

echo 'Checking if plan file was generated in the correct location...'
if [ ! -f tofu/aws/modules/airgap/tfplan ]; then
    echo 'ERROR: Plan file was not generated successfully in module directory'
    echo 'Contents of tofu/aws/modules/airgap/:'
    ls -la tofu/aws/modules/airgap/
    exit 1
fi

echo 'Verifying plan file is not empty...'
PLAN_SIZE=\$(stat -c%s tofu/aws/modules/airgap/tfplan 2>/dev/null || echo 0)
if [ "\$PLAN_SIZE" = "0" ]; then
    echo 'ERROR: Plan file is empty'
    exit 1
fi

echo "Plan file generated successfully (\$PLAN_SIZE bytes) in tofu/aws/modules/airgap/tfplan"

# Copy plan file from module directory to shared volume for persistence
cp tofu/aws/modules/airgap/tfplan /root/tfplan-backup
echo 'Plan file backed up to shared volume'

echo 'Infrastructure plan validation completed'
    """

    executeScriptInContainer(planScript)
}

def applyInfrastructure() {
    logInfo('Applying infrastructure configuration')

    def applyScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE="${env.TF_WORKSPACE}"

echo 'Debug: Listing current directory contents...'
ls -la .

echo 'Debug: Listing mounted qa-infra-automation/tofu/aws/modules/airgap contents...'
ls -la /root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/ || echo 'Mounted directory listing failed'

echo 'Restoring plan file from shared volume...'
if [ -f /root/tfplan-backup ]; then
    # Restore plan file to the correct module directory
    cp /root/tfplan-backup /root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/tfplan
    echo 'Plan file restored from shared volume to module directory'
else
    echo 'WARNING: No backup plan file found in shared volume, generating new plan...'
    tofu -chdir=/root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap plan -input=false -var-file="${env.TERRAFORM_VARS_FILENAME}" -out=tfplan
    if [ \$? -ne 0 ]; then
        echo 'ERROR: Plan generation failed'
        exit 1
    fi
fi

# Check if plan was restored/generated successfully in module directory
if [ ! -f /root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/tfplan ]; then
    echo 'ERROR: Plan file was not generated successfully in module directory'
    ls -la /root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/ || echo 'Cannot list module directory'
    exit 1
fi

# Verify the plan file is not empty
PLAN_SIZE=\$(stat -c%s /root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/tfplan 2>/dev/null || echo 0)
if [ "\$PLAN_SIZE" = "0" ]; then
    echo 'ERROR: Plan file is empty'
    exit 1
fi

echo 'Plan file restored successfully (\$PLAN_SIZE bytes), applying...'
echo 'Starting tofu apply...'
tofu -chdir=/root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap apply -auto-approve -input=false tfplan
APPLY_RC=\$?

echo "Tofu apply completed with return code: \$APPLY_RC"
if [ \$APPLY_RC -ne 0 ]; then
    echo 'ERROR: Tofu apply failed'
    exit 1
fi

# Clean up the plan file after successful application
rm -f /root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/tfplan

echo 'Debug: Listing module directory after apply...'
ls -la /root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/

echo 'Verifying state after apply...'
tofu -chdir=/root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap state list

echo 'Backing up terraform state immediately after apply...'
# Create multiple backups of the state file for reliability
STATE_FILE="/root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/terraform.tfstate"
if [ -f "\$STATE_FILE" ]; then
    cp "\$STATE_FILE" "\$STATE_FILE.backup-\$(date +%Y%m%d-%H%M%S)"
    cp "\$STATE_FILE" /root/terraform-state-primary.tfstate
    cp "\$STATE_FILE" /root/terraform.tfstate
    STATE_SIZE=\$(stat -c%s "\$STATE_FILE" 2>/dev/null || echo 0)
    echo "SUCCESS: terraform.tfstate backed up successfully (\$STATE_SIZE bytes)"
    ls -la "\$STATE_FILE"
else
    echo 'ERROR: Terraform state file not found after apply'
    exit 1
fi

echo 'Backing up terraform variables file for archival...'
cp /root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/"${env.TERRAFORM_VARS_FILENAME}" /root/"${env.TERRAFORM_VARS_FILENAME}"

echo 'Generating outputs for downstream stages...'
tofu -chdir=/root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap output -json > /root/infrastructure-outputs.json

echo 'Verifying inventory file generation...'
if [ -f /root/go/src/github.com/rancher/qa-infra-automation/ansible/rke2/airgap/inventory/inventory.yml ] && [ -s /root/go/src/github.com/rancher/qa-infra-automation/ansible/rke2/airgap/inventory/inventory.yml ]; then
    echo 'SUCCESS: inventory.yml generated by tofu apply exists and has content'
    cp /root/go/src/github.com/rancher/qa-infra-automation/ansible/rke2/airgap/inventory/inventory.yml /root/ansible-inventory.yml
else
    echo 'WARNING: inventory.yml not found or empty after apply'
fi

echo 'Infrastructure apply completed successfully'
    """

    executeScriptInContainer(applyScript)

    // Extract files to shared volume after successful apply (redundant but ensuring)
    logInfo('Extracting files after apply for persistence')
    sh """
    if [ -f qa-infra-automation/tofu/aws/modules/airgap/terraform.tfstate ]; then
        cp qa-infra-automation/tofu/aws/modules/airgap/terraform.tfstate ./
    fi
    """
}

def backupTerraformStateImmediately() {
    logInfo('Creating immediate backup of terraform state after successful deployment')

    try {
        // Extract state immediately for successful deployments
        extractStateFromVolume()
        extractStateFromContainer()

        def timestamp = new Date().format('yyyyMMdd-HHmmss')
        def backupName = "terraform-state-build-${env.BUILD_NUMBER}-${timestamp}.tfstate"

        def backupScript = """
        if [ -f terraform.tfstate ]; then
            cp terraform.tfstate ${backupName}
            echo "SUCCESS: Immediate backup created: ${backupName}"
        elif [ -f terraform-state.tfstate ]; then
            cp terraform-state.tfstate ${backupName}
            echo "SUCCESS: Immediate backup created from fallback: ${backupName}"
        else
            echo "WARNING: No state file found for immediate backup"
        fi
        """.stripIndent()

        executeScriptInContainer(backupScript)

        // Archive the immediate backup
        archiveArtifacts artifacts: backupName, allowEmptyArchive: true
        logInfo('Immediate terraform state backup completed')
    } catch (Exception e) {
        logError("Immediate backup failed: ${e.message}")
    }
}

// Infrastructure state archival functions
def archiveInfrastructureState() {
    logInfo('Archiving infrastructure state')
    try {
        // Extract current state
        extractStateFromVolume()
        extractStateFromContainer()

        def timestamp = new Date().format('yyyyMMdd-HHmmss')
        def stateName = "infrastructure-state-${env.BUILD_NUMBER}-${timestamp}.tfstate"

        sh """
            if [ -f terraform.tfstate ]; then
                cp terraform.tfstate ${stateName}
                echo "State archived: ${stateName}"
            elif [ -f terraform-state.tfstate ]; then
                cp terraform-state.tfstate ${stateName}
                echo "State archived from fallback: ${stateName}"
            else
                echo "No state file available for archival"
            fi
        """

        archiveArtifacts artifacts: stateName, allowEmptyArchive: true
        logInfo('Infrastructure state archived successfully')
    } catch (Exception e) {
        logError("State archival failed: ${e.message}")
    }
}

def archiveInfrastructureFailureArtifacts() {
    logInfo('Archiving failure artifacts')
    try {
        // Archive partial state and logs
        archiveInfrastructureState()
        archiveBuildArtifacts([
            'tfplan-backup',
            '*.log',
            'ansible-logs.txt',
            'error-*.txt'
        ])
        logInfo('Failure artifacts archived')
    } catch (Exception e) {
        logError("Failure artifacts archival failed: ${e.message}")
    }
}

def finalStateArchival() {
    logInfo('Performing final comprehensive state archival')
    try {
        archiveInfrastructureState()
        // Additional final artifacts
        archiveBuildArtifacts([
            'infrastructure-outputs.json',
            '${env.TERRAFORM_VARS_FILENAME}',
            'ansible-inventory.yml',
            'deployment-summary.json'
        ])
        logInfo('Final state archival completed')
    } catch (Exception e) {
        logError("Final archival failed: ${e.message}")
    }
}
