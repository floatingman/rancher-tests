#!/usr/bin/env groovy

/**
 * Ansible Airgap Setup Jenkinsfile
 * Based on Jenkinsfile.recurring but adapted for airgap RKE2 infrastructure setup
 *
 * This pipeline sets up airgap RKE2 infrastructure using Ansible and OpenTofu
 * with enhanced error handling and proper workspace management.
 */

pipeline {
    agent any

    // Global pipeline options
    options {
        buildDiscarder(logRotator(numToKeepStr: '10'))
        timeout(time: 3, unit: 'HOURS')
        timestamps()
        ansiColor('xterm')
        skipStagesAfterUnstable()
        retry(1)
    }

    // Environment-specific parameters
    parameters {
        string(
            name: 'RKE2_VERSION',
            defaultValue: 'v1.28.8+rke2r1',
            description: 'RKE2 version to deploy (e.g., v1.28.8+rke2r1, v1.29.5+rke2r1, v1.30.2+rke2r1)'
        )
        string(
            name: 'RANCHER_VERSION',
            defaultValue: 'v2.10-head',
            description: 'Rancher version to deploy (e.g., head, v2.10-head, v2.11.0, v2.9-head)'
        )
        string(
            name: 'RANCHER_TEST_REPO_URL',
            defaultValue: 'https://github.com/rancher/tests',
            description: 'URL of rancher/tests repository'
        )
        string(
            name: 'RANCHER_TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of rancher/tests repository'
        )
        string(
            name: 'QA_INFRA_REPO_URL',
            defaultValue: 'https://github.com/rancher/qa-infra-automation',
            description: 'URL of qa-infra-automation repository'
        )
        string(
            name: 'QA_INFRA_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of qa-infra-automation repository'
        )
        string(
            name: 'PRIVATE_REGISTRY_URL',
            defaultValue: '',
            description: 'Private registry URL for airgap deployment'
        )
        string(
            name: 'PRIVATE_REGISTRY_USERNAME',
            defaultValue: '',
            description: 'Private registry username for airgap deployment'
        )
        password(
            name: 'PRIVATE_REGISTRY_PASSWORD',
            defaultValue: '',
            description: 'Private registry password for airgap deployment'
        )
        booleanParam(
            name: 'PARALLEL_EXECUTION',
            defaultValue: true,
            description: 'Enable parallel execution where possible'
        )
        booleanParam(
            name: 'DESTROY_ON_FAILURE',
            defaultValue: true,
            description: 'Destroy infrastructure when Ansible playbooks fail (automatic cleanup)'
        )
        choice(
            name: 'LOG_LEVEL',
            choices: ['INFO', 'DEBUG', 'VERBOSE'],
            description: 'Pipeline logging level'
        )
    }

    // Global environment variables
    environment {
        // Repository configurations
        RANCHER_TEST_REPO_URL = "${params.RANCHER_TEST_REPO_URL ?: 'https://github.com/rancher/tests'}"
        QA_INFRA_REPO = "${params.QA_INFRA_REPO_URL ?: 'https://github.com/rancher/qa-infra-automation'}"

        // Private registry configurations
        PRIVATE_REGISTRY_URL = "${params.PRIVATE_REGISTRY_URL ?: ''}"
        PRIVATE_REGISTRY_USERNAME = "${params.PRIVATE_REGISTRY_USERNAME ?: ''}"
        PRIVATE_REGISTRY_PASSWORD = "${params.PRIVATE_REGISTRY_PASSWORD ?: ''}"

        // Path configurations
        ROOT_PATH = '/root/go/src/github.com/rancher/tests/'
        QA_INFRA_WORK_PATH = '/root/go/src/github.com/rancher/qa-infra-automation'

        // Cleanup configurations
        DESTROY_ON_FAILURE = "${params.DESTROY_ON_FAILURE}"

        // Computed values
        JOB_SHORT_NAME = "${getShortJobName()}"
        BUILD_CONTAINER_NAME = "${JOB_SHORT_NAME}${BUILD_NUMBER}-airgap-ansible"
        IMAGE_NAME = "rancher-ansible-airgap-setup-${JOB_SHORT_NAME}${BUILD_NUMBER}"
        VALIDATION_VOLUME = "AnsibleAirgapSharedVolume-${JOB_SHORT_NAME}${BUILD_NUMBER}"

        // Configuration files
        ANSIBLE_VARS_FILENAME = 'vars.yaml'
        TERRAFORM_VARS_FILENAME = 'cluster.tfvars'
        ENV_FILE = '.env'

        // Terraform workspace
        TF_WORKSPACE = "jenkins_airgap_ansible_workspace_${BUILD_NUMBER}"

        // Timeouts (in minutes)
        TERRAFORM_TIMEOUT = '30'
        ANSIBLE_TIMEOUT = '45'
        VALIDATION_TIMEOUT = '15'

        // AWS Infrastructure defaults
        AWS_REGION = 'us-east-2'
        AWS_AMI = 'ami-0c2d3e23fb3adceb8'

        // State storage configuration (S3-only, no DynamoDB)
        TF_STATE_BUCKET = 'jenkins-terraform-state-storage'
        TF_STATE_KEY_PREFIX = 'jenkins-airgap-rke2'
        TF_STATE_REGION = "${AWS_REGION}"
    }

    stages {
        stage('Initialize Pipeline') {
            steps {
                script {
                    logWarning('⚠️ IMPORTANT: No concurrent state locking available')
                    logWarning('⚠️ Ensure only ONE instance of this pipeline runs at a time')
                    logWarning('⚠️ Manual coordination required to prevent state conflicts')

                    // Validate parameters and environment
                    validateParameters()

                    // Set up dynamic variables
                    setupDynamicEnvironment()

                    // Clean workspace
                    deleteDir()

                    logInfo('Pipeline initialized successfully')
                    logInfo("Build container: ${env.BUILD_CONTAINER_NAME}")
                    logInfo("Docker image: ${env.IMAGE_NAME}")
                    logInfo("Volume: ${env.VALIDATION_VOLUME}")
                }
            }
        }

        stage('Checkout Repositories') {
            steps {
                script {
                    logInfo('Checking out source repositories')

                    // Checkout Rancher Tests Repository
                    dir('./tests') {
                        logInfo("Cloning rancher tests repository from ${env.RANCHER_TEST_REPO_URL}")
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.RANCHER_TEST_REPO_BRANCH}"]],
                            extensions: [
                                [$class: 'CleanCheckout'],
                                [$class: 'CloneOption', depth: 1, shallow: true]
                            ],
                            userRemoteConfigs: [[
                                url: env.RANCHER_TEST_REPO_URL,
                            ]]
                        ])
                    }

                    // Checkout QA Infrastructure Repository
                    dir('./qa-infra-automation') {
                        logInfo("Cloning qa-infra-automation repository from ${env.QA_INFRA_REPO}")
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.QA_INFRA_REPO_BRANCH}"]],
                            extensions: [
                                [$class: 'CleanCheckout'],
                                [$class: 'CloneOption', depth: 1, shallow: true]
                            ],
                            userRemoteConfigs: [[
                                url: env.QA_INFRA_REPO,
                            ]]
                        ])
                    }

                    logInfo('Repository checkout completed successfully')
                }
            }
        }

        stage('Configure Environment') {
            steps {
                script {
                    logInfo('Configuring deployment environment')

                    // Configure credentials and environment files
                    withCredentials(getCredentialsList()) {
                        // Generate configuration files
                        generateConfigurationFiles()

                        // Setup SSH keys securely
                        setupSSHKeys()

                        // Build Docker image with proper tagging
                        buildDockerImage()

                        // Create shared volume
                        createSharedVolume()
                    }
                }
            }
        }

        stage('Deploy Infrastructure') {
            steps {
                script {
                    logInfo('Initializing airgap infrastructure deployment with OpenTofu')

                    // Configuration validation
                    def requiredVars = [
                        'QA_INFRA_WORK_PATH',
                        'TF_WORKSPACE',
                        'TERRAFORM_VARS_FILENAME',
                        'TERRAFORM_TIMEOUT'
                    ]

                    validateRequiredVariables(requiredVars)

                    // Enhanced timeout with reasonable defaults
                    def timeoutMinutes = env.TERRAFORM_TIMEOUT ?
                        Integer.parseInt(env.TERRAFORM_TIMEOUT) : 30

                    timeout(time: timeoutMinutes, unit: 'MINUTES') {
                        try {
                            // Pre-flight checks
                            validateInfrastructurePrerequisites()

                            // Infrastructure deployment with enhanced error handling
                            deployInfrastructure()

                            // Post-deployment validation
                            validateInfrastructureState()

                            logInfo('Infrastructure provisioned and validated successfully')
                        } catch (org.jenkinsci.plugins.workflow.steps.FlowInterruptedException e) {
                            logError("Infrastructure deployment timed out after ${timeoutMinutes} minutes")
                            handleInfrastructureFailure('TIMEOUT', e)
                            throw e
                        } catch (Exception e) {
                            logError("Infrastructure setup failed: ${e.message}")
                            handleInfrastructureFailure('DEPLOYMENT_FAILED', e)
                            throw e
                        }
                    }
                }
            }
            post {
                success {
                    script {
                        logInfo('Infrastructure deployment succeeded - archiving state')
                        archiveInfrastructureState()
                        // Additional immediate state backup for successful deployments
                        backupTerraformStateImmediately()
                    }
                }
                failure {
                    script {
                        logError('Infrastructure operations failed')
                        archiveInfrastructureFailureArtifacts()
                        // Still try to archive any partial state
                        archiveInfrastructureState()
                    }
                }
                always {
                    script {
                        // Final comprehensive state archival attempt
                        finalStateArchival()
                    }
                }
            }
        }
    }

    post {
        always {
            script {
                logInfo('Starting post-build cleanup')

                // Archive important artifacts including comprehensive tfstate backups
                archiveBuildArtifacts([
                    'kubeconfig.yaml',
                    'terraform.tfstate',
                    'terraform-state.tfstate',
                    'terraform-state-backup-*.tfstate',
                    'tfstate-backup-*.tfstate',
                    'terraform-state-build-*.tfstate',
                    'terraform-vars.tfvars',
                    'infrastructure-outputs.json',
                    'ansible-inventory.yml',
                    'ansible-logs.txt',
                    'deployment-summary.json'
                ])

                // Always cleanup containers and volumes
                try {
                    node {
                        cleanupContainersAndVolumes()
                    }
                } catch (Exception e) {
                    logError("Node context not available for cleanup: ${e.message}")
                    try {
                        cleanupContainersAndVolumes()
                    } catch (Exception cleanupException) {
                        logError("Cleanup failed: ${cleanupException.message}")
                    }
                }
            }
        }

        success {
            script {
                logInfo('Pipeline completed successfully')
                sendSlackNotification([
                    color: 'good',
                    message: "✅ Ansible Airgap setup succeeded for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }

        failure {
            script {
                logError('Pipeline failed')
                sendSlackNotification([
                    color: 'danger',
                    message: "❌ Ansible Airgap setup failed for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }

        unstable {
            script {
                logWarning('Pipeline completed with warnings')
                sendSlackNotification([
                    color: 'warning',
                    message: "⚠️ Ansible Airgap setup completed with warnings for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
    }
}

/**
 * HELPER FUNCTIONS
 * These functions are adapted from both Jenkinsfile.recurring and Jenkinsfile.airgap.rke2.improved
 */

def getShortJobName() {
    def jobName = "${env.JOB_NAME}"
    if (jobName.contains('/')) {
        def lastSlashIndex = jobName.lastIndexOf('/')
        return jobName.substring(lastSlashIndex + 1)
    }
    return jobName
}

def validateParameters() {
    // Validate required parameters
    if (!params.RKE2_VERSION) {
        error('RKE2_VERSION parameter is required')
    }
    if (!params.RANCHER_VERSION) {
        error('RANCHER_VERSION parameter is required')
    }
    if (!params.RANCHER_TEST_REPO_URL) {
        error('RANCHER_TEST_REPO_URL parameter is required')
    }
    if (!params.QA_INFRA_REPO_URL) {
        error('QA_INFRA_REPO_URL parameter is required')
    }

    logInfo('Parameters validated successfully')
}

def setupDynamicEnvironment() {
    env.RKE2_VERSION = params.RKE2_VERSION
    env.RANCHER_VERSION = params.RANCHER_VERSION

    logInfo('Dynamic environment configured')
    logInfo("RKE2 Version: ${env.RKE2_VERSION}")
    logInfo("Rancher Version: ${env.RANCHER_VERSION}")
}

def getCredentialsList() {
    return [
        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
        string(credentialsId: 'AWS_SSH_PEM_KEY', variable: 'AWS_SSH_PEM_KEY'),
        string(credentialsId: 'AWS_SSH_KEY_NAME', variable: 'AWS_SSH_KEY_NAME'),
        string(credentialsId: 'SLACK_WEBHOOK', variable: 'SLACK_WEBHOOK')
    ]
}

def generateConfigurationFiles() {
    logInfo('Generating configuration files for infrastructure deployment')

    // Validate required environment variables
    validateConfigurationEnvironmentVariables()

    // Generate Terraform configuration
    generateTerraformConfiguration()

    // Generate Ansible configuration
    generateAnsibleConfiguration()

    // Generate environment file for containers
    generateEnvironmentFile()

    logInfo('Configuration files generated successfully')
}

def validateConfigurationEnvironmentVariables() {
    logInfo('Validating configuration environment variables')

    def requiredVars = [
        'TERRAFORM_CONFIG': 'Terraform configuration content',
        'ANSIBLE_CONFIG': 'Ansible configuration content',
        'RKE2_VERSION': 'RKE2 version for deployment',
        'RANCHER_VERSION': 'Rancher version for deployment'
    ]

    def missingVars = []
    requiredVars.each { varName, description ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add("${varName} (${description})")
        }
    }

    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables for configuration:\n- ${missingVars.join('\n- ')}"
        logError(errorMsg)
        throw new IllegalArgumentException(errorMsg)
    }

    logInfo('All required environment variables validated successfully')
}

def generateTerraformConfiguration() {
    logInfo('Generating Terraform configuration')

    if (!env.TERRAFORM_CONFIG) {
        throw new RuntimeException('TERRAFORM_CONFIG environment variable is not set')
    }

    def tofuConfig = env.TERRAFORM_CONFIG

    // Replace variables in config (similar to Jenkinsfile.recurring pattern)
    tofuConfig = tofuConfig.replace('${AWS_SECRET_ACCESS_KEY}', env.AWS_SECRET_ACCESS_KEY)
    tofuConfig = tofuConfig.replace('${AWS_ACCESS_KEY_ID}', env.AWS_ACCESS_KEY_ID)
    tofuConfig = tofuConfig.replace('${AWS_REGION}', env.AWS_REGION)
    tofuConfig = tofuConfig.replace('${AWS_IAM_PROFILE}', env.AWS_IAM_PROFILE ?: '')
    tofuConfig = tofuConfig.replace('${AWS_VPC}', env.AWS_VPC ?: '')
    tofuConfig = tofuConfig.replace('${AWS_SECURITY_GROUPS}', env.AWS_SECURITY_GROUPS ?: '')

    // Write the configuration file
    dir('./qa-infra-automation') {
        dir('./tofu/aws/modules/airgap') {
            writeFile file: env.TERRAFORM_VARS_FILENAME, text: tofuConfig
            logInfo("Terraform configuration written to: ${env.TERRAFORM_VARS_FILENAME}")
        }
    }
}

def generateAnsibleConfiguration() {
    logInfo('Generating Ansible configuration')

    if (!env.ANSIBLE_CONFIG) {
        throw new RuntimeException('ANSIBLE_CONFIG environment variable is not set')
    }

    def ansibleConfig = env.ANSIBLE_CONFIG

    // Replace variables in config
    ansibleConfig = ansibleConfig.replace('${ADMIN_PASSWORD}', env.ADMIN_PASSWORD ?: '')

    // Write the Ansible configuration file to the correct location for airgap deployment
    dir('./qa-infra-automation') {
        // Ensure the directory structure exists
        sh 'mkdir -p ansible/rke2/airgap/inventory/group_vars'

        // Write the group_vars/all.yml file
        writeFile file: 'ansible/rke2/airgap/inventory/group_vars/all.yml', text: ansibleConfig
        logInfo('Ansible configuration written to: ansible/rke2/airgap/inventory/group_vars/all.yml')

        // Also create a copy in the original location for backward compatibility
        sh 'mkdir -p ansible'
        writeFile file: "ansible/${env.ANSIBLE_VARS_FILENAME}", text: ansibleConfig
        logInfo("Ansible configuration also written to: ansible/${env.ANSIBLE_VARS_FILENAME} (backward compatibility)")
    }
}

def generateEnvironmentFile() {
    logInfo('Generating environment file for container execution')

    // Build environment content securely without direct interpolation of secrets
    def envLines = [
        '# Environment variables for infrastructure deployment containers',
        "TF_WORKSPACE=${env.TF_WORKSPACE}",
        "BUILD_NUMBER=${env.BUILD_NUMBER}",
        "JOB_NAME=${env.JOB_NAME}",
        "TERRAFORM_TIMEOUT=${env.TERRAFORM_TIMEOUT}",
        "ANSIBLE_TIMEOUT=${env.ANSIBLE_TIMEOUT}",
        "QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH}",
        "TERRAFORM_VARS_FILENAME=${env.TERRAFORM_VARS_FILENAME}",
        "ANSIBLE_VARS_FILENAME=${env.ANSIBLE_VARS_FILENAME}",
        "RKE2_VERSION=${env.RKE2_VERSION}",
        "RANCHER_VERSION=${env.RANCHER_VERSION}",
        "PRIVATE_REGISTRY_URL=${env.PRIVATE_REGISTRY_URL}",
        "PRIVATE_REGISTRY_USERNAME=${env.PRIVATE_REGISTRY_USERNAME}",
        '',
        '# AWS Credentials for OpenTofu (Standard AWS environment variables)'
    ]

    // Add credentials securely
    envLines.add('AWS_ACCESS_KEY_ID=' + env.AWS_ACCESS_KEY_ID)
    envLines.add('AWS_SECRET_ACCESS_KEY=' + env.AWS_SECRET_ACCESS_KEY)
    envLines.add('AWS_REGION=' + env.AWS_REGION)
    envLines.add('')
    envLines.add('# Terraform Variables for OpenTofu (TF_VAR_ prefix for automatic variable population)')
    envLines.add('TF_VAR_aws_access_key=' + env.AWS_ACCESS_KEY_ID)
    envLines.add('TF_VAR_aws_secret_access_key=' + env.AWS_SECRET_ACCESS_KEY)
    envLines.add('TF_VAR_aws_region=' + env.AWS_REGION)
    envLines.add('')
    envLines.add('# S3 Backend State Storage Configuration')
    envLines.add("TF_STATE_BUCKET=${env.TF_STATE_BUCKET}")
    envLines.add("TF_STATE_KEY_PREFIX=${env.TF_STATE_KEY_PREFIX}")
    envLines.add("TF_STATE_REGION=${env.TF_STATE_REGION}")

    def envContent = envLines.join('\n')
    writeFile file: env.ENV_FILE, text: envContent
    logInfo("Environment file created: ${env.ENV_FILE}")
}

def setupSSHKeys() {
    if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
        logInfo('Setting up SSH keys')

        dir('./tests/.ssh') {
            def decodedKey = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
            writeFile file: env.AWS_SSH_KEY_NAME, text: decodedKey
            sh "chmod 600 ${env.AWS_SSH_KEY_NAME}"
        }

        logInfo('SSH keys configured successfully')
    }
}

def buildDockerImage() {
    logInfo("Building Docker image: ${env.IMAGE_NAME}")

    dir('./') {
        sh './tests/validation/configure.sh'
        sh """
            docker build . \
                -f ./tests/validation/Dockerfile.tofu.e2e \
                -t ${env.IMAGE_NAME} \
                --build-arg BUILD_DATE=\$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
                --build-arg VCS_REF=\$(git rev-parse --short HEAD) \
                --label "pipeline.build.number=${env.BUILD_NUMBER}" \
                --label "pipeline.job.name=${env.JOB_NAME}"
        """
    }

    logInfo('Docker image built successfully')
}

def createSharedVolume() {
    logInfo("Creating shared volume: ${env.VALIDATION_VOLUME}")
    sh "docker volume create --name ${env.VALIDATION_VOLUME}"
}

def executeScriptInContainer(scriptContent, extraEnv = [:]) {
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-script-${timestamp}"
    def scriptFile = "docker-script-${timestamp}.sh"

    writeFile file: scriptFile, text: scriptContent

    def envVars = ''
    extraEnv.each { key, value ->
        envVars += " -e ${key}=${value}"
    }

    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            -v ${pwd()}/${scriptFile}:/tmp/script.sh \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${envVars} \
            ${env.IMAGE_NAME} \
            sh /tmp/script.sh
    """

    sh "rm -f ${scriptFile}"
}

def cleanupContainersAndVolumes() {
    logInfo('Cleaning up Docker containers and volumes')

    try {
        if (env.NODE_NAME) {
            sh """
                # Stop and remove any containers with our naming pattern
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker stop || true
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker rm -v || true

                # Remove the Docker image
                docker rmi -f ${env.IMAGE_NAME} || true

                # Remove the shared volume
                docker volume rm -f ${env.VALIDATION_VOLUME} || true

                # Clean up any dangling images and volumes
                docker system prune -f || true
            """
        } else {
            logWarning('No node context available for Docker cleanup')
        }
    } catch (Exception e) {
        logError("Docker cleanup failed: ${e.message}")
    }
}

def archiveBuildArtifacts(artifacts) {
    try {
        archiveArtifacts artifacts: artifacts.join(','), allowEmptyArchive: true
        logInfo("Artifacts archived: ${artifacts.join(', ')}")
    } catch (Exception e) {
        logError("Failed to archive artifacts: ${e.message}")
    }
}

def sendSlackNotification(config) {
    if (env.SLACK_WEBHOOK) {
        try {
            def payload = [
                channel: '#rancher-qa',
                username: 'Jenkins',
                color: config.color,
                title: 'Ansible Airgap Setup Pipeline',
                message: config.message,
                fields: [
                    [title: 'Job', value: env.JOB_NAME, short: true],
                    [title: 'Build', value: env.BUILD_NUMBER, short: true],
                    [title: 'RKE2 Version', value: env.RKE2_VERSION, short: true],
                    [title: 'Rancher Version', value: env.RANCHER_VERSION, short: true]
                ]
            ]

            httpRequest(
                httpMode: 'POST',
                url: env.SLACK_WEBHOOK,
                contentType: 'APPLICATION_JSON',
                requestBody: groovy.json.JsonOutput.toJson(payload)
            )

            logInfo('Slack notification sent successfully')
        } catch (Exception e) {
            logError("Failed to send Slack notification: ${e.message}")
        }
    }
}

/**
 * INFRASTRUCTURE MANAGEMENT FUNCTIONS
 * These are adapted from Jenkinsfile.airgap.rke2.improved
 */

def validateRequiredVariables(requiredVars) {
    logInfo('Validating required environment variables')

    def missingVars = []
    requiredVars.each { varName ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add(varName)
        }
    }

    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables: ${missingVars.join(', ')}"
        logError(errorMsg)
        throw new IllegalArgumentException(errorMsg)
    }

    logInfo('All required variables validated successfully')
}

def validateInfrastructurePrerequisites() {
    logInfo('Validating infrastructure prerequisites')

    def prerequisiteScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Checking OpenTofu installation...'
tofu version

echo 'Checking workspace directory...'
test -d ${env.QA_INFRA_WORK_PATH}

echo 'Validating terraform vars file...'
test -f ${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/${env.TERRAFORM_VARS_FILENAME}

echo 'All infrastructure prerequisites validated successfully'
"""

    try {
        executeScriptInContainer(prerequisiteScript)
        logInfo('All infrastructure prerequisites validated')
    } catch (Exception e) {
        def errorMsg = "Infrastructure prerequisites validation failed: ${e.message}"
        logError(errorMsg)
        throw new RuntimeException(errorMsg, e)
    }
}

def deployInfrastructure() {
    logInfo('Starting infrastructure deployment process')

    // Step 1: Initialize OpenTofu
    initializeOpenTofu()

    // Step 2: Manage workspace
    manageWorkspace()

    // Step 3: Plan infrastructure changes
    planInfrastructure()

    // Step 4: Apply infrastructure
    applyInfrastructure()

    logInfo('Infrastructure deployment completed successfully')
}

def initializeOpenTofu() {
    logInfo('Initializing OpenTofu with S3 backend')

    def initScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Configuring S3 backend for state storage (no DynamoDB locking)...'
cat > tofu/aws/modules/airgap/backend.tf << EOF
terraform {
  backend "s3" {
    bucket  = "${env.TF_STATE_BUCKET}"
    key     = "${env.TF_STATE_KEY_PREFIX}/${env.TF_WORKSPACE}/terraform.tfstate"
    region  = "${env.TF_STATE_REGION}"
    encrypt = true

    # WARNING: No state locking available
    # Manual coordination required to prevent concurrent operations
  }
}
EOF

echo '⚠️  WARNING: No state locking available - manual coordination required'
echo 'Backend configuration without DynamoDB:'
cat tofu/aws/modules/airgap/backend.tf

echo 'Backend configuration written:'
cat tofu/aws/modules/airgap/backend.tf

echo 'Initializing OpenTofu backend...'
tofu -chdir=tofu/aws/modules/airgap init -input=false -upgrade -reconfigure

echo 'Verifying initialization success...'
tofu -chdir=tofu/aws/modules/airgap providers

echo 'OpenTofu initialization with S3 backend completed successfully'
"""

    executeScriptInContainer(initScript)
}

def manageWorkspace() {
    logInfo("Managing OpenTofu workspace: ${env.TF_WORKSPACE}")

    def workspaceScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Managing workspace state...'
unset TF_WORKSPACE

echo 'Current workspaces:'
tofu -chdir=tofu/aws/modules/airgap workspace list

echo 'Creating or selecting workspace: ${env.TF_WORKSPACE}'
if ! tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE} 2>/dev/null; then
    echo 'Workspace does not exist, creating new workspace...'
    tofu -chdir=tofu/aws/modules/airgap workspace new ${env.TF_WORKSPACE}

    if ! tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE}; then
        echo 'ERROR: Failed to create and select workspace'
        exit 1
    fi
fi

# Verify workspace selection
CURRENT_WORKSPACE=\$(tofu -chdir=tofu/aws/modules/airgap workspace show)
echo "Current workspace: \$CURRENT_WORKSPACE"

# Strip whitespace and handle empty responses
CURRENT_WORKSPACE=\$(echo "\$CURRENT_WORKSPACE" | xargs)

if [ "\$CURRENT_WORKSPACE" = "" ]; then
    echo 'ERROR: Workspace show command returned empty response'
    tofu -chdir=tofu/aws/modules/airgap workspace list
    exit 1
fi

if [ "\$CURRENT_WORKSPACE" != "${env.TF_WORKSPACE}" ]; then
    echo "ERROR: Expected workspace ${env.TF_WORKSPACE}, but got '\$CURRENT_WORKSPACE'"
    echo 'Available workspaces:'
    tofu -chdir=tofu/aws/modules/airgap workspace list
    exit 1
fi

export TF_WORKSPACE=${env.TF_WORKSPACE}
echo "Workspace management completed: \$TF_WORKSPACE"
"""

    executeScriptInContainer(workspaceScript)
}

def planInfrastructure() {
    logInfo('Planning infrastructure changes')

    def planScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Generating infrastructure plan for validation...'
tofu -chdir=tofu/aws/modules/airgap plan -input=false -var-file=${env.TERRAFORM_VARS_FILENAME} -out=tfplan

echo 'Checking if plan file was generated in the correct location...'
if [ ! -f tofu/aws/modules/airgap/tfplan ]; then
    echo 'ERROR: Plan file was not generated successfully in module directory'
    echo 'Contents of tofu/aws/modules/airgap/:'
    ls -la tofu/aws/modules/airgap/
    exit 1
fi

echo 'Verifying plan file is not empty...'
PLAN_SIZE=\$(stat -c%s tofu/aws/modules/airgap/tfplan 2>/dev/null || echo 0)
if [ "\$PLAN_SIZE" = "0" ]; then
    echo 'ERROR: Plan file is empty'
    exit 1
fi

echo "Plan file generated successfully (\$PLAN_SIZE bytes) in tofu/aws/modules/airgap/tfplan"

# Copy plan file from module directory to shared volume for persistence
cp tofu/aws/modules/airgap/tfplan /root/tfplan-backup
echo 'Plan file backed up to shared volume'

echo 'Infrastructure plan validation completed'
"""

    executeScriptInContainer(planScript)
}

def applyInfrastructure() {
    logInfo('Applying infrastructure configuration')

    def applyScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Restoring plan file from shared volume...'
if [ -f /root/tfplan-backup ]; then
    # Restore plan file to the correct module directory
    cp /root/tfplan-backup tofu/aws/modules/airgap/tfplan
    echo 'Plan file restored from shared volume to module directory'
else
    echo 'ERROR: No backup plan file found in shared volume'
    echo 'Generating new plan...'
    tofu -chdir=tofu/aws/modules/airgap plan -input=false -var-file=${env.TERRAFORM_VARS_FILENAME} -out=tfplan
fi

# Check if plan was restored/generated successfully in module directory
if [ ! -f tofu/aws/modules/airgap/tfplan ]; then
    echo 'ERROR: Plan file was not generated successfully in module directory'
    exit 1
fi

# Verify the plan file is not empty
PLAN_SIZE=\$(stat -c%s tofu/aws/modules/airgap/tfplan 2>/dev/null || echo 0)
if [ "\$PLAN_SIZE" = "0" ]; then
    echo 'ERROR: Plan file is empty'
    exit 1
fi

echo 'Plan file restored successfully (\$PLAN_SIZE bytes), applying...'
tofu -chdir=tofu/aws/modules/airgap apply -auto-approve -input=false tfplan

# Clean up the plan file after successful application
rm -f tofu/aws/modules/airgap/tfplan

echo 'Verifying state after apply...'
tofu -chdir=tofu/aws/modules/airgap state list

echo 'Backing up terraform state immediately after apply...'
# Create multiple backups of the state file for reliability
cp tofu/aws/modules/airgap/terraform.tfstate terraform-state-backup-\$(date +%Y%m%d-%H%M%S).tfstate
cp tofu/aws/modules/airgap/terraform.tfstate /root/terraform-state-primary.tfstate
cp tofu/aws/modules/airgap/terraform.tfstate /root/terraform.tfstate

echo 'Backing up terraform variables file for archival...'
# Backup locally for archival (no S3 upload needed with backend)
cp tofu/aws/modules/airgap/${env.TERRAFORM_VARS_FILENAME} /root/${env.TERRAFORM_VARS_FILENAME}

# Verify state file exists and has content
if [ -f tofu/aws/modules/airgap/terraform.tfstate ] && [ -s tofu/aws/modules/airgap/terraform.tfstate ]; then
    echo "SUCCESS: terraform.tfstate backed up successfully (\$(stat -c%s tofu/aws/modules/airgap/terraform.tfstate) bytes)"
    ls -la tofu/aws/modules/airgap/terraform.tfstate
else
    echo "ERROR: terraform.tfstate is missing or empty after apply"
fi

echo 'Generating outputs for downstream stages...'
tofu -chdir=tofu/aws/modules/airgap output -json > ${env.QA_INFRA_WORK_PATH}/infrastructure-outputs.json

echo 'Verifying inventory file generation...'
if [ -f ansible/rke2/airgap/inventory/inventory.yml ] && [ -s ansible/rke2/airgap/inventory/inventory.yml ]; then
    echo 'SUCCESS: inventory.yml generated by tofu apply exists and has content'
    echo 'Fixing YAML syntax issues in inventory file...'

    # Debug: Show the full inventory.yml content first
    echo "=== Full inventory.yml content before fixing ==="
    cat ansible/rke2/airgap/inventory/inventory.yml
    echo "=== End inventory.yml content ==="

    # Show specific lines that might have YAML syntax issues
    echo "=== Lines with potential YAML syntax issues ==="
    grep -n ":" ansible/rke2/airgap/inventory/inventory.yml \\| grep ": [^']" \\| head -10
    echo "=== End potential issues ==="

    # Fix the ProxyCommand quoting issue with a comprehensive approach
    # Create a backup first
    cp ansible/rke2/airgap/inventory/inventory.yml ansible/rke2/airgap/inventory/inventory.yml.backup

    # Use python to properly fix the YAML syntax (more reliable than sed)
    python3 << 'EOF'
import re
import sys

# Read the inventory file
with open('ansible/rke2/airgap/inventory/inventory.yml', 'r') as f:
    content = f.read()

print("=== Python YAML fixer ===")
print("Original content:")
print(content)

# Find the exact problematic line and fix it
# The specific issue is: ProxyCommand='ssh -W %h:%p -i {{ ssh_private_key_file }} {{ bastion_user }}@{{ bastion_host }}'
# We need to change the single quotes to double quotes

# Pattern to match the exact problematic line
pattern = "ProxyCommand='ssh -W %h:%p -i {{ ssh_private_key_file }} {{ bastion_user }}@{{ bastion_host }}'"
replacement = 'ProxyCommand="ssh -W %h:%p -i {{ ssh_private_key_file }} {{ bastion_user }}@{{ bastion_host }}"'

fixed_content = re.sub(pattern, replacement, content)

print("=== After first replacement ===")
print(fixed_content)

# Also handle a more general pattern
pattern2 = r"ProxyCommand='([^']*)'"
replacement2 = r'ProxyCommand="\1"'
fixed_content = re.sub(pattern2, replacement2, fixed_content)

print("=== Final fixed content ===")
print(fixed_content)

# Write the fixed content back
with open('ansible/rke2/airgap/inventory/inventory.yml', 'w') as f:
    f.write(fixed_content)

print("=== Python YAML fixer completed ===")

# Validate the fix
try:
    import yaml
    with open('ansible/rke2/airgap/inventory/inventory.yml', 'r') as f:
        yaml.safe_load(f)
    print("=== YAML validation: SUCCESS ===")
except Exception as e:
    print("=== YAML validation: FAILED ===")
    print(f"Error: {e}")
EOF

    echo 'Fixed inventory file contents:'
    head -30 ansible/rke2/airgap/inventory/inventory.yml

    # Validate the YAML syntax
    echo "=== Validating YAML syntax ==="
    python3 -c "import yaml; yaml.safe_load(open('ansible/rke2/airgap/inventory/inventory.yml', 'r'))" && echo "YAML syntax is valid" || echo "YAML syntax still has issues"
    echo "=== End YAML validation ==="
else
    echo 'ERROR: inventory.yml missing or empty after tofu apply'
    echo 'Contents of ansible/rke2/airgap/inventory/:'
    ls -la ansible/rke2/airgap/inventory/
    exit 1
fi

echo 'Infrastructure provisioned and inventory generated successfully'
"""

    executeScriptInContainer(applyScript)
}

def validateInfrastructureState() {
    logInfo('Validating infrastructure deployment state')

    def validationScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Validating infrastructure state...'
STATE_COUNT=\$(tofu -chdir=tofu/aws/modules/airgap state list | wc -l)
echo "Number of resources in state: \$STATE_COUNT"

echo 'Checking critical outputs...'
tofu -chdir=tofu/aws/modules/airgap output -raw vpc_id || echo 'WARNING: vpc_id output missing'
tofu -chdir=tofu/aws/modules/airgap output -raw subnet_ids || echo 'WARNING: subnet_ids output missing'

echo 'Validating inventory files...'
if [ -f ansible/rke2/airgap/inventory/inventory.yml ] && [ -s ansible/rke2/airgap/inventory/inventory.yml ]; then
    echo 'SUCCESS: inventory.yml exists and has content'
else
    echo 'WARNING: inventory.yml missing or empty'
fi

echo 'Infrastructure state validation completed'
"""

    executeScriptInContainer(validationScript)
}

/**
 * LOGGING FUNCTIONS
 */

def logInfo(message) {
    echo "ℹ️ [INFO] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logError(message) {
    echo "❌ [ERROR] ${new Date().format('HH:mm:ss')} - ${message}"
}
def logWarning(message) {
    echo "⚠️ [WARNING] ${new Date().format('HH:mm:ss')} - ${message}"
}

/**
 * INFRASTRUCTURE ARCHIVAL FUNCTIONS
 */

def archiveInfrastructureState() {
    logInfo('Archiving infrastructure state files')
    
    try {
        // Extract state files from shared volume first (most reliable method)
        extractStateFromVolume()
        
        // Fallback: try to extract from running container if volume extraction failed
        extractStateFromContainer()
        
        // Archive all available infrastructure artifacts with comprehensive patterns
        def artifacts = [
            'terraform.tfstate',
            'terraform-state.tfstate',
            'terraform-state-backup-*.tfstate',
            'terraform-vars.tfvars',
            'infrastructure-outputs.json',
            'ansible-inventory.yml',
            'tfstate-backup-*.tfstate'
        ]
        
        archiveArtifacts artifacts: artifacts.join(','), allowEmptyArchive: true
        
        logInfo('Infrastructure state archived successfully')
    } catch (Exception e) {
        logError("Failed to archive infrastructure state: ${e.message}")
    }
}

def extractStateFromVolume() {
    logInfo('Extracting terraform state from shared volume')
    
    try {
        // Create a temporary container to extract files from the shared volume
        def extractorScript = """
# Create temporary container to access the shared volume
EXTRACTOR_CONTAINER="${env.BUILD_CONTAINER_NAME}-extractor-\$(date +%s)"

docker run --rm \\
    -v ${env.VALIDATION_VOLUME}:/shared \\
    -v \$(pwd):/workspace \\
    --name \$EXTRACTOR_CONTAINER \\
    ${env.IMAGE_NAME} \\
    sh -c '
        echo "Extracting state files from shared volume..."
        
        # Copy terraform state file with timestamp
        if [ -f /shared/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/terraform.tfstate ]; then
            cp /shared/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/terraform.tfstate /workspace/terraform.tfstate
            cp /shared/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/terraform.tfstate /workspace/tfstate-backup-\$(date +%Y%m%d-%H%M%S).tfstate
            echo "SUCCESS: terraform.tfstate extracted from shared volume"
        elif [ -f /shared/terraform-state-primary.tfstate ]; then
            cp /shared/terraform-state-primary.tfstate /workspace/terraform.tfstate
            cp /shared/terraform-state-primary.tfstate /workspace/tfstate-backup-\$(date +%Y%m%d-%H%M%S).tfstate
            echo "SUCCESS: terraform.tfstate extracted from shared volume backup"
        elif [ -f /shared/terraform.tfstate ]; then
            cp /shared/terraform.tfstate /workspace/terraform.tfstate
            cp /shared/terraform.tfstate /workspace/tfstate-backup-\$(date +%Y%m%d-%H%M%S).tfstate
            echo "SUCCESS: terraform.tfstate extracted from shared volume root"
        else
            echo "WARNING: terraform.tfstate not found in shared volume"
            find /shared -name "*.tfstate" -type f 2>/dev/null || echo "No tfstate files found in shared volume"
        fi
        
        # Copy infrastructure outputs
        if [ -f /shared/go/src/github.com/rancher/qa-infra-automation/infrastructure-outputs.json ]; then
            cp /shared/go/src/github.com/rancher/qa-infra-automation/infrastructure-outputs.json /workspace/infrastructure-outputs.json
            echo "SUCCESS: infrastructure-outputs.json extracted"
        fi

        # Copy terraform variables file
        if [ -f /shared/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/${env.TERRAFORM_VARS_FILENAME} ]; then
            cp /shared/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/${env.TERRAFORM_VARS_FILENAME} /workspace/terraform-vars.tfvars
            echo "SUCCESS: terraform variables file extracted"
        elif [ -f /shared/${env.TERRAFORM_VARS_FILENAME} ]; then
            cp /shared/${env.TERRAFORM_VARS_FILENAME} /workspace/terraform-vars.tfvars
            echo "SUCCESS: terraform variables file extracted from shared root"
        fi

        # Copy ansible inventory
        if [ -f /shared/go/src/github.com/rancher/qa-infra-automation/ansible/rke2/airgap/inventory/inventory.yml ]; then
            cp /shared/go/src/github.com/rancher/qa-infra-automation/ansible/rke2/airgap/inventory/inventory.yml /workspace/ansible-inventory.yml
            echo "SUCCESS: ansible-inventory.yml extracted"
        fi
        
        echo "Volume extraction completed"
    '
"""
        
        sh(script: extractorScript, returnStdout: false)
        logInfo('State files extracted from shared volume successfully')
    } catch (Exception e) {
        logWarning("Volume extraction failed: ${e.message}")
    }
}

def extractStateFromContainer() {
    logInfo('Attempting container-based state extraction as fallback')
    
    try {
        // Find any running containers matching our pattern
        def containerIds = sh(
            script: "docker ps -q --filter 'name=${env.BUILD_CONTAINER_NAME}' || true",
            returnStdout: true
        ).trim()
        
        if (containerIds) {
            logInfo("Found running containers: ${containerIds}")
            
            sh """
                # Extract from the first matching container
                CONTAINER_ID=\$(echo "${containerIds}" | head -n1)
                echo "Extracting from container: \$CONTAINER_ID"
                
                # Copy state files with multiple fallback paths
                docker cp \$CONTAINER_ID:${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/terraform.tfstate ./terraform-state.tfstate 2>/dev/null || \\
                docker cp \$CONTAINER_ID:/root/terraform-state-primary.tfstate ./terraform-state.tfstate 2>/dev/null || \\
                docker cp \$CONTAINER_ID:/root/terraform.tfstate ./terraform-state.tfstate 2>/dev/null || \\
                docker cp \$CONTAINER_ID:/root/go/src/github.com/rancher/qa-infra-automation/tofu/aws/modules/airgap/terraform.tfstate ./terraform-state.tfstate 2>/dev/null || \\
                echo "WARNING: Could not extract terraform.tfstate from container"
                
                docker cp \$CONTAINER_ID:${env.QA_INFRA_WORK_PATH}/infrastructure-outputs.json ./infrastructure-outputs.json 2>/dev/null || \\
                echo "WARNING: Could not extract infrastructure-outputs.json from container"

                # Copy terraform variables file with multiple fallback paths
                docker cp \$CONTAINER_ID:${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/${env.TERRAFORM_VARS_FILENAME} ./terraform-vars.tfvars 2>/dev/null || \\
                docker cp \$CONTAINER_ID:/root/${env.TERRAFORM_VARS_FILENAME} ./terraform-vars.tfvars 2>/dev/null || \\
                echo "WARNING: Could not extract terraform variables file from container"

                docker cp \$CONTAINER_ID:${env.QA_INFRA_WORK_PATH}/ansible/rke2/airgap/inventory/inventory.yml ./ansible-inventory.yml 2>/dev/null || \\
                echo "WARNING: Could not extract ansible-inventory.yml from container"
            """
        } else {
            logWarning('No running containers found for state extraction')
        }
    } catch (Exception e) {
        logWarning("Container extraction failed: ${e.message}")
    }
}

def backupTerraformStateImmediately() {
    logInfo('Creating immediate backup of terraform state after successful deployment')
    
    try {
        // Extract state immediately for successful deployments
        extractStateFromVolume()
        extractStateFromContainer()
        
        // Create timestamped backup with build information
        def timestamp = new Date().format('yyyyMMdd-HHmmss')
        def backupName = "terraform-state-build-${env.BUILD_NUMBER}-${timestamp}.tfstate"
        
        sh """
            # Create backup with build metadata
            if [ -f terraform.tfstate ]; then
                cp terraform.tfstate ${backupName}
                echo "SUCCESS: Immediate backup created: ${backupName}"
            elif [ -f terraform-state.tfstate ]; then
                cp terraform-state.tfstate ${backupName}
                echo "SUCCESS: Immediate backup created from fallback: ${backupName}"
            else
                echo "WARNING: No state file found for immediate backup"
            fi
        """
        
        // Archive the immediate backup
        archiveArtifacts artifacts: backupName, allowEmptyArchive: true
        
        logInfo('Immediate terraform state backup completed')
    } catch (Exception e) {
        logError("Immediate backup failed: ${e.message}")
    }
}

def finalStateArchival() {
    logInfo('Performing final comprehensive state archival')
    
    try {
        // One last attempt to get all possible state files
        extractStateFromVolume()
        extractStateFromContainer()
        
        // List all potential state files in workspace
        sh 'find . -name "*.tfstate" -type f || true'
        sh 'find . -name "*terraform*" -type f || true'
        sh 'find . -name "*infrastructure*" -type f || true'
        
        // Archive everything we can find
        def comprehensiveArtifacts = [
            '*.tfstate',
            'terraform*.tfstate',
            'tfstate-*',
            'infrastructure-outputs.json',
            'ansible-inventory.yml',
            'workspace-list.txt',
            'state-list.txt',
            'terraform-show.txt'
        ]
        
        archiveArtifacts artifacts: comprehensiveArtifacts.join(','), allowEmptyArchive: true
        
        logInfo('Final state archival completed')
    } catch (Exception e) {
        logError("Final archival failed: ${e.message}")
    }
}

def archiveInfrastructureFailureArtifacts() {
    logInfo('Archiving infrastructure failure artifacts for debugging')
    
    try {
        // Create debugging artifacts
        def debugCommands = [
            "cd ${env.QA_INFRA_WORK_PATH}",
            'tofu -chdir=tofu/aws/modules/airgap workspace list > workspace-list.txt 2>&1 || echo "No workspace list available"',
            'tofu -chdir=tofu/aws/modules/airgap state list > state-list.txt 2>&1 || echo "No state available"',
            'tofu -chdir=tofu/aws/modules/airgap show > terraform-show.txt 2>&1 || echo "No terraform show available"',
            'ls -la tofu/aws/modules/airgap/ > directory-contents.txt 2>&1 || echo "Directory not accessible"',
            'echo "Infrastructure failure artifact collection completed"'
        ]
        
        executeScriptInContainer(debugCommands.join(' && '))
        
        // Copy debug files from container
        sh """
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/workspace-list.txt ./ || true
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/state-list.txt ./ || true
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/terraform-show.txt ./ || true
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/directory-contents.txt ./ || true
        """
        
        // Archive failure artifacts
        archiveArtifacts artifacts: 'workspace-list.txt,state-list.txt,terraform-show.txt,directory-contents.txt', allowEmptyArchive: true
        
        logInfo('Infrastructure failure artifacts archived')
    } catch (Exception e) {
        logError("Failed to archive failure artifacts: ${e.message}")
    }
}

def handleInfrastructureFailure(failureType, exception) {
    logError("Handling infrastructure failure: ${failureType}")
    logError("Exception: ${exception.message}")
    
    if (env.DESTROY_ON_FAILURE == 'true') {
        logWarning('DESTROY_ON_FAILURE is enabled - cleaning up infrastructure')
        try {
            def cleanupScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Starting infrastructure cleanup due to failure...'
echo 'Current workspace:'
tofu -chdir=tofu/aws/modules/airgap workspace show

echo 'Destroying infrastructure...'
tofu -chdir=tofu/aws/modules/airgap destroy -auto-approve -var-file=${env.TERRAFORM_VARS_FILENAME} || echo 'Destroy command completed with warnings'
"""
            
            executeScriptInContainer(cleanupScript)
            logInfo('Infrastructure cleanup completed')
        } catch (Exception cleanupException) {
            logError("Infrastructure cleanup failed: ${cleanupException.message}")
        }
    } else {
        logWarning('DESTROY_ON_FAILURE is disabled - infrastructure left in current state')
        logWarning("Workspace ${env.TF_WORKSPACE} may need manual cleanup")
    }
}


