#!/usr/bin/env groovy

/**
 * Ansible Airgap Setup Jenkinsfile
 * Based on Jenkinsfile.recurring but adapted for airgap RKE2 infrastructure setup
 *
 * This pipeline sets up airgap RKE2 infrastructure using Ansible and OpenTofu
 * with enhanced error handling and proper workspace management.
 */

pipeline {
    agent any

    // Global pipeline options
    options {
        buildDiscarder(logRotator(numToKeepStr: '10'))
        timeout(time: 3, unit: 'HOURS')
        timestamps()
        ansiColor('xterm')
        skipStagesAfterUnstable()
        retry(1)
    }

    // Environment-specific parameters
    parameters {
        string(
            name: 'RKE2_VERSION',
            defaultValue: 'v1.28.8+rke2r1',
            description: 'RKE2 version to deploy (e.g., v1.28.8+rke2r1, v1.29.5+rke2r1, v1.30.2+rke2r1)'
        )
        string(
            name: 'RANCHER_VERSION',
            defaultValue: 'v2.10-head',
            description: 'Rancher version to deploy (e.g., head, v2.10-head, v2.11.0, v2.9-head)'
        )
        string(
            name: 'RANCHER_TEST_REPO_URL',
            defaultValue: 'https://github.com/rancher/tests',
            description: 'URL of rancher/tests repository'
        )
        string(
            name: 'RANCHER_TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of rancher/tests repository'
        )
        string(
            name: 'QA_INFRA_REPO_URL',
            defaultValue: 'https://github.com/rancher/qa-infra-automation',
            description: 'URL of qa-infra-automation repository'
        )
        string(
            name: 'QA_INFRA_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of qa-infra-automation repository'
        )
        string(
            name: 'PRIVATE_REGISTRY_URL',
            defaultValue: '',
            description: 'Private registry URL for airgap deployment'
        )
        string(
            name: 'PRIVATE_REGISTRY_USERNAME',
            defaultValue: 'default-user',
            description: 'Private registry username for airgap deployment'
        )
        password(
            name: 'PRIVATE_REGISTRY_PASSWORD',
            defaultValue: '',
            description: 'Private registry password for airgap deployment'
        )
        string(
            name: 'S3_BUCKET_NAME',
            defaultValue: 'jenkins-terraform-state-storage',
            description: 'S3 bucket name where Terraform state is stored'
        )
        string(
            name: 'S3_KEY_PREFIX',
            defaultValue: 'jenkins-airgap-rke2/terraform.tfstate',
            description: 'S3 key prefix for the Terraform state files'
        )
        string(
            name: 'S3_REGION',
            defaultValue: 'us-east-2',
            description: 'AWS region where the S3 bucket is located'
        )
        string(
            name: 'HOSTNAME_PREFIX',
            defaultValue: 'ansible-airgap',
            description: 'Hostname prefix for *.qa.rancher.space and other AWS resources'
        )
        booleanParam(
            name: 'DESTROY_ON_FAILURE',
            defaultValue: true,
            description: 'Destroy infrastructure when Ansible playbooks fail (automatic cleanup)'
        )
    }

    // Global environment variables
    environment {
        // Repository configurations
        RANCHER_TEST_REPO_URL = "${params.RANCHER_TEST_REPO_URL ?: 'https://github.com/rancher/tests'}"
        QA_INFRA_REPO = "${params.QA_INFRA_REPO_URL ?: 'https://github.com/rancher/qa-infra-automation'}"

        // Private registry configurations
        PRIVATE_REGISTRY_URL = "${params.PRIVATE_REGISTRY_URL ?: ''}"
        PRIVATE_REGISTRY_USERNAME = "${params.PRIVATE_REGISTRY_USERNAME ?: 'default-user'}"
        PRIVATE_REGISTRY_PASSWORD = "${params.PRIVATE_REGISTRY_PASSWORD ?: ''}"

        // Path configurations
        ROOT_PATH = '/root/go/src/github.com/rancher/tests/'
        QA_INFRA_WORK_PATH = '/root/go/src/github.com/rancher/qa-infra-automation'

        // Cleanup configurations
        DESTROY_ON_FAILURE = "${params.DESTROY_ON_FAILURE}"

        // Computed values
        JOB_SHORT_NAME = "${getShortJobName()}"
        BUILD_CONTAINER_NAME = "${JOB_SHORT_NAME}${BUILD_NUMBER}-airgap-ansible"
        IMAGE_NAME = "rancher-ansible-airgap-setup-${JOB_SHORT_NAME}${BUILD_NUMBER}"
        VALIDATION_VOLUME = "AnsibleAirgapSharedVolume-${JOB_SHORT_NAME}${BUILD_NUMBER}"

        // Configuration files
        ANSIBLE_VARS_FILENAME = 'vars.yaml'
        TERRAFORM_VARS_FILENAME = 'cluster.tfvars'
        TERRAFORM_BACKEND_VARS_FILENAME = 'backend.tfvars'
        ENV_FILE = '.env'

        // Terraform workspace
        TF_WORKSPACE = "jenkins_airgap_ansible_workspace_${BUILD_NUMBER}"

        // Timeouts (in minutes)
        TERRAFORM_TIMEOUT = '30'
        ANSIBLE_TIMEOUT = '45'
        VALIDATION_TIMEOUT = '15'

        // Backend configuration (S3 backend parameters)
        S3_BUCKET_NAME = "${params.S3_BUCKET_NAME ?: 'jenkins-terraform-state-storage'}"
        S3_REGION = "${params.S3_REGION ?: 'us-east-2'}"
        S3_KEY_PREFIX = "${params.S3_KEY_PREFIX ?: 'jenkins-airgap-rke2'}"

        // Hostname prefix
        HOSTNAME_PREFIX = "${params.HOSTNAME_PREFIX ?: 'ansible-airgap'}"
    }

    stages {
        stage('Initialize Pipeline') {
            steps {
                script {
                    logInfo('Initializing pipeline')
                    // Validate parameters and environment
                    validateParameters()

                    // Set up dynamic variables
                    setupDynamicEnvironment()

                    // Clean workspace
                    deleteDir()

                    logInfo('Pipeline initialized successfully')
                    logInfo("Build container: ${env.BUILD_CONTAINER_NAME}")
                    logInfo("Docker image: ${env.IMAGE_NAME}")
                    logInfo("Volume: ${env.VALIDATION_VOLUME}")
                }
            }
        }

        stage('Checkout Repositories') {
            steps {
                script {
                    logInfo('Checking out source repositories')

                    // Checkout Rancher Tests Repository
                    dir('./tests') {
                        logInfo("Cloning rancher tests repository from ${env.RANCHER_TEST_REPO_URL}")
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.RANCHER_TEST_REPO_BRANCH}"]],
                            extensions: [
                                [$class: 'CleanCheckout'],
                                [$class: 'CloneOption', depth: 1, shallow: true]
                            ],
                            userRemoteConfigs: [[
                                url: env.RANCHER_TEST_REPO_URL,
                            ]]
                        ])
                    }

                    // Checkout QA Infrastructure Repository
                    dir('./qa-infra-automation') {
                        logInfo("Cloning qa-infra-automation repository from ${env.QA_INFRA_REPO}")
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.QA_INFRA_REPO_BRANCH}"]],
                            extensions: [
                                [$class: 'CleanCheckout'],
                                [$class: 'CloneOption', depth: 1, shallow: true]
                            ],
                            userRemoteConfigs: [[
                                url: env.QA_INFRA_REPO,
                            ]]
                        ])
                    }

                    logInfo('Repository checkout completed successfully')
                }
            }
        }

        stage('Configure Environment') {
            steps {
                script {
                    logInfo('Configuring deployment environment')

                    // Configure credentials and environment files
                    withCredentials(getCredentialsList()) {

                        // Setup SSH keys securely
                        setupSSHKeys()

                        // Generate environment file for container execution
                        generateEnvironmentFile()

                        // Build Docker image with proper tagging
                        buildDockerImage()

                        // Create shared volume
                        createSharedVolume()
                    }
                }
            }
        }

        stage('Deploy Infrastructure') {
            steps {
                script {
                    logInfo('Initializing airgap infrastructure deployment with OpenTofu')

                    // Configuration validation
                    def requiredVars = [
                        'QA_INFRA_WORK_PATH',
                        'TF_WORKSPACE',
                        'TERRAFORM_VARS_FILENAME',
                        'TERRAFORM_BACKEND_VARS_FILENAME',
                        'TERRAFORM_TIMEOUT'
                    ]

                    validateRequiredVariables(requiredVars)

                    // Enhanced timeout with reasonable defaults
                    def timeoutMinutes = env.TERRAFORM_TIMEOUT ?
                        Integer.parseInt(env.TERRAFORM_TIMEOUT) : 30

                    timeout(time: timeoutMinutes, unit: 'MINUTES') {
                        try {
                            // Pre-flight checks
                            validateInfrastructurePrerequisites()

                            // Infrastructure deployment with enhanced error handling
                            deployInfrastructure()

                            // Post-deployment validation
                            validateInfrastructureState()

                            logInfo('Infrastructure provisioned and validated successfully')
                        } catch (org.jenkinsci.plugins.workflow.steps.FlowInterruptedException e) {
                            logError("Infrastructure deployment timed out after ${timeoutMinutes} minutes")
                            logError("Timeout exception details: ${e.message}")
                            try {
                                archiveInfrastructureFailureArtifacts()
                                if (env.DESTROY_ON_FAILURE.toBoolean()) {
                                    logInfo('DESTROY_ON_FAILURE is true - attempting infrastructure cleanup for timeout')
                                    def cleanupScript = """
#!/bin/bash
set -e

# Source the external cleanup script
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap_timeout_cleanup.sh
                                    """
                                    executeScriptInContainer(cleanupScript)
                                    logInfo('Infrastructure cleanup attempted for timeout')
                                } else {
                                    logWarning('DESTROY_ON_FAILURE is false - manual cleanup required for timeout')
                                    logWarning('Please run the destroy pipeline or manually clean up resources in workspace: ${env.TF_WORKSPACE}')
                                }
                                cleanupContainersAndVolumes()
                            } catch (cleanupException) {
                                logError("Cleanup during timeout handling failed: ${cleanupException.message}")
                            }
                            throw e
                        } catch (Exception e) {
                            logError("Infrastructure setup failed: ${e.message}")
                            logError("Deployment failure exception details: ${e.message}")
                            try {
                                archiveInfrastructureFailureArtifacts()
                                if (env.DESTROY_ON_FAILURE.toBoolean()) {
                                    logInfo('DESTROY_ON_FAILURE is true - attempting infrastructure cleanup for deployment failure')
                                    def cleanupScript = """
#!/bin/bash
set -e

# Source the external cleanup script
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap_deployment_failure_cleanup.sh
                                    """
                                    executeScriptInContainer(cleanupScript)
                                    logInfo('Infrastructure cleanup attempted for deployment failure')
                                } else {
                                    logWarning('DESTROY_ON_FAILURE is false - manual cleanup required for deployment failure')
                                    logWarning('Please run the destroy pipeline or manually clean up resources in workspace: ${env.TF_WORKSPACE}')
                                }
                                cleanupContainersAndVolumes()
                            } catch (cleanupException) {
                                logError("Cleanup during deployment failure handling failed: ${cleanupException.message}")
                            }
                            throw e
                        }
                    }
                }
            }
            post {
                success {
                    script {
                        logInfo('Infrastructure deployment succeeded - archiving state')
                        archiveInfrastructureState()
                        // Additional immediate state backup for successful deployments
                        backupTerraformStateImmediately()
                    }
                }
                failure {
                    script {
                        logError('Infrastructure operations failed')
                        archiveInfrastructureFailureArtifacts()
                        // Still try to archive any partial state
                        archiveInfrastructureState()
                    }
                }
                always {
                    script {
                        // Final comprehensive state archival attempt
                        finalStateArchival()
                    }
                }
            }
        }
    }

    post {
        always {
            script {
                logInfo('Starting post-build cleanup')

                // Archive important artifacts including comprehensive tfstate backups
                archiveBuildArtifacts([
                    'kubeconfig.yaml',
                    'terraform.tfstate',
                    'terraform-state.tfstate',
                    'terraform-state-backup-*.tfstate',
                    'tfstate-backup-*.tfstate',
                    'terraform-state-build-*.tfstate',
                    'terraform-vars.tfvars',
                    'infrastructure-outputs.json',
                    'ansible-inventory.yml',
                    'ansible-logs.txt',
                    'deployment-summary.json'
                ])

                // Always cleanup containers and volumes
                try {
                    node {
                        cleanupContainersAndVolumes()
                    }
                } catch (Exception e) {
                    logError("Node context not available for cleanup: ${e.message}")
                    try {
                        cleanupContainersAndVolumes()
                    } catch (Exception cleanupException) {
                        logError("Cleanup failed: ${cleanupException.message}")
                    }
                }
            }
        }

        success {
            script {
                logInfo('Pipeline completed successfully')
                sendSlackNotification([
                    color: 'good',
                    message: "✅ Ansible Airgap setup succeeded for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }

        failure {
            script {
                logError('Pipeline failed')
                sendSlackNotification([
                    color: 'danger',
                    message: "❌ Ansible Airgap setup failed for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }

        unstable {
            script {
                logWarning('Pipeline completed with warnings')
                sendSlackNotification([
                    color: 'warning',
                    message: "⚠️ Ansible Airgap setup completed with warnings for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
    }
}

/**
 * HELPER FUNCTIONS
 * These functions are adapted from both Jenkinsfile.recurring and Jenkinsfile.airgap.rke2.improved
 */

// Logging utility functions
def logInfo(msg) {
    echo "[INFO] ${msg}"
}

def logError(msg) {
    echo "[ERROR] ${msg}"
}

def logWarning(msg) {
    echo "[WARNING] ${msg}"
}

// State extraction utility functions for backup
def extractStateFromVolume() {
    logInfo('Extracting terraform state from shared volume')
    sh """
    if [ -f /root/terraform.tfstate ]; then
        cp /root/terraform.tfstate ./terraform.tfstate || echo 'No state file in volume or copy failed'
        echo 'State extraction from volume attempted'
    else
        echo 'No state file found in shared volume'
    fi
    """
}

def extractStateFromContainer() {
    logInfo('Extracting terraform state from container backup')
    sh """
    if [ -f /root/terraform-state-primary.tfstate ]; then
        cp /root/terraform-state-primary.tfstate ./terraform-state.tfstate || echo 'Fallback state copy failed'
        echo 'Fallback state extraction from container attempted'
    else
        echo 'No fallback state found in container'
    fi
    """
}

def getShortJobName() {
    def jobName = "${env.JOB_NAME}"
    if (jobName.contains('/')) {
        def lastSlashIndex = jobName.lastIndexOf('/')
        return jobName.substring(lastSlashIndex + 1)
    }
    return jobName
}

def validateParameters() {
    // Validate required parameters
    if (!params.RKE2_VERSION) {
        error('RKE2_VERSION parameter is required')
    }
    if (!params.RANCHER_VERSION) {
        error('RANCHER_VERSION parameter is required')
    }
    if (!params.RANCHER_TEST_REPO_URL) {
        error('RANCHER_TEST_REPO_URL parameter is required')
    }
    if (!params.QA_INFRA_REPO_URL) {
        error('QA_INFRA_REPO_URL parameter is required')
    }

    logInfo('Parameters validated successfully')
}

def setupDynamicEnvironment() {
    env.RKE2_VERSION = params.RKE2_VERSION
    env.RANCHER_VERSION = params.RANCHER_VERSION

    logInfo('Dynamic environment configured')
    logInfo("RKE2 Version: ${env.RKE2_VERSION}")
    logInfo("Rancher Version: ${env.RANCHER_VERSION}")
}

def getCredentialsList() {
    return [
        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
        string(credentialsId: 'AWS_SSH_PEM_KEY', variable: 'AWS_SSH_PEM_KEY'),
        string(credentialsId: 'AWS_SSH_KEY_NAME', variable: 'AWS_SSH_KEY_NAME'),
        string(credentialsId: 'SLACK_WEBHOOK', variable: 'SLACK_WEBHOOK')
    ]
}

def validateConfigurationEnvironmentVariables() {
    logInfo('Validating configuration environment variables')

    def requiredVars = [
        'TERRAFORM_CONFIG': 'Terraform configuration content',
        'S3_BUCKET_NAME': 'S3 bucket name for backend',
        'S3_REGION': 'S3 bucket region for backend',
        'S3_KEY_PREFIX': 'S3 key prefix for backend state files',
        'ANSIBLE_VARIABLES': 'Ansible configuration content',
        'RKE2_VERSION': 'RKE2 version for deployment',
        'RANCHER_VERSION': 'Rancher version for deployment'
    ]

    def missingVars = []
    requiredVars.each { varName, description ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add("${varName} (${description})")
        }
    }

    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables for configuration:\n- ${missingVars.join('\n- ')}"
        logError(errorMsg)
        error(errorMsg)
    }

    logInfo('All required environment variables validated successfully')
}

def generateTofuConfiguration() {
    logInfo('Generating Terraform configuration')

    if (!env.TERRAFORM_CONFIG) {
        error('TERRAFORM_CONFIG environment variable is not set')
    }

    // Ensure S3 backend parameters are set
    if (!env.S3_BUCKET_NAME) { error('S3_BUCKET_NAME environment variable is not set') }
    if (!env.S3_REGION) { error('S3_REGION environment variable is not set') }
    if (!env.S3_KEY_PREFIX) { error('S3_KEY_PREFIX environment variable is not set') }

    sh 'mkdir -p qa-infra-automation/tofu/aws/modules/airgap'

    def terraformConfig = env.TERRAFORM_CONFIG

    // Replace variables in config (similar to Jenkinsfile.recurring pattern)
    terraformConfig = terraformConfig.replace('${AWS_SECRET_ACCESS_KEY}', env.AWS_SECRET_ACCESS_KEY ?: '')
    terraformConfig = terraformConfig.replace('${AWS_ACCESS_KEY_ID}', env.AWS_ACCESS_KEY_ID ?: '')
    terraformConfig = terraformConfig.replace('${AWS_REGION}', env.AWS_REGION ?: '')
    terraformConfig = terraformConfig.replace('${AWS_IAM_PROFILE}', env.AWS_IAM_PROFILE ?: '')
    terraformConfig = terraformConfig.replace('${AWS_VPC}', env.AWS_VPC ?: '')
    terraformConfig = terraformConfig.replace('${AWS_SECURITY_GROUPS}', env.AWS_SECURITY_GROUPS ?: '')
    terraformConfig = terraformConfig.replace('${HOSTNAME_PREFIX}', env.HOSTNAME_PREFIX ?: '')

    // Write the configuration file
    dir('./qa-infra-automation') {
        dir('./tofu/aws/modules/airgap') {
            writeFile file: env.TERRAFORM_VARS_FILENAME, text: terraformConfig
            logInfo("Terraform configuration written to: ${env.TERRAFORM_VARS_FILENAME}")

            // Generate backend.tfvars content from S3 parameters
            def backendVars = """
bucket = \"${env.S3_BUCKET_NAME}\"
key    = \"${env.S3_KEY_PREFIX}"
region = \"${env.S3_REGION}\"
"""
            writeFile file: env.TERRAFORM_BACKEND_VARS_FILENAME, text: backendVars
            logInfo("S3 backend configuration written to: ${env.TERRAFORM_BACKEND_VARS_FILENAME}")
        }
    }
}

def generateAnsibleConfiguration() {
    logInfo('Generating Ansible configuration')

    if (!env.ANSIBLE_VARIABLES) {
        error('ANSIBLE_VARIABLES environment variable is not set')
    }

    def ansibleVars = env.ANSIBLE_VARIABLES

    // Replace variables in config
    ansibleVars = ansibleVars.replace('${ADMIN_PASSWORD}', env.ADMIN_PASSWORD ?: '')
    ansibleVars = ansibleVars.replace('${HOSTNAME_PREFIX}', env.HOSTNAME_PREFIX ?: '')
    ansibleVars = ansibleVars.replace('${PRIVATE_REGISTRY_USERNAME}', env.PRIVATE_REGISTRY_USERNAME ?: '')
    ansibleVars = ansibleVars.replace('${PRIVATE_REGISTRY_PASSWORD}', env.PRIVATE_REGISTRY_PASSWORD ?: '')

    // Write the Ansible configuration file to the correct location for airgap deployment
    dir('./qa-infra-automation') {
        // Ensure the directory structure exists
        sh 'mkdir -p ansible/rke2/airgap/inventory/group_vars'

        // Write the group_vars/all.yml file
        writeFile file: 'ansible/rke2/airgap/inventory/group_vars/all.yml', text: ansibleVars
        logInfo('Ansible configuration written to: ansible/rke2/airgap/inventory/group_vars/all.yml')

        // Also create a copy in the original location for backward compatibility
        sh 'mkdir -p ansible'
        writeFile file: "ansible/${env.ANSIBLE_VARS_FILENAME}", text: ansibleVars
        logInfo("Ansible configuration also written to: ansible/${env.ANSIBLE_VARS_FILENAME} (backward compatibility)")
    }
}

def generateEnvironmentFile() {
    logInfo('Generating environment file for container execution')

    // Build environment content securely without direct interpolation of secrets
    def envLines = [
        '# Environment variables for infrastructure deployment containers',
        "TF_WORKSPACE=${env.TF_WORKSPACE}",
        "BUILD_NUMBER=${env.BUILD_NUMBER}",
        "JOB_NAME=${env.JOB_NAME}",
        "TERRAFORM_TIMEOUT=${env.TERRAFORM_TIMEOUT}",
        "ANSIBLE_TIMEOUT=${env.ANSIBLE_TIMEOUT}",
        "QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH}",
        "TERRAFORM_VARS_FILENAME=${env.TERRAFORM_VARS_FILENAME}",
        "ANSIBLE_VARS_FILENAME=${env.ANSIBLE_VARS_FILENAME}",
        "RKE2_VERSION=${env.RKE2_VERSION}",
        "RANCHER_VERSION=${env.RANCHER_VERSION}",
        "PRIVATE_REGISTRY_URL=${env.PRIVATE_REGISTRY_URL}",
        "PRIVATE_REGISTRY_USERNAME=${env.PRIVATE_REGISTRY_USERNAME}",
        '',
        '# AWS Credentials for OpenTofu (Standard AWS environment variables)'
    ]

    // Add credentials securely
    envLines.add('AWS_ACCESS_KEY_ID=' + env.AWS_ACCESS_KEY_ID)
    envLines.add('AWS_SECRET_ACCESS_KEY=' + env.AWS_SECRET_ACCESS_KEY)
    envLines.add('AWS_REGION=' + env.AWS_REGION)
    envLines.add('')
    envLines.add('# Terraform Variables for OpenTofu (TF_VAR_ prefix for automatic variable population)')
    envLines.add('TF_VAR_aws_access_key=' + env.AWS_ACCESS_KEY_ID)
    envLines.add('TF_VAR_aws_secret_access_key=' + env.AWS_SECRET_ACCESS_KEY)
    envLines.add('TF_VAR_aws_region=' + env.AWS_REGION)
    def envContent = envLines.join('\n')
    def envFilePath = "${pwd()}/${env.ENV_FILE}"
    writeFile file: env.ENV_FILE, text: envContent
    logInfo("Environment file created: ${env.ENV_FILE}")
    logInfo("Full path to environment file: ${envFilePath}")

    // Debug: Check if file exists (using Jenkins built-in method)
    def envFileExists = fileExists(env.ENV_FILE)
    logInfo("Environment file exists: ${envFileExists}")

    if (envFileExists) {
        // Use Jenkins readFile to get file size instead of File constructor
        try {
            def fileContent = readFile file: env.ENV_FILE
            def envFileSize = fileContent.length()
            logInfo("Environment file size: ${envFileSize} bytes")
        } catch (Exception e) {
            logInfo("Could not read environment file: ${e.message}")
        }
    }

    // Debug: Log the environment file content (without secrets)
    logInfo("Environment file contents (non-sensitive variables only):")
    envLines.each { line ->
        if (!line.contains('SECRET') && !line.contains('PASSWORD') && !line.contains('KEY')) {
            logInfo("  ${line}")
        } else {
            logInfo("  [REDACTED - contains sensitive data]")
        }
    }

    // Debug: Also log the raw environment variable values
    logInfo("Raw environment variable values:")
    logInfo("  TERRAFORM_VARS_FILENAME=${env.TERRAFORM_VARS_FILENAME}")
    logInfo("  QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH}")
}

def setupSSHKeys() {
    if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
        logInfo('Setting up SSH keys')

        dir('./tests/.ssh') {
            def decodedKey = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
            writeFile file: env.AWS_SSH_KEY_NAME, text: decodedKey
            sh "chmod 600 ${env.AWS_SSH_KEY_NAME}"
        }

        logInfo('SSH keys configured successfully')
    }
}

def buildDockerImage() {
    logInfo("Building Docker image: ${env.IMAGE_NAME}")

    dir('./') {
        sh './tests/validation/configure.sh'
        sh """
            docker build . \
                -f ./tests/validation/Dockerfile.tofu.e2e \
                -t ${env.IMAGE_NAME} \
                --build-arg BUILD_DATE=\$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
                --build-arg VCS_REF=\$(git rev-parse --short HEAD) \
                --label "pipeline.build.number=${env.BUILD_NUMBER}" \
                --label "pipeline.job.name=${env.JOB_NAME}"
        """
    }

    logInfo('Docker image built successfully')
}

def createSharedVolume() {
    logInfo("Creating shared volume: ${env.VALIDATION_VOLUME}")
    sh "docker volume create --name ${env.VALIDATION_VOLUME}"
}

def executeScriptInContainer(scriptContent, extraEnv = [:], skipWorkspaceEnv = false) {
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-script-${timestamp}"
    def scriptFile = "docker-script-${timestamp}.sh"

    writeFile file: scriptFile, text: scriptContent

    def envVars = ''
    extraEnv.each { key, value ->
        envVars += " -e ${key}=${value}"
    }

    def workspaceEnv = skipWorkspaceEnv ? '' : " -e TF_WORKSPACE=${env.TF_WORKSPACE}"

    // Debug: Check if environment file exists right before docker command
    def envFileExistsBeforeDocker = fileExists(env.ENV_FILE)
    def envFilePathBeforeDocker = "${pwd()}/${env.ENV_FILE}"
    logInfo("Environment file check before Docker command:")
    logInfo("  File exists: ${envFileExistsBeforeDocker}")
    logInfo("  File path: ${envFilePathBeforeDocker}")

    if (envFileExistsBeforeDocker) {
        try {
            def fileContent = readFile file: env.ENV_FILE
            def fileSize = fileContent.length()
            logInfo("  File size: ${fileSize} bytes")
            logInfo("  File contains TERRAFORM_VARS_FILENAME: ${fileContent.contains('TERRAFORM_VARS_FILENAME')}")
        } catch (Exception e) {
            logInfo("  Could not read file: ${e.message}")
        }
    }

    // Debug: Show the exact docker command being executed
    def dockerCmd = """
        docker run --rm \\
            -v ${env.VALIDATION_VOLUME}:/root \\
            -v ${pwd()}/qa-infra-automation:/root/go/src/github.com/rancher/qa-infra-automation \\
            -v ${pwd()}/${scriptFile}:/tmp/script.sh \\
            -v ${envFilePathBeforeDocker}:/tmp/.env \\
            --name ${containerName} \\
            -t --env-file /tmp/.env \\
            -e QA_INFRA_WORK_PATH=/root/go/src/github.com/rancher/qa-infra-automation${workspaceEnv} \\
            ${envVars} \\
            ${env.IMAGE_NAME} \\
            sh /tmp/script.sh
    """

    logInfo("Executing docker command:")
    logInfo(dockerCmd)

    sh dockerCmd

    sh "rm -f ${scriptFile}"
}

def cleanupContainersAndVolumes() {
    logInfo('Cleaning up Docker containers and volumes')

    try {
        if (env.NODE_NAME) {
            sh """
                # Stop and remove any containers with our naming pattern
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker stop || true
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker rm -v || true

                # Remove the Docker image
                docker rmi -f ${env.IMAGE_NAME} || true

                # Remove the shared volume
                docker volume rm -f ${env.VALIDATION_VOLUME} || true

                # Clean up any dangling images and volumes
                docker system prune -f || true
            """
        } else {
            logWarning('No node context available for Docker cleanup')
        }
    } catch (Exception e) {
        logError("Docker cleanup failed: ${e.message}")
    }
}

def archiveBuildArtifacts(artifacts) {
    try {
        archiveArtifacts artifacts: artifacts.join(','), allowEmptyArchive: true
        logInfo("Artifacts archived: ${artifacts.join(', ')}")
    } catch (Exception e) {
        logError("Failed to archive artifacts: ${e.message}")
    }
}

def sendSlackNotification(config) {
    if (env.SLACK_WEBHOOK) {
        try {
            def payload = [
                channel: '#rancher-qa',
                username: 'Jenkins',
                color: config.color,
                title: 'Ansible Airgap Setup Pipeline',
                message: config.message,
                fields: [
                    [title: 'Job', value: env.JOB_NAME, short: true],
                    [title: 'Build', value: env.BUILD_NUMBER, short: true],
                    [title: 'RKE2 Version', value: env.RKE2_VERSION, short: true],
                    [title: 'Rancher Version', value: env.RANCHER_VERSION, short: true]
                ]
            ]

            httpRequest(
                httpMode: 'POST',
                url: env.SLACK_WEBHOOK,
                contentType: 'APPLICATION_JSON',
                requestBody: groovy.json.JsonOutput.toJson(payload)
            )

            logInfo('Slack notification sent successfully')
        } catch (Exception e) {
            logError("Failed to send Slack notification: ${e.message}")
        }
    }
}

/**
 * INFRASTRUCTURE MANAGEMENT FUNCTIONS
 * These are adapted from Jenkinsfile.airgap.rke2.improved
 */

def validateRequiredVariables(requiredVars) {
    logInfo('Validating required environment variables')

    def missingVars = []
    requiredVars.each { varName ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add(varName)
        }
    }

    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables: ${missingVars.join(', ')}"
        logError(errorMsg)
        error(errorMsg)
    }

    logInfo('All required variables validated successfully')
}

def validateInfrastructurePrerequisites() {
    logInfo('Validating infrastructure prerequisites')

    def prerequisiteScript = """
#!/bin/bash
set -e

# Debug: Print environment variables
echo "Debug: QA_INFRA_WORK_PATH=\${QA_INFRA_WORK_PATH}"
echo "Debug: TERRAFORM_VARS_FILENAME=\${TERRAFORM_VARS_FILENAME}"

# Source the external prerequisites validation script
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap_validate_prerequisites.sh
 """

    try {
        executeScriptInContainer(prerequisiteScript)
        logInfo('All infrastructure prerequisites validated')
    } catch (Exception e) {
        def errorMsg = "Infrastructure prerequisites validation failed: ${e.message}"
        logError(errorMsg)
        error(errorMsg)
    }
}

def deployInfrastructure() {
    logInfo('Starting infrastructure deployment process')

    // Step 1: Generate Tofu config (must be first to create required files)
    generateTofuConfiguration()

    // Step 2: Validate infrastructure prerequisites (now files exist)
    validateInfrastructurePrerequisites()

    // Step 3: Initialize OpenTofu
    initializeOpenTofu()

    // Step 4: Manage workspace
    manageWorkspace()

    // Step 5: Plan infrastructure changes
    planInfrastructure()

    // Step 6: Apply infrastructure
    applyInfrastructure()

    logInfo('Infrastructure deployment completed successfully')
}

def validateInfrastructureState() {
    logInfo('Validating infrastructure state after deployment')

    def validationScript = """
#!/bin/bash
set -e

# Source the external infrastructure validation script
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap_validate_infrastructure.sh
     """

    executeScriptInContainer(validationScript)
    logInfo('Infrastructure state validated successfully')
}

def initializeOpenTofu() {
    logInfo('Initializing OpenTofu with S3 backend')

    def initScript = """
#!/bin/bash
set -e

# Source the external OpenTofu initialization script
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap_initialize_tofu.sh
     """

    executeScriptInContainer(initScript, [:], true)
}

def manageWorkspace() {
    logInfo("Managing OpenTofu workspace: ${env.TF_WORKSPACE}")

    def workspaceScript = """
#!/bin/bash
set -e

# Source the external workspace management script
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap_manage_workspace.sh
     """

    executeScriptInContainer(workspaceScript)
}

def planInfrastructure() {
    logInfo('Planning infrastructure changes')

    def planScript = """
#!/bin/bash
set -e

# Source the external plan infrastructure script
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap_plan_infrastructure.sh
     """

    executeScriptInContainer(planScript)
}

def applyInfrastructure() {
    logInfo('Applying infrastructure configuration')

    def applyScript = """
#!/bin/bash
set -e

# Source the external apply infrastructure script
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap_apply_infrastructure.sh
     """

    executeScriptInContainer(applyScript)

    // Extract files to shared volume after successful apply (redundant but ensuring)
    logInfo('Extracting files after apply for persistence')
    sh """
    if [ -f qa-infra-automation/tofu/aws/modules/airgap/terraform.tfstate ]; then
        cp qa-infra-automation/tofu/aws/modules/airgap/terraform.tfstate ./
    fi
    """
}

def backupTerraformStateImmediately() {
    logInfo('Creating immediate backup of terraform state after successful deployment')

    try {
        // Extract state immediately for successful deployments
        extractStateFromVolume()
        extractStateFromContainer()

        def timestamp = new Date().format('yyyyMMdd-HHmmss')
        def backupName = "terraform-state-build-${env.BUILD_NUMBER}-${timestamp}.tfstate"

        def backupScript = """
#!/bin/bash
set -e

# Source the external backup script
BACKUP_NAME="${backupName}"
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap_backup_state.sh
        """.stripIndent()

        executeScriptInContainer(backupScript)

        // Archive the immediate backup
        archiveArtifacts artifacts: backupName, allowEmptyArchive: true
        logInfo('Immediate terraform state backup completed')
    } catch (Exception e) {
        logError("Immediate backup failed: ${e.message}")
    }
}

// Infrastructure state archival functions
def archiveInfrastructureState() {
    logInfo('Archiving infrastructure state')
    try {
        // Extract current state
        extractStateFromVolume()
        extractStateFromContainer()

        def timestamp = new Date().format('yyyyMMdd-HHmmss')
        def stateName = "infrastructure-state-${env.BUILD_NUMBER}-${timestamp}.tfstate"

        sh """
            if [ -f terraform.tfstate ]; then
                cp terraform.tfstate ${stateName}
                echo "State archived: ${stateName}"
            elif [ -f terraform-state.tfstate ]; then
                cp terraform-state.tfstate ${stateName}
                echo "State archived from fallback: ${stateName}"
            else
                echo "No state file available for archival"
            fi
        """

        archiveArtifacts artifacts: stateName, allowEmptyArchive: true
        logInfo('Infrastructure state archived successfully')
    } catch (Exception e) {
        logError("State archival failed: ${e.message}")
    }
}

def archiveInfrastructureFailureArtifacts() {
    logInfo('Archiving failure artifacts')
    try {
        // Archive partial state and logs
        archiveInfrastructureState()
        archiveBuildArtifacts([
            'tfplan-backup',
            '*.log',
            'ansible-logs.txt',
            'error-*.txt'
        ])
        logInfo('Failure artifacts archived')
    } catch (Exception e) {
        logError("Failure artifacts archival failed: ${e.message}")
    }
}

def finalStateArchival() {
    logInfo('Performing final comprehensive state archival')
    try {
        archiveInfrastructureState()
        // Additional final artifacts
        archiveBuildArtifacts([
            'infrastructure-outputs.json',
            '${env.TERRAFORM_VARS_FILENAME}',
            'ansible-inventory.yml',
            'deployment-summary.json'
        ])
        logInfo('Final state archival completed')
    } catch (Exception e) {
        logError("Final archival failed: ${e.message}")
    }
}
