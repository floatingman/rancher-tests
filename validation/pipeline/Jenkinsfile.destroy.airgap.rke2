#!/usr/bin/env groovy

/**
 * Infrastructure Destruction Jenkinsfile for Airgap RKE2
 *
 * This pipeline is designed to safely destroy infrastructure created by
 * the main airgap RKE2 deployment pipeline. It retrives Terraform state
 * from S3 backend and performs controlled destruction.
 */
 
// ========================================
// CONSTANTS AND CONFIGURATION (parity with setup pipeline)
// ========================================
class PipelineConfig {
    static final String DEFAULT_HOSTNAME_PREFIX = 'airgap-ansible-jenkins'
    static final String DEFAULT_RKE2_VERSION = 'v1.28.8+rke2r1'
    static final String DEFAULT_RANCHER_VERSION = 'v2.9-head'
    static final String DEFAULT_RANCHER_TEST_REPO = 'https://github.com/rancher/tests.git'
    static final String DEFAULT_QA_INFRA_REPO = 'https://github.com/rancher/qa-infra-automation.git'
    static final String DEFAULT_S3_BUCKET = 'rancher-terraform-state'
    static final String DEFAULT_S3_REGION = 'us-east-1'
    static final String CONTAINER_NAME_PREFIX = 'rancher-ansible-airgap'
    static final String SHARED_VOLUME_PREFIX = 'validation-volume'
    static final String DOCKER_BUILD_CONTEXT = '.'
    static final String DOCKERFILE_PATH = 'tests/validation/Dockerfile.tofu.e2e'
    static final int TERRAFORM_TIMEOUT_MINUTES = 60
    static final int ANSIBLE_TIMEOUT_MINUTES = 90
    static final int VALIDATION_TIMEOUT_MINUTES = 30
    static final String LOG_PREFIX_INFO = '[INFO]'
    static final String LOG_PREFIX_ERROR = '[ERROR]'
    static final String LOG_PREFIX_WARNING = '[WARNING]'
}

// Ensure lazy loader binding variables exist before the pipeline block.
// Some Jenkins evaluations reference helpers early; declare refs up-front
__ciHelpersRef = null
__ciAirgapRef = null

pipeline {
    agent any

    // Global pipeline options
    options {
        buildDiscarder(logRotator(numToKeepStr: '10'))
        timeout(time: 2, unit: 'HOURS')
        timestamps()
        ansiColor('xterm')
        skipStagesAfterUnstable()
    }

    parameters {
        string(
            name: 'TARGET_WORKSPACE',
            defaultValue: '',
            description: 'Terraform workspace to destroy (e.g., jenkins_airgap_ansible_workspace_123)'
        )
        string(
            name: 'RANCHER_TEST_REPO_URL',
            defaultValue: 'https://github.com/rancher/tests',
            description: 'URL of rancher/tests repository'
        )
        string(
            name: 'RANCHER_TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of rancher/tests repository'
        )
        string(
            name: 'QA_INFRA_REPO_URL',
            defaultValue: 'https://github.com/rancher/qa-infra-automation',
            description: 'URL of qa-infra-automation repository'
        )
        string(
            name: 'QA_INFRA_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of qa-infra-automation repository'
        )
        string(
            name: 'S3_BUCKET_NAME',
            defaultValue: 'jenkins-terraform-state-storage',
            description: 'S3 bucket name where Terraform state is stored'
        )
        string(
            name: 'S3_KEY_PREFIX',
            defaultValue: 'jenkins-airgap-rke2/terraform.tfstate',
            description: 'S3 key prefix for the Terraform state files'
        )
        string(
            name: 'S3_REGION',
            defaultValue: 'us-east-2',
            description: 'AWS region where the S3 bucket is located'
        )
    }

    environment {
        // Default S3 configuration - use parameters with fallbacks
        S3_BUCKET_NAME = "${params.S3_BUCKET_NAME ?: 'jenkins-terraform-state-storage'}"
        S3_KEY_PREFIX = "${params.S3_KEY_PREFIX ?: 'jenkins-airgap-rke2/terraform.tfstate'}"
        S3_REGION = "${params.S3_REGION ?: 'us-east-2'}"
        AWS_REGION = "${params.S3_REGION ?: 'us-east-2'}"

        // Repository configurations
        RANCHER_TEST_REPO_URL = "${params.RANCHER_TEST_REPO_URL ?: 'https://github.com/rancher/tests'}"
        QA_INFRA_REPO = "${params.QA_INFRA_REPO_URL ?: 'https://github.com/rancher/qa-infra-automation'}"
        QA_INFRA_WORK_PATH = '/root/go/src/github.com/rancher/qa-infra-automation'
        ROOT_PATH = '/root/go/src/github.com/rancher/tests/'

        // Computed values
        JOB_SHORT_NAME = "${getShortJobName()}"
        BUILD_CONTAINER_NAME = "${JOB_SHORT_NAME}${BUILD_NUMBER}-destroy"
        IMAGE_NAME = "rancher-destroy-${JOB_SHORT_NAME}${BUILD_NUMBER}"
        VALIDATION_VOLUME = "DestroySharedVolume-${JOB_SHORT_NAME}${BUILD_NUMBER}"

        // Target workspace from parameters
        TARGET_WORKSPACE = "${params.TARGET_WORKSPACE}"
        TF_WORKSPACE = "${params.TARGET_WORKSPACE}"

        // Timeouts (in minutes)
        TERRAFORM_TIMEOUT = '30'

        // Configuration files
        TERRAFORM_VARS_FILENAME = 'cluster.tfvars'
        TERRAFORM_BACKEND_VARS_FILENAME = 'backend.tfvars'
        ENV_FILE = '.env'
    }

    stages {
        stage('Initialize Pipeline') {
            steps {
                script {
                    logInfo('Initializing pipeline')
                    // Validate parameters and environment
                    validateParameters()

                    // Clean workspace
                    deleteDir()

                    logInfo('Pipeline initialized successfully')
                    logInfo("Build container: ${env.BUILD_CONTAINER_NAME}")
                    logInfo("Docker image: ${env.IMAGE_NAME}")
                    logInfo("Volume: ${env.VALIDATION_VOLUME}")
                }
            }
        }

        stage('Checkout Repositories') {
            steps {
                script {
                    logInfo('Checking out source repositories')

                    // Checkout Rancher Tests Repository
                    dir('./tests') {
                        logInfo("Cloning rancher tests repository from ${env.RANCHER_TEST_REPO_URL}")
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.RANCHER_TEST_REPO_BRANCH}"]],
                            extensions: [
                                [$class: 'CleanCheckout'],
                                [$class: 'CloneOption', depth: 1, shallow: true]
                            ],
                            userRemoteConfigs: [[
                                url: env.RANCHER_TEST_REPO_URL,
                            ]]
                        ])
                    }

                    // Checkout QA Infrastructure Repository
                    dir('./qa-infra-automation') {
                        logInfo("Cloning qa-infra-automation repository from ${env.QA_INFRA_REPO}")
                        checkout([
                            $class: 'GitSCM',
                            branches: [[name: "*/${params.QA_INFRA_REPO_BRANCH}"]],
                            extensions: [
                                [$class: 'CleanCheckout'],
                                [$class: 'CloneOption', depth: 1, shallow: true]
                            ],
                            userRemoteConfigs: [[
                                url: env.QA_INFRA_REPO,
                            ]]
                        ])
                    }

                    logInfo('Repository checkout completed successfully')
                }
            }
        }

        stage('Configure Environment') {
            steps {
                script {
                    logInfo('Configuring deployment environment')

                    // Configure credentials and environment files
                    withCredentials(getCredentialsList()) {
                        // Generate environment file with AWS credentials
                        generateDestructionEnvironmentFile()

                        // Setup SSH keys securely
                        setupSSHKeys()

                        // Build Docker image with proper tagging
                        buildDockerImage()

                        // Create shared volume
                        createSharedVolume()
                    }
                }
            }
        }

        stage('Infrastructure Destruction') {
            steps {
                script {
                    logInfo('Performing infrastructure destruction using consolidated script')

                    // Configuration validation
                    def requiredVars = [
                        'QA_INFRA_WORK_PATH',
                        'TF_WORKSPACE',
                        'TERRAFORM_VARS_FILENAME',
                        'TERRAFORM_BACKEND_VARS_FILENAME',
                        'TERRAFORM_TIMEOUT'
                    ]
                    validateRequiredVariables(requiredVars)

                    // Generate and copy backend configuration before running destroy
                    logInfo('Generating OpenTofu backend configuration')
                    generateTofuBackendConfiguration()
          
                    logInfo('Initializing OpenTofu with backend configuration')
                    initializeOpenTofu()

                    // Enhanced timeout with reasonable defaults
                    def timeoutMinutes = env.TERRAFORM_TIMEOUT ?
                        Integer.parseInt(env.TERRAFORM_TIMEOUT) : 30

                    timeout(time: timeoutMinutes, unit: 'MINUTES') {
                        try {
                            // Infrastructure destruction using consolidated script
                            destroyInfrastructureWithConsolidatedScript()

                            logInfo('Infrastructure destruction process completed.')
                            archiveDestructionResults()
                        }
            catch (org.jenkinsci.plugins.workflow.steps.FlowInterruptedException e) {
                            logError("Infrastructure destruction timed out after ${timeoutMinutes} minutes")
                            logError("Timeout exception details: ${e.message}")
                            try {
                                archiveDestructionFailureArtifacts()
              } catch (Exception cleanupException) {
                                logError("Failed to perform infrastructure cleanup: ${cleanupException.message}")
                            }
            } catch (Exception e) {
                            logError("Infrastructure destruction failed: ${e.message}")
                            archiveDestructionFailureArtifacts()
                            throw e
            }
                    }
                }
            }
            post {
                failure {
                    script {
                        logError('Infrastructure destruction operations failed')
                        archiveDestructionFailureArtifacts()
                    }
                }
            }
        }
    }
    post {
        always {
            script {
                logInfo('Starting post-destruction cleanup')

                // Archive important artifacts
                archiveBuildArtifacts([
                    'destruction-plan.txt',
                    'destruction-summary.json',
                    'destruction-logs.txt'
                ])

                // Cleanup containers and volumes
                cleanupContainersAndVolumes()
            }
        }

        success {
            script {
                logInfo('Destruction pipeline completed successfully')
        
                // Clean up S3 workspace directory after successful destruction
                cleanupS3WorkspaceDirectory()
            }
        }

        failure {
            script {
                logError('Destruction pipeline failed')
            }
        }

        aborted {
            script {
                logWarning('Destruction pipeline was aborted')
            }
        }
    }
}

/**
 * CONSOLIDATED SCRIPT HELPER FUNCTIONS
 */
 
 // Lazy loader for CI helpers (mirrors pattern in setup Jenkinsfile)
 __ciHelpersRef = null
def ciHelpers() {
    if (__ciHelpersRef == null) {
        def candidates = [
             'validation/pipeline/ci/helpers.groovy',
             'tests/validation/pipeline/ci/helpers.groovy'
         ]
        for (p in candidates) {
            try {
                if (fileExists(p)) { __ciHelpersRef = load(p); break }
             } catch (ignored) {}
            }
        }
    return __ciHelpersRef
    }
 
 // Lazy loader for CI airgap steps (parity with setup pipeline)
 __ciAirgapRef = null
def ciAirgap() {
    if (__ciAirgapRef == null) {
        def candidates = [
             'validation/pipeline/ci/airgap.groovy',
             'tests/validation/pipeline/ci/airgap.groovy'
         ]
        for (p in candidates) {
            try {
                if (fileExists(p)) { __ciAirgapRef = load(p); break }
             } catch (ignored) {}
            }
        }
    return __ciAirgapRef
    }

def destroyInfrastructureWithConsolidatedScript() {
    logInfo('Executing infrastructure destruction with consolidated script')

    def scriptContent = '''
#!/bin/bash
set -e
# Source the consolidated infrastructure cleanup script
source /root/go/src/github.com/rancher/tests/validation/pipeline/scripts/airgap/airgap_infrastructure_cleanup.sh
'''

    // Pass required environment variables to container
    def extraEnvVars = [
        'CLEANUP_WORKSPACE': 'true',
        'DESTROY_ON_FAILURE': 'true'
    ]

    executeScriptInContainer(scriptContent, extraEnvVars)
}

/**
 * DESTRUCTION-SPECIFIC HELPER FUNCTIONS
 */

def validateParameters() {
    // Validate required parameters
    if (!params.TARGET_WORKSPACE || params.TARGET_WORKSPACE.trim().isEmpty()) {
        error('TARGET_WORKSPACE parameter is required for destruction')
    }
    if (!params.RANCHER_TEST_REPO_URL) {
        error('RANCHER_TEST_REPO_URL parameter is required')
    }
    if (!params.QA_INFRA_REPO_URL) {
        error('QA_INFRA_REPO_URL parameter is required')
    }

    logInfo('Parameters validated successfully')
    logInfo("Target workspace: ${params.TARGET_WORKSPACE}")
}

def validateRequiredVariables(requiredVars) {
    logInfo('Validating required environment variables')

    def missingVars = []
    requiredVars.each { varName ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add(varName)
        }
    }

    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables: ${missingVars.join(', ')}"
        logError(errorMsg)
        error(errorMsg)
    }

    logInfo('All required variables validated successfully')
}

def validateInfrastructurePrerequisites() {
    logInfo('Validating infrastructure prerequisites')

    try {
        def scriptPath = 'tests/validation/pipeline/scripts/airgap/tofu_validate_prerequisites.sh'
        def scriptContent = readFile(file: scriptPath)
        executeScriptInContainer(scriptContent)
        logInfo('All infrastructure prerequisites validated')
    } catch (Exception e) {
        def errorMsg = "Infrastructure prerequisites validation failed: ${e.message}"
        logError(errorMsg)
        error(errorMsg)
    }
}


def getShortJobName() {
    def jobName = "${env.JOB_NAME}"
    if (jobName.contains('/')) {
        def lastSlashIndex = jobName.lastIndexOf('/')
        return jobName.substring(lastSlashIndex + 1)
    }
    return jobName
}

def getCredentialsList() {
    return [
        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
    ]
}

def generateDestructionEnvironmentFile() {
    logInfo('Generating environment file for destruction containers')

    // Debug logging for S3 variables
    logInfo("S3_BUCKET_NAME: '${env.S3_BUCKET_NAME}'")
    logInfo("S3_KEY_PREFIX: '${env.S3_KEY_PREFIX}'")
    logInfo("S3_REGION: '${env.S3_REGION}'")
    logInfo("AWS_REGION: '${env.AWS_REGION}'")

    // Ensure S3 variables have values by using parameter fallbacks
    def s3BucketName = env.S3_BUCKET_NAME ?: params.S3_BUCKET_NAME ?: 'jenkins-terraform-state-storage'
    def s3KeyPrefix = env.S3_KEY_PREFIX ?: params.S3_KEY_PREFIX ?: 'jenkins-airgap-rke2/terraform.tfstate'
    def s3Region = env.S3_REGION ?: params.S3_REGION ?: 'us-east-2'
    def awsRegion = env.AWS_REGION ?: params.S3_REGION ?: 'us-east-2'

    logInfo("Using S3_BUCKET_NAME: '${s3BucketName}'")
    logInfo("Using S3_KEY_PREFIX: '${s3KeyPrefix}'")
    logInfo("Using S3_REGION: '${s3Region}'")
    logInfo("Using AWS_REGION: '${awsRegion}'")

    // Build environment content securely WITHOUT credentials
    // Credentials will be passed via withCredentials block
    def envLines = [
        '# Environment variables for infrastructure destruction containers',
        '# NOTE: All sensitive credentials are passed via Jenkins withCredentials block for security',
        "TARGET_WORKSPACE=${env.TARGET_WORKSPACE}",
        "BUILD_NUMBER=${env.BUILD_NUMBER}",
        "JOB_NAME=${env.JOB_NAME}",
        "QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH}",
        "TERRAFORM_VARS_FILENAME=${env.TERRAFORM_VARS_FILENAME}",
        "S3_BUCKET_NAME=${s3BucketName}",
        "S3_KEY_PREFIX=${s3KeyPrefix}",
        "S3_REGION=${s3Region}",
        "AWS_REGION=${awsRegion}",
        '',
        '# AWS Credentials excluded - will be passed via withCredentials',
        '',
        '# Terraform Variables for OpenTofu (TF_VAR_ prefix for automatic variable population)',
        'TF_VAR_aws_region=' + awsRegion
    ]

    def envContent = envLines.join('\n')
    writeFile file: env.ENV_FILE, text: envContent
    logInfo("Environment file created: ${env.ENV_FILE}")

    // Verify the file was created correctly
    def fileContent = readFile file: env.ENV_FILE
    logInfo('Environment file content preview:')
    def lines = fileContent.split('\n')
    for (int i = 0; i < Math.min(10, lines.size()); i++) {
        logInfo(lines[i])
    }
}

def setupSSHKeys() {
    if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
        logInfo('Setting up SSH keys')

        dir('./tests/.ssh') {
            def decodedKey = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
            writeFile file: env.AWS_SSH_KEY_NAME, text: decodedKey
            sh "chmod 600 ${env.AWS_SSH_KEY_NAME}"
        }

        logInfo('SSH keys configured successfully')
    }
}

def buildDockerImage() {
    // Prefer library implementation to keep Jenkinsfiles thin and consistent
    try {
        def lib = ciAirgap()
        if (lib) {
            lib.buildDockerImage(this)
            return
        }
    } catch (ignored) {
    // fall back to local implementation if library not available
    }
 
    logInfo("Building Docker image: ${env.IMAGE_NAME}")
 
    // Ensure required directories exist before Docker build
    sh 'ls -la ./tests || echo "tests directory not found"'
    sh 'ls -la ./qa-infra-automation || echo "qa-infra-automation directory not found"'
 
    // Verify the Dockerfile exists
    sh 'ls -la ./tests/validation/Dockerfile.tofu.e2e || echo "Dockerfile not found"'
 
    dir('./') {
        sh './tests/validation/configure.sh > /dev/null 2>&1'
 
        // Execute shell commands separately to avoid Jenkins parsing issues
        def buildDate = sh(script: "date -u +'%Y-%m-%dT%H:%M:%SZ'", returnStdout: true).trim()
        def vcsRef = sh(script: 'git rev-parse --short HEAD 2>/dev/null || echo "unknown"', returnStdout: true).trim()
 
        sh """
            docker build . \\
                -f ./tests/validation/Dockerfile.tofu.e2e \\
                -t ${env.IMAGE_NAME} \\
                --build-arg BUILD_DATE=${buildDate} \\
                --build-arg VCS_REF=${vcsRef} \\
                --label "pipeline.build.number=${env.BUILD_NUMBER}" \\
                --label "pipeline.job.name=${env.JOB_NAME}" \\
                --quiet
        """
    }
 
    logInfo('Docker image built successfully')
}

def createSharedVolume() {
    // Strict: delegate to library; fail fast if library missing
    def lib = ciAirgap()
    try {
        if (lib) {
            lib.createSharedVolume(this)
            return
        }
    } catch (groovy.lang.MissingMethodException | java.lang.NoSuchMethodError ignored) {
    // will surface unified error below
    } catch (Exception e) {
        error("Library createSharedVolume invocation failed: ${e.message}")
    }
    error('Required library function ci/airgap.groovy::createSharedVolume not available — aborting. Ensure validation/pipeline/ci/airgap.groovy is present and exported.')
}

def executeScriptInContainer(scriptContent, extraEnv = [:], skipWorkspaceEnv = false) {
    // Delegate execution to CI helpers to centralize credential handling and docker command construction
    def helpers = ciHelpers()
    if (helpers) {
        return helpers.executeScriptInContainer(this, scriptContent, extraEnv, skipWorkspaceEnv)
    }
    // Fallback to local implementation if helpers not available (preserve behavior)
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-script-${timestamp}"
    def scriptFile = "docker-script-${timestamp}.sh"
    def credentialEnvFile = null

    writeFile file: scriptFile, text: scriptContent

    try {
        def envVars = ''
        extraEnv.each { key, value ->
            envVars += " -e ${key}=${value}"
        }

        def workspaceEnv = skipWorkspaceEnv ? '' : " -e TF_WORKSPACE=${env.TF_WORKSPACE}"

        def s3BucketName = env.S3_BUCKET_NAME ?: params.S3_BUCKET_NAME ?: 'jenkins-terraform-state-storage'
        def s3KeyPrefix = env.S3_KEY_PREFIX ?: params.S3_KEY_PREFIX ?: 'jenkins-airgap-rke2/terraform.tfstate'
        def s3Region = env.S3_REGION ?: params.S3_REGION ?: 'us-east-2'
        def awsRegion = env.AWS_REGION ?: params.S3_REGION ?: 'us-east-2'

        withCredentials([
        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
      ]) {
            credentialEnvFile = createCredentialEnvironmentFile()

            def dockerCmd = """
                docker run --rm \\
                    -v ${env.VALIDATION_VOLUME}:/root \\
                    -v ${pwd()}/${scriptFile}:/tmp/script.sh \\
                    --name ${containerName} \\
                    -t --env-file ${env.ENV_FILE} \\
                    -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \\
                    -e TF_WORKSPACE=${env.TF_WORKSPACE} \\
                    -e TERRAFORM_VARS_FILENAME=${env.TERRAFORM_VARS_FILENAME} \\
                    -e S3_BUCKET_NAME="${s3BucketName}" \\
                    -e S3_KEY_PREFIX="${s3KeyPrefix}" \\
                    -e S3_REGION="${s3Region}" \\
                    -e AWS_REGION="${awsRegion}" ${envVars} \\
                    ${env.IMAGE_NAME} \\
                    sh /tmp/script.sh
            """

            def modifiedDockerCmd = addCredentialEnvFileToDockerCommand(dockerCmd, credentialEnvFile)

            sh modifiedDockerCmd
      }
      } catch (Exception e) {
        logError("Script execution failed: ${e.message}")
        throw e
      } finally {
        sh "rm -f ${scriptFile}"

        try {
            if (credentialEnvFile && fileExists(credentialEnvFile)) {
                sh "shred -vfz -n 3 ${credentialEnvFile} 2>/dev/null || rm -f ${credentialEnvFile}"
                logInfo("Credential environment file securely shredded")
            }
      } catch (Exception cleanupException) {
            logWarning("Failed to cleanup credential environment file: ${cleanupException.message}")
        }
    }
}



def generateTofuConfiguration() {
    // Strict: delegate to library; fail fast if library missing
    def lib = ciAirgap()
    try {
        if (lib) {
            lib.generateTofuConfiguration(this)
            return
        }
    } catch (groovy.lang.MissingMethodException | java.lang.NoSuchMethodError ignored) {
    // fallthrough to unified error below
    } catch (Exception e) {
        error("Library generateTofuConfiguration invocation failed: ${e.message}")
    }
    error('Required library function ci/airgap.groovy::generateTofuConfiguration not available — aborting. Ensure validation/pipeline/ci/airgap.groovy is present and exported.')
}

def generateTofuBackendConfiguration() {
    logInfo('Generating Tofu configuration')

    // Ensure S3 backend parameters are set
    if (!env.S3_BUCKET_NAME) { error('S3_BUCKET_NAME environment variable is not set') }
    if (!env.S3_REGION) { error('S3_REGION environment variable is not set') }
    if (!env.S3_KEY_PREFIX) { error('S3_KEY_PREFIX environment variable is not set') }

    logInfo("S3 Backend Configuration:")
    logInfo("  Bucket: ${env.S3_BUCKET_NAME}")
    logInfo("  Key: ${env.S3_KEY_PREFIX}")
    logInfo("  Region: ${env.S3_REGION}")

    sh 'mkdir -p qa-infra-automation/tofu/aws/modules/airgap'

    // Write both backend.tf and backend.tfvars files to host
    def hostBackendPath = "./qa-infra-automation/tofu/aws/modules/airgap/backend.tf"
    def containerBackendPath = "${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/backend.tf"
  
    dir('./qa-infra-automation') {
        dir('./tofu/aws/modules/airgap') {
            // Generate backend.tf content with S3 backend configuration
            def backendTf = """
terraform {
  backend "s3" {
    bucket = "${env.S3_BUCKET_NAME}"
    key    = "${env.S3_KEY_PREFIX}"
    region = "${env.S3_REGION}"
  }
}
"""
            writeFile file: 'backend.tf', text: backendTf
            logInfo("S3 backend.tf configuration written to host")
      
            // Show the content for debugging
            logInfo("Backend.tf content:")
            logInfo(backendTf)
        }
    }
  
    // Now copy both backend configuration files from host to container
    logInfo("Copying backend configuration files from host to container...")
  
    try {
        // Copy backend.tf
        sh """
      docker run --rm \
        -v ${env.VALIDATION_VOLUME}:/root \
        -v ${pwd()}/qa-infra-automation/tofu/aws/modules/airgap:/host_input \
        ${env.IMAGE_NAME} \
        cp /host_input/backend.tf ${containerBackendPath}
    """
    
        logInfo("Backend configuration files copied to container")
    
        // Verify the files were copied to container
        sh """
      docker run --rm \
        -v ${env.VALIDATION_VOLUME}:/root \
        ${env.IMAGE_NAME} \
        test -f ${containerBackendPath} && echo "backend.tf exists in container" || echo "backend.tf does NOT exist in container"
    """
    
        // Show the file content in container
        logInfo("Backend.tf content in container:")
        sh """
      docker run --rm \
        -v ${env.VALIDATION_VOLUME}:/root \
        ${env.IMAGE_NAME} \
        cat ${containerBackendPath}
    """
    
  } catch (Exception e) {
        logError("Failed to copy backend configuration to container: ${e.message}")
        error("Unable to copy backend configuration files to container")
    }
}

def downloadClusterTfvarsFromS3() {
    logInfo('Downloading cluster.tfvars from S3 workspace')

    withCredentials([
    string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
    string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
  ]) {
        // Script will try multiple likely S3 keys/locations and download the first match.
        def downloadScript = """
#!/bin/bash
set -e

VARFILE="${env.TERRAFORM_VARS_FILENAME}"
BUCKET="${env.S3_BUCKET_NAME}"
REGION="${env.S3_REGION}"
WORKSPACE="${env.TF_WORKSPACE}"
SHARED="/root"
MODULE_PATH="${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap"

echo "Attempting to locate \${VARFILE} for workspace '\${WORKSPACE}' in s3://\${BUCKET}/"

candidates=(
  "env:/\${WORKSPACE}/\${VARFILE}"
  "env:/\${WORKSPACE}/config/\${VARFILE}"
  "\${WORKSPACE}/\${VARFILE}"
  "\${WORKSPACE}/config/\${VARFILE}"
  "config/\${VARFILE}"
  "\${VARFILE}"
)

found=0
for key in "\${candidates[@]}"; do
  echo "Checking s3://\${BUCKET}/\${key}"
  if aws s3 ls "s3://\${BUCKET}/\${key}" --region "\${REGION}" >/dev/null 2>&1; then
    echo "Found at s3://\${BUCKET}/\${key}, downloading..."
    aws s3 cp "s3://\${BUCKET}/\${key}" "\${SHARED}/\${VARFILE}" --region "\${REGION}"
    mkdir -p "\${MODULE_PATH}"
    cp "\${SHARED}/\${VARFILE}" "\${MODULE_PATH}/\${VARFILE}"
    echo "Downloaded and copied \${VARFILE} to \${MODULE_PATH}/\${VARFILE}"
    found=1
    break
  fi
done

if [[ "\${found}" -ne 1 ]]; then
  echo "WARNING: Could not locate \${VARFILE} in S3 workspace s3://\${BUCKET}/ (checked \${#candidates[@]} locations)."
  echo "Available files (partial):"
  aws s3 ls "s3://\${BUCKET}/env:/\${WORKSPACE}/" --recursive --region "\${REGION}" 2>/dev/null || aws s3 ls "s3://\${BUCKET}/\${WORKSPACE}/" --recursive --region "\${REGION}" 2>/dev/null || true
  echo "Proceeding without creating fallback var file; destruction scripts will handle missing vars appropriately."
fi
"""

        def timestamp = System.currentTimeMillis()
        def scriptFile = "download-cluster-tfvars-${timestamp}.sh"
        def containerName = "${env.BUILD_CONTAINER_NAME}-download-${timestamp}"

        writeFile file: scriptFile, text: downloadScript

        try {
            sh """
        docker run --rm \\
          -v ${env.VALIDATION_VOLUME}:/root \\
          -v ${pwd()}/${scriptFile}:/tmp/script.sh \\
          --name ${containerName} \\
          -e AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}" \\
          -e AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}" \\
          -e AWS_DEFAULT_REGION="${env.AWS_REGION}" \\
          -e S3_BUCKET_NAME="${env.S3_BUCKET_NAME}" \\
          -e S3_REGION="${env.S3_REGION}" \\
          -e TF_WORKSPACE="${env.TF_WORKSPACE}" \\
          -e TERRAFORM_VARS_FILENAME="${env.TERRAFORM_VARS_FILENAME}" \\
          -e TARGET_WORKSPACE="${env.TARGET_WORKSPACE}" \\
          ${env.IMAGE_NAME} \\
          sh /tmp/script.sh
      """
            logInfo('cluster.tfvars download attempt completed')
    } catch (Exception e) {
            logError("Failed to execute download script: ${e.message}")
            logWarning('Proceeding without cluster.tfvars; downstream scripts will decide next steps')
    } finally {
            sh "rm -f ${scriptFile}"
        }
  }
}

def initializeOpenTofu() {
    // Download cluster.tfvars from S3 workspace before initialization
    downloadClusterTfvarsFromS3()

    logInfo('Initializing OpenTofu with S3 backend')

    def scriptPath = 'tests/validation/pipeline/scripts/airgap/tofu_initialize.sh'
    def scriptContent = readFile(file: scriptPath)
    executeScriptInContainer(scriptContent, [:], true)

    // Run a reconfigure init to accept backend changes and avoid "Backend configuration changed" errors.
    // This performs: tofu -chdir=tofu/aws/modules/airgap init -reconfigure
    logInfo('Running OpenTofu reconfigure init to accept backend changes')
    def reconfigureScript = """#!/bin/bash
set -e
# Switch to module directory inside the container and reconfigure the backend
cd ${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap || { echo "Module path not found: ${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap"; exit 1; }
tofu init -reconfigure
"""
    executeScriptInContainer(reconfigureScript, [:], true)
    logInfo('OpenTofu reconfigure init completed')
}

def manageWorkspace() {
    logInfo("Deleting OpenTofu workspace: ${env.TF_WORKSPACE}")

    def scriptPath = 'tests/validation/pipeline/scripts/airgap/tofu_delete_workspace.sh'
    def scriptContent = readFile(file: scriptPath)
    executeScriptInContainer(scriptContent)
}


def archiveDestructionResults() {
    logInfo('Archiving destruction results')

    try {
        sh '''
            # Try to copy destruction results if container exists
            CONTAINER_ID=$(docker ps -aqf "name=''' + env.BUILD_CONTAINER_NAME + '''")
            if [ -n "$CONTAINER_ID" ]; then
                docker cp $CONTAINER_ID:''' + env.QA_INFRA_WORK_PATH + '''/destruction-summary.json ./
                echo "Destruction results archived successfully"
            else
                echo "No container found to archive results from"
            fi
        '''
    } catch (Exception e) {
        logError("Failed to archive destruction results: ${e.message}")
    }
}

def archiveDestructionFailureArtifacts() {
    logInfo('Archiving destruction failure artifacts')

    try {
        def debugCommands = [
            "cd ${env.QA_INFRA_WORK_PATH}",
            'tofu -chdir=tofu/aws/modules/airgap workspace list > workspace-list.txt 2>&1 || echo "No workspace list available"',
            "tofu -chdir=tofu/aws/modules/airgap state list > remaining-resources.txt 2>&1 || echo 'No state available'",
            "echo 'Destruction failure artifact collection completed'"
        ]

        executeInContainer(debugCommands)

        sh """
            # Try to copy failure artifacts if container exists
            CONTAINER_ID=\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}\$")
            if [ -n \"\$CONTAINER_ID\" ]; then
                docker cp \$CONTAINER_ID:${env.QA_INFRA_WORK_PATH}/workspace-list.txt ./
                docker cp \$CONTAINER_ID:${env.QA_INFRA_WORK_PATH}/remaining-resources.txt ./
            else
                echo \"No container found to archive failure artifacts from\"
            fi
        """

        archiveArtifacts artifacts: 'workspace-list.txt,remaining-resources.txt', allowEmptyArchive: true
    } catch (Exception e) {
        logError("Failed to archive failure artifacts: ${e.message}")
    }
}

def executeInContainer(commands) {
    def commandString = commands.join(' && ')
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-${timestamp}"
    def scriptFile = "destroy-commands-${timestamp}.sh"
    def credentialEnvFile = null

    writeFile file: scriptFile, text: commandString

    // Execute Docker command within withCredentials block to avoid interpolation
    withCredentials([
    string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
    string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
  ]) {
        // Create a temporary environment file with credentials
        credentialEnvFile = createCredentialEnvironmentFile()
    
        // Build the base Docker command
        def dockerCmd = """
          docker run --rm \\
              -v ${env.VALIDATION_VOLUME}:/root \\
              -v ${pwd()}/${scriptFile}:/tmp/script.sh \\
              --name ${containerName} \\
              -t --env-file ${env.ENV_FILE} \\
              -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \\
              -e TF_WORKSPACE=${env.TARGET_WORKSPACE} \\
              ${env.IMAGE_NAME} \\
              sh /tmp/script.sh
      """
    
        // Add credential environment file to Docker command without exposing credentials in logs
        def modifiedDockerCmd = addCredentialEnvFileToDockerCommand(dockerCmd, credentialEnvFile)
    
        sh modifiedDockerCmd
  }

    sh "rm -f ${scriptFile}"
  
    // Cleanup credential environment file
    try {
        if (credentialEnvFile && fileExists(credentialEnvFile)) {
            sh "shred -vfz -n 3 ${credentialEnvFile} 2>/dev/null || rm -f ${credentialEnvFile}"
            logInfo("Credential environment file securely shredded")
        }
  } catch (Exception e) {
        logWarning("Failed to cleanup credential environment file: ${e.message}")
    }
}

def cleanupContainersAndVolumes() {
    // Strict: delegate to library cleanup implementation; fail fast if missing
    def lib = ciAirgap()
    try {
        if (lib) {
            lib.cleanupContainersAndVolumes(this)
            return
        }
    } catch (groovy.lang.MissingMethodException | java.lang.NoSuchMethodError ignored) {
    // fallthrough to unified error below
    } catch (Exception e) {
        error("Library cleanupContainersAndVolumes invocation failed: ${e.message}")
    }
    error('Required library function ci/airgap.groovy::cleanupContainersAndVolumes not available — aborting. Ensure validation/pipeline/ci/airgap.groovy is present and exported.')
}

def archiveBuildArtifacts(artifacts) {
    try {
        archiveArtifacts artifacts: artifacts.join(','), allowEmptyArchive: true
        logInfo("Artifacts archived: ${artifacts.join(', ')}")
    } catch (Exception e) {
        logError("Failed to archive artifacts: ${e.message}")
    }
}

def cleanupS3WorkspaceDirectory() {
    logInfo('Cleaning up S3 workspace directory and terraform state after successful destruction')
  
    try {
        // Validate required S3 variables are available
        def requiredS3Vars = ['S3_BUCKET_NAME', 'S3_REGION', 'S3_KEY_PREFIX', 'TF_WORKSPACE']
        validateRequiredVariables(requiredS3Vars)
    
        logInfo("Preparing to clean up S3 directory: env:/${env.TF_WORKSPACE}")
        logInfo("S3 Bucket: ${env.S3_BUCKET_NAME}")
        logInfo("S3 Region: ${env.S3_REGION}")
        logInfo("S3 Key Prefix (terraform.tfstate): ${env.S3_KEY_PREFIX}")
    
        // Execute S3 cleanup using official AWS CLI Docker image
        withCredentials([
      string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
      string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY')
    ]) {
            sh """
        echo '=== S3 Cleanup Complete ==='
        echo "Target workspace: ${env.TF_WORKSPACE}"
        echo "S3 bucket: ${env.S3_BUCKET_NAME}"
        echo "S3 region: ${env.S3_REGION}"
        echo "Terraform state file: ${env.S3_KEY_PREFIX}"
        
        # Create cleanup script with proper escaping
        cat > s3_cleanup.sh << 'EOF'
        #!/bin/bash
        set -e
        
        # Clean up workspace directory (contains cluster.tfvars and other config files)
        echo "Checking if workspace directory exists..."
        if aws s3 ls "s3://${env.S3_BUCKET_NAME}/env:/${env.TF_WORKSPACE}/" --region "${env.S3_REGION}" 2>/dev/null; then
            echo "Workspace directory found: s3://${env.S3_BUCKET_NAME}/env:/${env.TF_WORKSPACE}/"
            
            # List contents before deletion for logging
            echo "Workspace contents to be deleted:"
            aws s3 ls "s3://${env.S3_BUCKET_NAME}/env:/${env.TF_WORKSPACE}/" --recursive --region "${env.S3_REGION}" || echo "No contents found"
            
            # Delete entire workspace directory
            echo "Deleting workspace directory..."
            aws s3 rm "s3://${env.S3_BUCKET_NAME}/env:/${env.TF_WORKSPACE}/" --recursive --region "${env.S3_REGION}"
            
            # Verify deletion
            echo "Verifying workspace deletion..."
            if aws s3 ls "s3://${env.S3_BUCKET_NAME}/env:/${env.TF_WORKSPACE}/" --region "${env.S3_REGION}" 2>/dev/null; then
                echo "ERROR: Failed to delete workspace directory"
                exit 1
            else
                echo "[OK] Successfully deleted workspace directory"
            fi
        else
            echo "[INFO] Workspace directory does not exist in S3 - nothing to clean up"
        fi
        
        # Clean up terraform state file (stored at S3_KEY_PREFIX)
        echo ""
        echo "Checking if terraform state file exists..."
        if aws s3 ls "s3://${env.S3_BUCKET_NAME}/${env.S3_KEY_PREFIX}" --region "${env.S3_REGION}" 2>/dev/null; then
            echo "Terraform state file found: s3://${env.S3_BUCKET_NAME}/${env.S3_KEY_PREFIX}"
            
            # Delete terraform state file
            echo "Deleting terraform state file..."
            aws s3 rm "s3://${env.S3_BUCKET_NAME}/${env.S3_KEY_PREFIX}" --region "${env.S3_REGION}"
            
            # Verify deletion
            echo "Verifying terraform state deletion..."
            if aws s3 ls "s3://${env.S3_BUCKET_NAME}/${env.S3_KEY_PREFIX}" --region "${env.S3_REGION}" 2>/dev/null; then
                echo "ERROR: Failed to delete terraform state file"
                exit 1
            else
                echo "[OK] Successfully deleted terraform state file"
            fi
        else
            echo "[INFO] Terraform state file does not exist in S3 - nothing to clean up"
        fi
        
        echo "=== S3 Cleanup Complete ==="
        EOF
        
        # Run AWS CLI in Docker container to execute cleanup script
        docker run --rm \\
          -e AWS_ACCESS_KEY_ID="${AWS_ACCESS_KEY_ID}" \\
          -e AWS_SECRET_ACCESS_KEY="${AWS_SECRET_ACCESS_KEY}" \\
          -e AWS_DEFAULT_REGION="${env.S3_REGION}" \\
          -e S3_BUCKET_NAME="${env.S3_BUCKET_NAME}" \\
          -e S3_KEY_PREFIX="${env.S3_KEY_PREFIX}" \\
          -e TF_WORKSPACE="${env.TF_WORKSPACE}" \\
          -v \$(pwd)/s3_cleanup.sh:/tmp/s3_cleanup.sh \\
          amazon/aws-cli:latest \\
          sh /tmp/s3_cleanup.sh
        
        # Cleanup local script
        rm -f s3_cleanup.sh
        
        echo '=== S3 Cleanup Complete ==='
      """
    }
    
        logInfo('S3 cleanup completed successfully')
    
  } catch (Exception e) {
        logError("S3 cleanup failed: ${e.message}")
        logWarning('Manual cleanup may be required for S3 resources')
    // Don't fail the build, just log the warning
    }
}

/**
 * LOGGING FUNCTIONS
 */

def logInfo(msg) {
    echo "${PipelineConfig.LOG_PREFIX_INFO} ${getTimestamp()} ${msg}"
}

def logError(msg) {
    echo "${PipelineConfig.LOG_PREFIX_ERROR} ${getTimestamp()} ${msg}"
}

def logWarning(msg) {
    echo "${PipelineConfig.LOG_PREFIX_WARNING} ${getTimestamp()} ${msg}"
}

def logDebug(msg) {
    if (params.LOG_LEVEL == 'DEBUG' || params.LOG_LEVEL == 'VERBOSE') {
        echo "[DEBUG] ${getTimestamp()} - ${msg}"
    }
}

static def getTimestamp() {
    return new Date().format('yyyy-MM-dd HH:mm:ss')
}

/**
 * Helper functions for robust environment variable assignment
 */

def getS3BucketName() {
    def paramValue = params.S3_BUCKET_NAME
    if (paramValue && paramValue.trim()) {
        return paramValue.trim()
    }
    return 'jenkins-terraform-state-storage'
}

def getS3KeyPrefix() {
    def paramValue = params.S3_KEY_PREFIX
    if (paramValue && paramValue.trim()) {
        return paramValue.trim()
    }
    return 'jenkins-airgap-rke2/terraform.tfstate'
}

def getS3Region() {
    def paramValue = params.S3_REGION
    if (paramValue && paramValue.trim()) {
        return paramValue.trim()
    }
    return 'us-east-2'
}

def getAwsRegion() {
    def paramValue = params.S3_REGION
    if (paramValue && paramValue.trim()) {
        return paramValue.trim()
    }
    return 'us-east-2'
}

def createCredentialEnvironmentFile() {
    // Delegate to CI helper implementation for consistency and single source of truth
    def helpers = ciHelpers()
    if (helpers) {
        return helpers.createCredentialEnvironmentFile(this)
    } else {
        // Fallback: minimal local implementation (keeps previous behavior)
        def timestamp = System.currentTimeMillis()
        def credentialEnvFile = "docker-credentials-${timestamp}.env"
        def envContent = []
        if (env.AWS_ACCESS_KEY_ID) { envContent.add("AWS_ACCESS_KEY_ID=${env.AWS_ACCESS_KEY_ID}") }
        if (env.AWS_SECRET_ACCESS_KEY) { envContent.add("AWS_SECRET_ACCESS_KEY=${env.AWS_SECRET_ACCESS_KEY}") }
        writeFile file: credentialEnvFile, text: envContent.join('\n')
        sh "chmod 600 ${credentialEnvFile}"
        logInfo("Created credential environment file (fallback): ${credentialEnvFile}")
        return credentialEnvFile
    }
}

def addCredentialEnvFileToDockerCommand(dockerCmd, credentialEnvFile) {
    def helpers = ciHelpers()
    if (helpers) {
        return helpers.addCredentialEnvFileToDockerCommand(dockerCmd, credentialEnvFile)
    }
    // Fallback to prior behavior
    def modifiedCmd = dockerCmd
    if (credentialEnvFile) {
        def insertionPoint = modifiedCmd.lastIndexOf('--name')
        if (insertionPoint != -1) {
            def nameEndIndex = modifiedCmd.indexOf(' ', insertionPoint)
            if (nameEndIndex != -1) {
                def nextSpaceIndex = modifiedCmd.indexOf(' ', nameEndIndex + 1)
                if (nextSpaceIndex != -1) {
                    modifiedCmd = modifiedCmd.substring(0, nextSpaceIndex) +
                                 ' \\\n              --env-file ' + credentialEnvFile +
                                 modifiedCmd.substring(nextSpaceIndex)
                }
            }
        }
    }
    return modifiedCmd
}
