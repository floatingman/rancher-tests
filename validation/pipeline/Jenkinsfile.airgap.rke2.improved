#!/usr/bin/env groovy

/**
 * Ansible Airgap Setup Jenkinsfile
 * Based on Jenkinsfile.recurring but adapted for airgap RKE2 infrastructure setup
 * 
 * This pipeline sets up airgap RKE2 infrastructure using Ansible and OpenTofu
 * with enhanced error handling and proper workspace management.
 */

pipeline {
    agent any
    
    // Global pipeline options
    options {
        buildDiscarder(logRotator(numToKeepStr: '10'))
        timeout(time: 3, unit: 'HOURS')
        timestamps()
        ansiColor('xterm')
        skipStagesAfterUnstable()
        retry(1)
    }
    
    // Environment-specific parameters
    parameters {
        string(
            name: 'RKE2_VERSION',
            defaultValue: 'v1.28.8+rke2r1',
            description: 'RKE2 version to deploy (e.g., v1.28.8+rke2r1, v1.29.5+rke2r1, v1.30.2+rke2r1)'
        )
        string(
            name: 'RANCHER_VERSION',
            defaultValue: 'v2.10-head',
            description: 'Rancher version to deploy (e.g., head, v2.10-head, v2.11.0, v2.9-head)'
        )
        string(
            name: 'RANCHER_TEST_REPO_URL',
            defaultValue: 'https://github.com/rancher/tests',
            description: 'URL of rancher/tests repository'
        )
        string(
            name: 'RANCHER_TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of rancher/tests repository'
        )
        string(
            name: 'QA_INFRA_REPO_URL',
            defaultValue: 'https://github.com/rancher/qa-infra-automation',
            description: 'URL of qa-infra-automation repository'
        )
        string(
            name: 'QA_INFRA_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of qa-infra-automation repository'
        )
        string(
            name: 'PRIVATE_REGISTRY_URL',
            defaultValue: '',
            description: 'Private registry URL for airgap deployment'
        )
        string(
            name: 'PRIVATE_REGISTRY_USERNAME',
            defaultValue: '',
            description: 'Private registry username for airgap deployment'
        )
        password(
            name: 'PRIVATE_REGISTRY_PASSWORD',
            defaultValue: '',
            description: 'Private registry password for airgap deployment'
        )
        booleanParam(
            name: 'CLEANUP_RESOURCES',
            defaultValue: true,
            description: 'Clean up AWS resources after deployment'
        )
        booleanParam(
            name: 'PARALLEL_EXECUTION',
            defaultValue: true,
            description: 'Enable parallel execution where possible'
        )
        booleanParam(
            name: 'DESTROY_ON_FAILURE',
            defaultValue: true,
            description: 'Destroy infrastructure when Ansible playbooks fail (automatic cleanup)'
        )
        choice(
            name: 'LOG_LEVEL',
            choices: ['INFO', 'DEBUG', 'VERBOSE'],
            description: 'Pipeline logging level'
        )
      }
    
    // Global environment variables
    environment {
        // Repository configurations
        RANCHER_TEST_REPO_URL = "${params.RANCHER_TEST_REPO_URL ?: 'https://github.com/rancher/tests'}"
        QA_INFRA_REPO = "${params.QA_INFRA_REPO_URL ?: 'https://github.com/rancher/qa-infra-automation'}"
        
        // Private registry configurations
        PRIVATE_REGISTRY_URL = "${params.PRIVATE_REGISTRY_URL ?: ''}"
        PRIVATE_REGISTRY_USERNAME = "${params.PRIVATE_REGISTRY_USERNAME ?: ''}"
        PRIVATE_REGISTRY_PASSWORD = "${params.PRIVATE_REGISTRY_PASSWORD ?: ''}"
        
        // Path configurations
        ROOT_PATH = "/root/go/src/github.com/rancher/tests/"
        QA_INFRA_WORK_PATH = "/root/go/src/github.com/rancher/qa-infra-automation"
        
        // Cleanup configurations
        DESTROY_ON_FAILURE = "${params.DESTROY_ON_FAILURE}"
        
        // Computed values
        JOB_SHORT_NAME = "${getShortJobName()}"
        BUILD_CONTAINER_NAME = "${JOB_SHORT_NAME}${BUILD_NUMBER}-airgap-ansible"
        IMAGE_NAME = "rancher-ansible-airgap-setup-${JOB_SHORT_NAME}${BUILD_NUMBER}"
        VALIDATION_VOLUME = "AnsibleAirgapSharedVolume-${JOB_SHORT_NAME}${BUILD_NUMBER}"
        
        // Configuration files
        ANSIBLE_VARS_FILENAME = "vars.yaml"
        TERRAFORM_VARS_FILENAME = "cluster.tfvars"
        ENV_FILE = ".env"
        
        // Terraform workspace
        TF_WORKSPACE = "jenkins_airgap_ansible_workspace_${BUILD_NUMBER}"
        
        // Timeouts (in minutes)
        TERRAFORM_TIMEOUT = "30"
        ANSIBLE_TIMEOUT = "45"
        VALIDATION_TIMEOUT = "15"
        
        // AWS Infrastructure defaults
        AWS_REGION = "us-west-2"
        AWS_AMI = "ami-0c2d3e23fb3adceb8"
    }
    
    stages {
        stage('Initialize Pipeline') {
            steps {
                script {
                    // Validate parameters and environment
                    validateParameters()
                    
                    // Set up dynamic variables
                    setupDynamicEnvironment()
                    
                    // Clean workspace
                    deleteDir()
                    
                    logInfo("Pipeline initialized successfully")
                    logInfo("Build container: ${env.BUILD_CONTAINER_NAME}")
                    logInfo("Docker image: ${env.IMAGE_NAME}")
                    logInfo("Volume: ${env.VALIDATION_VOLUME}")
                }
            }
            post {
                failure {
                    logError("Failed to initialize pipeline")
                }
            }
        }
        
        stage('Checkout Repositories') {
            parallel {
                stage('Checkout Rancher Tests') {
                    steps {
                        dir('./tests') {
                            logInfo("Cloning rancher tests repository from ${env.RANCHER_TEST_REPO_URL}")
                            checkout([
                                $class: 'GitSCM',
                                branches: [[name: "*/${params.RANCHER_TEST_REPO_BRANCH}"]],
                                extensions: [
                                    [$class: 'CleanCheckout'],
                                    [$class: 'CloneOption', depth: 1, shallow: true]
                                ],
                                userRemoteConfigs: [[
                                    url: env.RANCHER_TEST_REPO_URL,
                                ]]
                            ])
                        }
                    }
                }
                
                stage('Checkout QA Infrastructure') {
                    steps {
                        dir('./qa-infra-automation') {
                            logInfo("Cloning qa-infra-automation repository from ${env.QA_INFRA_REPO}")
                            checkout([
                                $class: 'GitSCM',
                                branches: [[name: "*/${params.QA_INFRA_REPO_BRANCH}"]],
                                extensions: [
                                    [$class: 'CleanCheckout'],
                                    [$class: 'CloneOption', depth: 1, shallow: true]
                                ],
                                userRemoteConfigs: [[
                                    url: env.QA_INFRA_REPO,
                                ]]
                            ])
                        }
                    }
                }
            }
            post {
                failure {
                    logError("Failed to checkout repositories")
                    cleanupContainersAndVolumes()
                }
            }
        }
        
        stage('Configure Environment') {
            steps {
                script {
                    logInfo("Configuring deployment environment")
                    
                    // Configure credentials and environment files
                    withCredentials(getCredentialsList()) {
                        // Generate configuration files
                        generateConfigurationFiles()
                        
                        // Setup SSH keys securely
                        setupSSHKeys()
                        
                        // Build Docker image with proper tagging
                        buildDockerImage()
                        
                        // Create shared volume
                        createSharedVolume()
                    }
                }
            }
            post {
                failure {
                    logError("Environment configuration failed")
                    cleanupContainersAndVolumes()
                }
            }
        }
        
        stage('Setup Infrastructure') {
            steps {
                script {
                    logInfo("Initializing airgap infrastructure deployment with OpenTofu")
                    
                    // Configuration validation
                    def requiredVars = [
                        'QA_INFRA_WORK_PATH',
                        'TF_WORKSPACE', 
                        'TERRAFORM_VARS_FILENAME',
                        'TERRAFORM_TIMEOUT'
                    ]
                    
                    validateRequiredVariables(requiredVars)
                    
                    // Enhanced timeout with reasonable defaults
                    def timeoutMinutes = env.TERRAFORM_TIMEOUT ? 
                        Integer.parseInt(env.TERRAFORM_TIMEOUT) : 30
                    
                    timeout(time: timeoutMinutes, unit: 'MINUTES') {
                        try {
                            // Pre-flight checks
                            validateInfrastructurePrerequisites()
                            
                            // Infrastructure deployment with enhanced error handling
                            deployInfrastructure()
                            
                            // Post-deployment validation
                            validateInfrastructureState()
                            
                            logInfo("Infrastructure provisioned and validated successfully")
                            
                        } catch (org.jenkinsci.plugins.workflow.steps.FlowInterruptedException e) {
                            logError("Infrastructure deployment timed out after ${timeoutMinutes} minutes")
                            handleInfrastructureFailure("TIMEOUT", e)
                            throw e
                        } catch (Exception e) {
                            logError("Infrastructure setup failed: ${e.message}")
                            handleInfrastructureFailure("DEPLOYMENT_FAILED", e)
                            throw e
                        }
                    }
                }
            }
            post {
                failure {
                    script {
                        logError("Infrastructure setup stage failed")
                        archiveInfrastructureFailureArtifacts()
                    }
                }
                always {
                    script {
                        archiveInfrastructureState()
                    }
                }
            }
        }
        
        stage('Setup SSH Keys') {
            steps {
                script {
                    logInfo("Setting up SSH keys for airgap deployment")
                    
                    timeout(time: 10, unit: 'MINUTES') {
                        try {
                            executeScriptInContainer("""
cd ${env.QA_INFRA_WORK_PATH}

echo 'Setting up SSH keys for airgap nodes...'
export ANSIBLE_CONFIG=ansible/rke2/ansible.cfg
export ANSIBLE_PRIVATE_KEY_FILE=/root/.ssh/jenkins-elliptic-validation.pem

# Run SSH key setup playbook
ansible-playbook -i ansible/rke2/airgap/inventory/inventory.yml \\
ansible/rke2/airgap/playbooks/setup/setup-ssh-keys.yml \\
${getAnsibleVerbosity()}

echo 'SSH keys setup completed successfully'
""")
                        } catch (Exception e) {
                            logError("SSH key setup failed: ${e.message}")
                            throw e
                        }
                    }
                }
            }
            post {
                failure {
                    logError("SSH key setup failed")
                    script {
                        destroyInfrastructureOnFailure("SSH Key Setup")
                    }
                }
            }
        }
        
        stage('Deploy RKE2 Cluster') {
            steps {
                script {
                    logInfo("Deploying RKE2 cluster in airgap environment")
                    
                    timeout(time: Integer.parseInt(env.ANSIBLE_TIMEOUT), unit: 'MINUTES') {
                        try {
                            executeScriptInContainer("""
cd ${env.QA_INFRA_WORK_PATH}

echo 'Starting RKE2 airgap deployment...'
export ANSIBLE_CONFIG=ansible/rke2/ansible.cfg
export ANSIBLE_PRIVATE_KEY_FILE=/root/.ssh/jenkins-elliptic-validation.pem

# Ensure inventory file exists and is properly formatted
if [ ! -f ansible/rke2/airgap/inventory/inventory.yml ]; then
    echo 'ERROR: Airgap inventory file not found'
    ls -la ansible/rke2/airgap/inventory/
    exit 1
fi

# Run RKE2 airgap deployment
ansible-playbook -i ansible/rke2/airgap/inventory/inventory.yml \\
ansible/rke2/airgap/playbooks/deploy/rke2-tarball-playbook.yml \\
${getAnsibleVerbosity()}

echo 'RKE2 airgap cluster deployed successfully'
""")
                        } catch (Exception e) {
                            logError("RKE2 deployment failed: ${e.message}")
                            throw e
                        }
                    }
                }
            }
            post {
                failure {
                    logError("RKE2 deployment failed")
                    script {
                        destroyInfrastructureOnFailure("RKE2 Deployment")
                    }
                }
            }
        }
        
        stage('Setup kubectl Access') {
            steps {
                script {
                    logInfo("Setting up kubectl access to RKE2 cluster")
                    
                    timeout(time: 5, unit: 'MINUTES') {
                        try {
                            executeScriptInContainer("""
cd ${env.QA_INFRA_WORK_PATH}

echo 'Setting up kubectl access...'
export ANSIBLE_CONFIG=ansible/rke2/ansible.cfg
export ANSIBLE_PRIVATE_KEY_FILE=/root/.ssh/jenkins-elliptic-validation.pem

# Run kubectl setup playbook
ansible-playbook -i ansible/rke2/airgap/inventory/inventory.yml \\
ansible/rke2/airgap/playbooks/setup/setup-kubectl-access.yml \\
${getAnsibleVerbosity()}

# Verify kubectl access
export KUBECONFIG=ansible/rke2/kubeconfig.yaml
echo 'Verifying cluster access...'
kubectl cluster-info
kubectl get nodes

echo 'kubectl access setup completed successfully'
""")
                        } catch (Exception e) {
                            logWarning("kubectl setup failed (non-critical): ${e.message}")
                            // Don't fail the pipeline for kubectl setup issues
                        }
                    }
                }
            }
            post {
                failure {
                    logWarning("kubectl access setup failed (non-critical)")
                    script {
                        // Don't destroy infrastructure for kubectl setup failures since it's non-critical
                        logWarning("kubectl setup is non-critical - infrastructure will be preserved")
                    }
                }
            }
        }
        
        stage('Deploy Rancher') {
            steps {
                script {
                    logInfo("Deploying Rancher on the airgap RKE2 cluster")
                    
                    timeout(time: Integer.parseInt(env.ANSIBLE_TIMEOUT), unit: 'MINUTES') {
                        try {
                            executeScriptInContainer("""
cd ${env.QA_INFRA_WORK_PATH}

echo 'Starting Rancher airgap deployment...'
export KUBECONFIG=ansible/rke2/kubeconfig.yaml
export ANSIBLE_CONFIG=ansible/rancher/ansible.cfg
export ANSIBLE_PRIVATE_KEY_FILE=/root/.ssh/jenkins-elliptic-validation.pem

# Run Rancher airgap deployment
ansible-playbook -i ansible/rke2/airgap/inventory/inventory.yml \\
ansible/rancher/playbooks/deploy/rancher-airgap-playbook.yml \\
${getAnsibleVerbosity()}

echo 'Rancher deployed successfully on airgap cluster'

# Verify Rancher deployment
export KUBECONFIG=ansible/rke2/kubeconfig.yaml
echo 'Verifying Rancher deployment...'
kubectl get pods -n cattle-system
kubectl get pods -n cattle-fleet-system
""")
                        } catch (Exception e) {
                            logError("Rancher deployment failed: ${e.message}")
                            throw e
                        }
                    }
                }
            }
            post {
                failure {
                    logError("Rancher deployment failed")
                    script {
                        destroyInfrastructureOnFailure("Rancher Deployment")
                    }
                }
            }
        }
        
        stage('Validate Deployment') {
            parallel {
                stage('Kubernetes Validation') {
                    steps {
                        script {
                            logInfo("Validating Kubernetes cluster")
                            
                            timeout(time: Integer.parseInt(env.VALIDATION_TIMEOUT), unit: 'MINUTES') {
                                executeScriptInContainer("""
cd ${env.QA_INFRA_WORK_PATH}
export KUBECONFIG=ansible/rke2/kubeconfig.yaml

echo 'Validating cluster nodes...'
kubectl get nodes -o wide

echo 'Validating system pods...'
kubectl get pods -A --field-selector=status.phase!=Running

echo 'Validating services...'
kubectl get svc -A

echo 'Cluster validation completed successfully'
""")
                            }
                        }
                    }
                }
                
                stage('Rancher Validation') {
                    steps {
                        script {
                            logInfo("Validating Rancher deployment")
                            
                            timeout(time: Integer.parseInt(env.VALIDATION_TIMEOUT), unit: 'MINUTES') {
                                executeScriptInContainer("""
cd ${env.QA_INFRA_WORK_PATH}
export KUBECONFIG=ansible/rke2/kubeconfig.yaml

echo 'Validating Rancher pods...'
kubectl get pods -n cattle-system

echo 'Validating Rancher services...'
kubectl get svc -n cattle-system

echo 'Checking Rancher ingress...'
kubectl get ingress -A

echo 'Rancher validation completed successfully'
""")
                            }
                        }
                    }
                }
            }
            post {
                failure {
                    logError("Deployment validation failed")
                }
                always {
                    archiveValidationResults()
                }
            }
        }
    }
    
    post {
        always {
            script {
                logInfo("Starting post-build cleanup")
                
                // Archive important artifacts
                archiveBuildArtifacts([
                    'kubeconfig.yaml',
                    'terraform.tfstate',
                    'ansible-logs.txt',
                    'deployment-summary.json'
                ])
                
                // Clean up resources
                if (params.CLEANUP_RESOURCES) {
                    cleanupInfrastructure()
                } else {
                    logInfo("Resource cleanup skipped (CLEANUP_RESOURCES=false)")
                    logInfo("Remember to manually clean up AWS resources")
                }
                
                // Always cleanup containers and volumes
                try {
                    node {
                        cleanupContainersAndVolumes()
                    }
                } catch (Exception e) {
                    logError("Node context not available for cleanup: ${e.message}")
                    try {
                        cleanupContainersAndVolumes()
                    } catch (Exception cleanupException) {
                        logError("Cleanup failed: ${cleanupException.message}")
                    }
                }
            }
        }
        
        success {
            script {
                logInfo("Pipeline completed successfully")
                sendSlackNotification([
                    color: 'good',
                    message: "✅ Ansible Airgap setup succeeded for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
        
        failure {
            script {
                logError("Pipeline failed")
                sendSlackNotification([
                    color: 'danger',
                    message: "❌ Ansible Airgap setup failed for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
        
        unstable {
            script {
                logWarning("Pipeline completed with warnings")
                sendSlackNotification([
                    color: 'warning',
                    message: "⚠️ Ansible Airgap setup completed with warnings for ${env.JOB_NAME} #${env.BUILD_NUMBER}"
                ])
            }
        }
    }
}

/**
 * HELPER FUNCTIONS
 * These functions are adapted from both Jenkinsfile.recurring and Jenkinsfile.airgap.rke2.improved
 */

def getShortJobName() {
    def jobName = "${env.JOB_NAME}"
    if (jobName.contains('/')) {
        def lastSlashIndex = jobName.lastIndexOf('/')
        return jobName.substring(lastSlashIndex + 1)
    }
    return jobName
}

def validateParameters() {
    // Validate required parameters
    if (!params.RKE2_VERSION) {
        error("RKE2_VERSION parameter is required")
    }
    if (!params.RANCHER_VERSION) {
        error("RANCHER_VERSION parameter is required")
    }
    if (!params.RANCHER_TEST_REPO_URL) {
        error("RANCHER_TEST_REPO_URL parameter is required")
    }
    if (!params.QA_INFRA_REPO_URL) {
        error("QA_INFRA_REPO_URL parameter is required")
    }
    
    logInfo("Parameters validated successfully")
}

def setupDynamicEnvironment() {
    env.RKE2_VERSION = params.RKE2_VERSION
    env.RANCHER_VERSION = params.RANCHER_VERSION
    
    logInfo("Dynamic environment configured")
    logInfo("RKE2 Version: ${env.RKE2_VERSION}")
    logInfo("Rancher Version: ${env.RANCHER_VERSION}")
}

def getCredentialsList() {
    return [
        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
        string(credentialsId: 'AWS_SSH_PEM_KEY', variable: 'AWS_SSH_PEM_KEY'),        
        string(credentialsId: 'AWS_SSH_KEY_NAME', variable: 'AWS_SSH_KEY_NAME'),
        string(credentialsId: 'SLACK_WEBHOOK', variable: 'SLACK_WEBHOOK')
    ]
}

def generateConfigurationFiles() {
    logInfo("Generating configuration files for infrastructure deployment")
    
    // Validate required environment variables
    validateConfigurationEnvironmentVariables()
    
    // Generate Terraform configuration
    generateTerraformConfiguration()
    
    // Generate Ansible configuration
    generateAnsibleConfiguration()
    
    // Generate environment file for containers
    generateEnvironmentFile()
    
    logInfo("Configuration files generated successfully")
}

def validateConfigurationEnvironmentVariables() {
    logInfo("Validating configuration environment variables")
    
    def requiredVars = [
        'TERRAFORM_CONFIG': 'Terraform configuration content',
        'ANSIBLE_CONFIG': 'Ansible configuration content',
        'RKE2_VERSION': 'RKE2 version for deployment',
        'RANCHER_VERSION': 'Rancher version for deployment'
    ]
    
    def missingVars = []
    requiredVars.each { varName, description ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add("${varName} (${description})")
        }
    }
    
    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables for configuration:\n- ${missingVars.join('\n- ')}"
        logError(errorMsg)
        throw new IllegalArgumentException(errorMsg)
    }
    
    logInfo("All required environment variables validated successfully")
}

def generateTerraformConfiguration() {
    logInfo("Generating Terraform configuration")
    
    if (!env.TERRAFORM_CONFIG) {
        throw new RuntimeException("TERRAFORM_CONFIG environment variable is not set")
    }
    
    def tofuConfig = env.TERRAFORM_CONFIG
    
    // Replace variables in config (similar to Jenkinsfile.recurring pattern)
    tofuConfig = tofuConfig.replace('${AWS_SECRET_ACCESS_KEY}', env.AWS_SECRET_ACCESS_KEY)
    tofuConfig = tofuConfig.replace('${AWS_ACCESS_KEY_ID}', env.AWS_ACCESS_KEY_ID)
    tofuConfig = tofuConfig.replace('${AWS_REGION}', env.AWS_REGION)
    tofuConfig = tofuConfig.replace('${AWS_IAM_PROFILE}', env.AWS_IAM_PROFILE ?: '')
    tofuConfig = tofuConfig.replace('${AWS_VPC}', env.AWS_VPC ?: '')
    tofuConfig = tofuConfig.replace('${AWS_SECURITY_GROUPS}', env.AWS_SECURITY_GROUPS ?: '')
    
    // Write the configuration file
    dir('./qa-infra-automation') {
        dir('./tofu/aws/modules/airgap') {
            writeFile file: env.TERRAFORM_VARS_FILENAME, text: tofuConfig
            logInfo("Terraform configuration written to: ${env.TERRAFORM_VARS_FILENAME}")
        }
    }
}

def generateAnsibleConfiguration() {
    logInfo("Generating Ansible configuration")
    
    if (!env.ANSIBLE_CONFIG) {
        throw new RuntimeException("ANSIBLE_CONFIG environment variable is not set")
    }
    
    def ansibleConfig = env.ANSIBLE_CONFIG
    
    // Replace variables in config
    ansibleConfig = ansibleConfig.replace('${ADMIN_PASSWORD}', env.ADMIN_PASSWORD ?: '')
    
    // Write the Ansible configuration file to the correct location for airgap deployment
    dir('./qa-infra-automation') {
        // Ensure the directory structure exists
        sh "mkdir -p ansible/rke2/airgap/inventory/group_vars"
        
        // Write the group_vars/all.yml file
        writeFile file: 'ansible/rke2/airgap/inventory/group_vars/all.yml', text: ansibleConfig
        logInfo("Ansible configuration written to: ansible/rke2/airgap/inventory/group_vars/all.yml")
        
        // Also create a copy in the original location for backward compatibility
        sh "mkdir -p ansible"
        writeFile file: "ansible/${env.ANSIBLE_VARS_FILENAME}", text: ansibleConfig
        logInfo("Ansible configuration also written to: ansible/${env.ANSIBLE_VARS_FILENAME} (backward compatibility)")
    }
}


def generateEnvironmentFile() {
    logInfo("Generating environment file for container execution")
    
    def envContent = """# Environment variables for infrastructure deployment containers
TF_WORKSPACE=${env.TF_WORKSPACE}
BUILD_NUMBER=${env.BUILD_NUMBER}
JOB_NAME=${env.JOB_NAME}
TERRAFORM_TIMEOUT=${env.TERRAFORM_TIMEOUT}
ANSIBLE_TIMEOUT=${env.ANSIBLE_TIMEOUT}
QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH}
TERRAFORM_VARS_FILENAME=${env.TERRAFORM_VARS_FILENAME}
ANSIBLE_VARS_FILENAME=${env.ANSIBLE_VARS_FILENAME}
RKE2_VERSION=${env.RKE2_VERSION}
RANCHER_VERSION=${env.RANCHER_VERSION}
PRIVATE_REGISTRY_URL=${env.PRIVATE_REGISTRY_URL}
PRIVATE_REGISTRY_USERNAME=${env.PRIVATE_REGISTRY_USERNAME}
"""
    
    writeFile file: env.ENV_FILE, text: envContent
    logInfo("Environment file created: ${env.ENV_FILE}")
}

def setupSSHKeys() {
    if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
        logInfo("Setting up SSH keys")
        
        dir('./tests/.ssh') {
            def decodedKey = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
            writeFile file: env.AWS_SSH_KEY_NAME, text: decodedKey
            sh "chmod 600 ${env.AWS_SSH_KEY_NAME}"
        }
        
        logInfo("SSH keys configured successfully")
    }
}

def buildDockerImage() {
    logInfo("Building Docker image: ${env.IMAGE_NAME}")
    
    dir('./') {
        sh "./tests/validation/configure.sh"
        sh """
            docker build . \
                -f ./tests/validation/Dockerfile.tofu.e2e \
                -t ${env.IMAGE_NAME} \
                --build-arg BUILD_DATE=\$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
                --build-arg VCS_REF=\$(git rev-parse --short HEAD) \
                --label "pipeline.build.number=${env.BUILD_NUMBER}" \
                --label "pipeline.job.name=${env.JOB_NAME}"
        """
    }
    
    logInfo("Docker image built successfully")
}

def createSharedVolume() {
    logInfo("Creating shared volume: ${env.VALIDATION_VOLUME}")
    sh "docker volume create --name ${env.VALIDATION_VOLUME}"
}

def executeInContainer(commands) {
    def commandString = commands.join(' && ')
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-${timestamp}"
    
    // Write the command to a temporary file to avoid shell escaping issues
    def scriptFile = "docker-script-${timestamp}.sh"
    writeFile file: scriptFile, text: commandString
    
    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            -v ${pwd()}/${scriptFile}:/tmp/script.sh \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${env.IMAGE_NAME} \
            sh /tmp/script.sh
    """
    
    // Clean up the temporary script file
    sh "rm -f ${scriptFile}"
}

def executeScriptInContainer(scriptContent, extraEnv = [:]) {
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-script-${timestamp}"
    def scriptFile = "docker-script-${timestamp}.sh"
    
    writeFile file: scriptFile, text: scriptContent
    
    def envVars = ""
    extraEnv.each { key, value ->
        envVars += " -e ${key}=${value}"
    }
    
    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            -v ${pwd()}/${scriptFile}:/tmp/script.sh \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TF_WORKSPACE} \
            ${envVars} \
            ${env.IMAGE_NAME} \
            sh /tmp/script.sh
    """
    
    sh "rm -f ${scriptFile}"
}

def getAnsibleVerbosity() {
    switch (params.LOG_LEVEL) {
        case 'DEBUG':
            return '-vvv'
        case 'VERBOSE':
            return '-vvvv'
        default:
            return '-v'
    }
}

def destroyInfrastructure() {
    logInfo("Destroying infrastructure")
    
    try {
        executeScriptInContainer("""
cd ${env.QA_INFRA_WORK_PATH}
tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE}
export TF_WORKSPACE=${env.TF_WORKSPACE}
tofu -chdir=tofu/aws/modules/airgap destroy -auto-approve -var-file=${env.TERRAFORM_VARS_FILENAME}
echo 'Infrastructure destroyed successfully'
""")
    } catch (Exception e) {
        logError("Infrastructure destruction failed: ${e.message}")
        logError("Manual cleanup may be required for workspace: ${env.TF_WORKSPACE}")
    }
}

def destroyInfrastructureOnFailure(String stageName) {
    if (params.DESTROY_ON_FAILURE.toBoolean()) {
        logWarning("DESTROY_ON_FAILURE enabled - Destroying infrastructure due to ${stageName} failure")
        try {
            destroyInfrastructure()
            logWarning("Infrastructure destroyed due to ${stageName} failure")
        } catch (Exception e) {
            logError("Failed to destroy infrastructure during failure cleanup: ${e.message}")
            logError("Manual cleanup may be required for workspace: ${env.TF_WORKSPACE}")
        }
    } else {
        logWarning("DESTROY_ON_FAILURE disabled - Infrastructure will be preserved for debugging")
        logWarning("Manual cleanup will be required for workspace: ${env.TF_WORKSPACE}")
    }
}

def cleanupInfrastructure() {
    logInfo("Cleaning up infrastructure resources")
    destroyInfrastructure()
}

def cleanupContainersAndVolumes() {
    logInfo("Cleaning up Docker containers and volumes")
    
    try {
        if (env.NODE_NAME) {
            sh """
                # Stop and remove any containers with our naming pattern
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker stop || true
                docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker rm -v || true
                
                # Remove the Docker image
                docker rmi -f ${env.IMAGE_NAME} || true
                
                # Remove the shared volume
                docker volume rm -f ${env.VALIDATION_VOLUME} || true
                
                # Clean up any dangling images and volumes
                docker system prune -f || true
            """
        } else {
            logWarning("No node context available for Docker cleanup")
        }
    } catch (Exception e) {
        logError("Docker cleanup failed: ${e.message}")
    }
}

def archiveBuildArtifacts(artifacts) {
    try {
        archiveArtifacts artifacts: artifacts.join(','), allowEmptyArchive: true
        logInfo("Artifacts archived: ${artifacts.join(', ')}")
    } catch (Exception e) {
        logError("Failed to archive artifacts: ${e.message}")
    }
}

def sendSlackNotification(config) {
    if (env.SLACK_WEBHOOK) {
        try {
            def payload = [
                channel: '#rancher-qa',
                username: 'Jenkins',
                color: config.color,
                title: 'Ansible Airgap Setup Pipeline',
                message: config.message,
                fields: [
                    [title: 'Job', value: env.JOB_NAME, short: true],
                    [title: 'Build', value: env.BUILD_NUMBER, short: true],
                    [title: 'RKE2 Version', value: env.RKE2_VERSION, short: true],
                    [title: 'Rancher Version', value: env.RANCHER_VERSION, short: true]
                ]
            ]
            
            httpRequest(
                httpMode: 'POST',
                url: env.SLACK_WEBHOOK,
                contentType: 'APPLICATION_JSON',
                requestBody: groovy.json.JsonOutput.toJson(payload)
            )
            
            logInfo("Slack notification sent successfully")
        } catch (Exception e) {
            logError("Failed to send Slack notification: ${e.message}")
        }
    }
}

/**
 * INFRASTRUCTURE MANAGEMENT FUNCTIONS
 * These are adapted from Jenkinsfile.airgap.rke2.improved
 */

def validateRequiredVariables(requiredVars) {
    logInfo("Validating required environment variables")
    
    def missingVars = []
    requiredVars.each { varName ->
        def varValue = env."${varName}"
        if (!varValue || varValue.trim().isEmpty()) {
            missingVars.add(varName)
        }
    }
    
    if (!missingVars.isEmpty()) {
        def errorMsg = "Missing required environment variables: ${missingVars.join(', ')}"
        logError(errorMsg)
        throw new IllegalArgumentException(errorMsg)
    }
    
    logInfo("All required variables validated successfully")
}

def validateInfrastructurePrerequisites() {
    logInfo("Validating infrastructure prerequisites")
    
    def prerequisiteScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Checking OpenTofu installation...'
tofu version

echo 'Checking workspace directory...'
test -d ${env.QA_INFRA_WORK_PATH}

echo 'Validating terraform vars file...'
test -f ${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/${env.TERRAFORM_VARS_FILENAME}

echo 'All infrastructure prerequisites validated successfully'
"""
    
    try {
        executeScriptInContainer(prerequisiteScript)
        logInfo("All infrastructure prerequisites validated")
    } catch (Exception e) {
        def errorMsg = "Infrastructure prerequisites validation failed: ${e.message}"
        logError(errorMsg)
        throw new RuntimeException(errorMsg, e)
    }
}

def deployInfrastructure() {
    logInfo("Starting infrastructure deployment process")
    
    // Step 1: Initialize OpenTofu
    initializeOpenTofu()
    
    // Step 2: Manage workspace
    manageWorkspace()
    
    // Step 3: Plan infrastructure changes
    planInfrastructure()
    
    // Step 4: Apply infrastructure
    applyInfrastructure()
    
    logInfo("Infrastructure deployment completed successfully")
}

def initializeOpenTofu() {
    logInfo("Initializing OpenTofu")
    
    def initScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Initializing OpenTofu backend...'
tofu -chdir=tofu/aws/modules/airgap init -input=false -upgrade -reconfigure

echo 'Verifying initialization success...'
tofu -chdir=tofu/aws/modules/airgap providers

echo 'OpenTofu initialization completed successfully'
"""
    
    executeScriptInContainer(initScript)
}

def manageWorkspace() {
    logInfo("Managing OpenTofu workspace: ${env.TF_WORKSPACE}")
    
    def workspaceScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Managing workspace state...'
unset TF_WORKSPACE

echo 'Current workspaces:'
tofu -chdir=tofu/aws/modules/airgap workspace list

echo 'Creating or selecting workspace: ${env.TF_WORKSPACE}'
if ! tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE} 2>/dev/null; then
    echo 'Workspace does not exist, creating new workspace...'
    tofu -chdir=tofu/aws/modules/airgap workspace new ${env.TF_WORKSPACE}
    
    if ! tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE}; then
        echo 'ERROR: Failed to create and select workspace'
        exit 1
    fi
fi

# Verify workspace selection
CURRENT_WORKSPACE=\$(tofu -chdir=tofu/aws/modules/airgap workspace show)
echo "Current workspace: \$CURRENT_WORKSPACE"

# Strip whitespace and handle empty responses
CURRENT_WORKSPACE=\$(echo "\$CURRENT_WORKSPACE" | xargs)

if [ "\$CURRENT_WORKSPACE" = "" ]; then
    echo 'ERROR: Workspace show command returned empty response'
    tofu -chdir=tofu/aws/modules/airgap workspace list
    exit 1
fi

if [ "\$CURRENT_WORKSPACE" != "${env.TF_WORKSPACE}" ]; then
    echo "ERROR: Expected workspace ${env.TF_WORKSPACE}, but got '\$CURRENT_WORKSPACE'"
    echo 'Available workspaces:'
    tofu -chdir=tofu/aws/modules/airgap workspace list
    exit 1
fi

export TF_WORKSPACE=${env.TF_WORKSPACE}
echo "Workspace management completed: \$TF_WORKSPACE"
"""
    
    executeScriptInContainer(workspaceScript)
}

def planInfrastructure() {
    logInfo("Planning infrastructure changes")

    def planScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Generating infrastructure plan for validation...'
tofu -chdir=tofu/aws/modules/airgap plan -input=false -var-file=${env.TERRAFORM_VARS_FILENAME} -out=tfplan

echo 'Checking if plan file was generated in the correct location...'
if [ ! -f tofu/aws/modules/airgap/tfplan ]; then
    echo 'ERROR: Plan file was not generated successfully in module directory'
    echo 'Contents of tofu/aws/modules/airgap/:'
    ls -la tofu/aws/modules/airgap/
    exit 1
fi

echo 'Verifying plan file is not empty...'
PLAN_SIZE=\$(stat -c%s tofu/aws/modules/airgap/tfplan 2>/dev/null || echo 0)
if [ "\$PLAN_SIZE" = "0" ]; then
    echo 'ERROR: Plan file is empty'
    exit 1
fi

echo "Plan file generated successfully (\$PLAN_SIZE bytes) in tofu/aws/modules/airgap/tfplan"

# Copy plan file from module directory to shared volume for persistence
cp tofu/aws/modules/airgap/tfplan /root/tfplan-backup
echo 'Plan file backed up to shared volume'

echo 'Infrastructure plan validation completed'
"""
    
    executeScriptInContainer(planScript)
}

def applyInfrastructure() {
    logInfo("Applying infrastructure configuration")
    
    def applyScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Restoring plan file from shared volume...'
if [ -f /root/tfplan-backup ]; then
    # Restore plan file to the correct module directory
    cp /root/tfplan-backup tofu/aws/modules/airgap/tfplan
    echo 'Plan file restored from shared volume to module directory'
else
    echo 'ERROR: No backup plan file found in shared volume'
    echo 'Generating new plan...'
    tofu -chdir=tofu/aws/modules/airgap plan -input=false -var-file=${env.TERRAFORM_VARS_FILENAME} -out=tfplan
fi

# Check if plan was restored/generated successfully in module directory
if [ ! -f tofu/aws/modules/airgap/tfplan ]; then
    echo 'ERROR: Plan file was not generated successfully in module directory'
    exit 1
fi

# Verify the plan file is not empty
PLAN_SIZE=\$(stat -c%s tofu/aws/modules/airgap/tfplan 2>/dev/null || echo 0)
if [ "\$PLAN_SIZE" = "0" ]; then
    echo 'ERROR: Plan file is empty'
    exit 1
fi

echo 'Plan file restored successfully (\$PLAN_SIZE bytes), applying...'
tofu -chdir=tofu/aws/modules/airgap apply -auto-approve -input=false tfplan

# Clean up the plan file after successful application
rm -f tofu/aws/modules/airgap/tfplan

echo 'Verifying state after apply...'
tofu -chdir=tofu/aws/modules/airgap state list

echo 'Generating outputs for downstream stages...'
tofu -chdir=tofu/aws/modules/airgap output -json > ${env.QA_INFRA_WORK_PATH}/infrastructure-outputs.json

echo 'Verifying inventory file generation...'
if [ -f ansible/rke2/airgap/inventory/inventory.yml ] && [ -s ansible/rke2/airgap/inventory/inventory.yml ]; then
    echo 'SUCCESS: inventory.yml generated by tofu apply exists and has content'
    echo 'Inventory file contents:'
    head -20 ansible/rke2/airgap/inventory/inventory.yml
else
    echo 'ERROR: inventory.yml missing or empty after tofu apply'
    echo 'Contents of ansible/rke2/airgap/inventory/:'
    ls -la ansible/rke2/airgap/inventory/
    exit 1
fi

echo 'Infrastructure provisioned and inventory generated successfully'
"""

    executeScriptInContainer(applyScript)
}

def validateInfrastructureState() {
    logInfo("Validating infrastructure deployment state")
    
    def validationScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Validating infrastructure state...'
STATE_COUNT=\$(tofu -chdir=tofu/aws/modules/airgap state list | wc -l)
echo "Number of resources in state: \$STATE_COUNT"

echo 'Checking critical outputs...'
tofu -chdir=tofu/aws/modules/airgap output -raw vpc_id || echo 'WARNING: vpc_id output missing'
tofu -chdir=tofu/aws/modules/airgap output -raw subnet_ids || echo 'WARNING: subnet_ids output missing'

echo 'Validating inventory files...'
if [ -f ansible/rke2/airgap/inventory/inventory.yml ] && [ -s ansible/rke2/airgap/inventory/inventory.yml ]; then
    echo 'SUCCESS: inventory.yml exists and has content'
else
    echo 'WARNING: inventory.yml missing or empty'
fi

echo 'Infrastructure state validation completed'
"""

    executeScriptInContainer(validationScript)
}

def archiveValidationResults() {
    logInfo("Archiving validation results")
    
    try {
        // Copy artifacts from container
        sh """
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/ansible/rke2/kubeconfig.yaml ./kubeconfig.yaml || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/tofu/aws/modules/airgap/terraform.tfstate ./terraform.tfstate || true
        """
        
        // Generate deployment summary
        def deploymentSummary = [
            buildNumber: env.BUILD_NUMBER,
            rke2Version: env.RKE2_VERSION,
            rancherVersion: env.RANCHER_VERSION,
            timestamp: new Date().format("yyyy-MM-dd'T'HH:mm:ss'Z'"),
            status: currentBuild.currentResult ?: 'SUCCESS'
        ]
        
        writeFile file: 'deployment-summary.json', text: groovy.json.JsonOutput.toJson(deploymentSummary)
        
    } catch (Exception e) {
        logError("Failed to archive validation results: ${e.message}")
    }
}

def handleInfrastructureFailure(failureType, exception) {
    logError("Handling infrastructure failure of type: ${failureType}")
    
    try {
        switch(failureType) {
            case "TIMEOUT":
                logError("Infrastructure deployment timed out")
                archiveInfrastructureState()
                break
            case "DEPLOYMENT_FAILED":
                logError("Infrastructure deployment failed")
                safeDestroyInfrastructure()
                break
            default:
                logError("Unknown failure type: ${failureType}")
                safeDestroyInfrastructure()
        }
        
        archiveFailureDiagnostics(exception)
        
    } catch (Exception cleanupException) {
        logError("Cleanup failed during failure handling: ${cleanupException.message}")
    }
}

def safeDestroyInfrastructure() {
    logInfo("Attempting safe infrastructure destruction")
    
    try {
        def destroyCommands = [
            "cd ${env.QA_INFRA_WORK_PATH}",
            "export TF_WORKSPACE=${env.TF_WORKSPACE}",
            "echo 'Selecting workspace for destruction...'",
            "tofu -chdir=tofu/aws/modules/airgap workspace select ${env.TF_WORKSPACE} || echo 'Workspace selection failed'",
            "echo 'Destroying infrastructure...'",
            "tofu -chdir=tofu/aws/modules/airgap destroy -auto-approve -var-file=${env.TERRAFORM_VARS_FILENAME} || echo 'Destroy completed with warnings'",
            "echo 'Infrastructure destruction completed'"
        ]
        
        timeout(time: 15, unit: 'MINUTES') {
            executeInContainer(destroyCommands)
        }
        
        logInfo("Infrastructure destroyed successfully")
        
    } catch (Exception e) {
        logError("Infrastructure destruction failed: ${e.message}")
        logError("Manual cleanup may be required for workspace: ${env.TF_WORKSPACE}")
    }
}

def archiveInfrastructureState() {
    logInfo("Archiving infrastructure state and outputs")
    
    try {
        def archiveScript = """
cd ${env.QA_INFRA_WORK_PATH}
export TF_WORKSPACE=${env.TF_WORKSPACE}

echo 'Archiving infrastructure state...'
echo 'Current directory contents:'
ls -la

echo 'Checking tfstate file location:'
ls -la tofu/aws/modules/airgap/terraform.tfstate 2>/dev/null || echo 'tfstate not found in module directory'
echo 'Tofu workspace status:'
tofu -chdir=tofu/aws/modules/airgap workspace list

echo 'Copying state files...'
cp tofu/aws/modules/airgap/terraform.tfstate infrastructure-${env.TF_WORKSPACE}.tfstate 2>/dev/null || echo 'No state file to archive'
cp tofu/aws/modules/airgap/tfplan infrastructure-plan.tfplan 2>/dev/null || echo 'No plan file to archive'
tofu -chdir=tofu/aws/modules/airgap show -no-color > infrastructure-state-summary.txt 2>/dev/null || echo 'Could not generate state summary'

echo 'Verifying copied files:'
ls -la infrastructure-${env.TF_WORKSPACE}.tfstate 2>/dev/null || echo 'Archived tfstate not found'
ls -la infrastructure-plan.tfplan 2>/dev/null || echo 'Archived plan not found'

echo 'State archival completed'
"""
        
        executeScriptInContainer(archiveScript)
        
        // Archive files from container
        def containerId = sh(returnStdout: true, script: "docker ps -aqf \"name=${env.BUILD_CONTAINER_NAME}\"").trim()
        if (containerId) {
            sh """
                docker cp ${containerId}:${env.QA_INFRA_WORK_PATH}/infrastructure-${env.TF_WORKSPACE}.tfstate ./ || true
                docker cp ${containerId}:${env.QA_INFRA_WORK_PATH}/infrastructure-outputs.json ./ || true
                docker cp ${containerId}:${env.QA_INFRA_WORK_PATH}/infrastructure-state-summary.txt ./ || true
            """
        } else {
            logWarning("No container found for archival")
        }
        
    } catch (Exception e) {
        logError("Failed to archive infrastructure state: ${e.message}")
    }
}

def archiveInfrastructureFailureArtifacts() {
    logInfo("Archiving infrastructure failure artifacts")
    
    try {
        def debugCommands = [
            "cd ${env.QA_INFRA_WORK_PATH}",
            "export TF_WORKSPACE=${env.TF_WORKSPACE}",
            "tofu -chdir=tofu/aws/modules/airgap workspace list > workspace-list.txt 2>&1",
            "tofu -chdir=tofu/aws/modules/airgap state list > state-resources.txt 2>&1 || echo 'No state available'",
            "tofu -chdir=tofu/aws/modules/airgap providers > providers.txt 2>&1 || echo 'Providers not available'",
            // "aws ec2 describe-instances --query 'Reservations[*].Instances[*].[InstanceId,State.Name,Tags[?Key==\\`Name\\`].Value|[0]]' --output table > aws-instances.txt 2>&1 || echo 'Could not query AWS instances'",
            "echo 'Failure artifact collection completed'"
        ]
        
        executeInContainer(debugCommands)
        
        // Copy debug files from container
        sh """
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/workspace-list.txt ./ || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/state-resources.txt ./ || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/providers.txt ./ || true
            docker cp \\\$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/aws-instances.txt ./ || true
        """
        
    } catch (Exception e) {
        logError("Failed to archive failure artifacts: ${e.message}")
    }
}

def archiveFailureDiagnostics(exception) {
    logInfo("Archiving failure diagnostics")
    
    def diagnostics = [
        timestamp: new Date().format("yyyy-MM-dd'T'HH:mm:ss'Z'"),
        buildNumber: env.BUILD_NUMBER,
        workspace: env.TF_WORKSPACE,
        failureType: exception.class.simpleName,
        errorMessage: exception.message,
        stackTrace: getStackTracePreview(exception.stackTrace, 10)
    ]
    
    try {
        writeFile file: 'infrastructure-failure-diagnostics.json', 
                  text: groovy.json.JsonOutput.prettyPrint(groovy.json.JsonOutput.toJson(diagnostics))
        
        logInfo("Failure diagnostics archived successfully")
    } catch (Exception e) {
        logError("Failed to archive failure diagnostics: ${e.message}")
    }
}

def getStackTracePreview(stackTrace, maxLines) {
    if (!stackTrace) {
        return 'No stack trace available'
    }
    
    def lines = []
    def count = 0
    
    for (element in stackTrace) {
        if (count >= maxLines) {
            break
        }
        lines.add(element.toString())
        count++
    }
    
    return lines.join('\n')
}

/**
 * LOGGING FUNCTIONS
 */

def logInfo(message) {
    echo "ℹ️ [INFO] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logError(message) {
    echo "❌ [ERROR] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logWarning(message) {
    echo "⚠️ [WARNING] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logDebug(message) {
    if (params.LOG_LEVEL == 'DEBUG' || params.LOG_LEVEL == 'VERBOSE') {
        echo "🔍 [DEBUG] ${new Date().format('HH:mm:ss')} - ${message}"
    }
}