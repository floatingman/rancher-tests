#!/usr/bin/env groovy

/**
 * Infrastructure Destruction Jenkinsfile for Airgap RKE2
 *
 * This pipeline is designed to safely destroy infrastructure created by
 * the main airgap RKE2 deployment pipeline. It retrieves Terraform state
 * from S3 backend and performs controlled destruction.
 */

pipeline {
    agent any

    // Global pipeline options
    options {
        buildDiscarder(logRotator(numToKeepStr: '10'))
        timeout(time: 2, unit: 'HOURS')
        timestamps()
        ansiColor('xterm')
        skipStagesAfterUnstable()
    }

    parameters {
        string(
            name: 'RANCHER_TEST_REPO_URL',
            defaultValue: 'https://github.com/rancher/tests',
            description: 'URL of rancher/tests repository'
        )
        string(
            name: 'RANCHER_TEST_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of rancher/tests repository'
        )
        string(
            name: 'QA_INFRA_REPO_URL',
            defaultValue: 'https://github.com/rancher/qa-infra-automation',
            description: 'URL of qa-infra-automation repository'
        )
        string(
            name: 'QA_INFRA_REPO_BRANCH',
            defaultValue: 'main',
            description: 'Branch of qa-infra-automation repository'
        )
        string(
            name: 'S3_BUCKET_NAME',
            defaultValue: 'jenkins-terraform-state-storage',
            description: 'S3 bucket name where Terraform state is stored'
        )
        string(
            name: 'S3_REGION',
            defaultValue: 'us-east-2',
            description: 'AWS region where the S3 bucket is located'
        )
        string(
            name: 'S3_KEY_PREFIX',
            defaultValue: 'jenkins-airgap-rke2',
            description: 'S3 key prefix for the Terraform state files'
        )
        string(
            name: 'TARGET_WORKSPACE',
            defaultValue: '',
            description: 'Terraform workspace to destroy (e.g., jenkins_airgap_ansible_workspace_123)'
        )
        choice(
            name: 'STATE_SOURCE',
            choices: ['S3_BACKEND'],
            description: 'Terraform state source (S3 backend only)'
        )
        booleanParam(
            name: 'FORCE_DESTROY',
            defaultValue: false,
            description: 'Force destruction even if state validation fails'
        )
        booleanParam(
            name: 'DRY_RUN',
            defaultValue: true,
            description: 'Perform dry run (plan only) without actual destruction'
        )
        choice(
            name: 'LOG_LEVEL',
            choices: ['INFO', 'DEBUG', 'VERBOSE'],
            description: 'Pipeline logging level'
        )
    }

    environment {
        // Dynamic state storage configuration from parameters
        TF_STATE_BUCKET = "${params.S3_BUCKET_NAME ?: 'jenkins-terraform-state-storage'}"
        TF_STATE_KEY_PREFIX = "${params.S3_KEY_PREFIX ?: 'jenkins-airgap-rke2'}"
        TF_STATE_REGION = "${params.S3_REGION ?: 'us-east-2'}"

        // Repository configurations
        RANCHER_TEST_REPO_URL = "${params.RANCHER_TEST_REPO_URL ?: 'https://github.com/rancher/tests'}"
        QA_INFRA_REPO = "${params.QA_INFRA_REPO_URL ?: 'https://github.com/rancher/qa-infra-automation'}"
        QA_INFRA_WORK_PATH = '/root/go/src/github.com/rancher/qa-infra-automation'
        ROOT_PATH = '/root/go/src/github.com/rancher/tests/'

        // Computed values
        JOB_SHORT_NAME = "${getShortJobName()}"
        BUILD_CONTAINER_NAME = "${JOB_SHORT_NAME}${BUILD_NUMBER}-destroy"
        IMAGE_NAME = "rancher-destroy-${JOB_SHORT_NAME}${BUILD_NUMBER}"
        VALIDATION_VOLUME = "DestroySharedVolume-${JOB_SHORT_NAME}${BUILD_NUMBER}"

        // Target workspace from parameters
        TARGET_WORKSPACE = "${params.TARGET_WORKSPACE}"

        // Configuration files
        TERRAFORM_VARS_FILENAME = 'cluster.tfvars'
        ENV_FILE = '.env-destroy'

        // AWS defaults
        AWS_REGION = 'us-east-2'
    }

    stages {
        stage('Infrastructure Destruction Operations') {
            steps {
                script {
                    logWarning('⚠️ IMPORTANT: No concurrent state locking available')
                    logWarning('⚠️ Ensure only ONE destruction pipeline runs at a time for the same workspace')
                    logWarning('⚠️ Manual coordination required to prevent state conflicts')
                }

                    // Validate Parameters
                    script {
                        logInfo('Validating destruction parameters')

                        if (!params.TARGET_WORKSPACE || params.TARGET_WORKSPACE.trim().isEmpty()) {
                            error('TARGET_WORKSPACE parameter is required for destruction')
                        }

                        env.TARGET_WORKSPACE = params.TARGET_WORKSPACE

                        logInfo("Target workspace: ${env.TARGET_WORKSPACE}")
                        logInfo('State source: S3 Backend')
                        logInfo("Dry run mode: ${params.DRY_RUN}")
                        logInfo("Force destroy: ${params.FORCE_DESTROY}")
                    }

                    // Prepare Environment
                    script {
                        logInfo('Preparing destruction environment')

                        // Clean workspace
                        deleteDir()

                        // Checkout QA infrastructure repository
                        dir('./qa-infra-automation') {
                            logInfo('Cloning qa-infra-automation repository')
                            checkout([
                                $class: 'GitSCM',
                                branches: [[name: "*/${params.QA_INFRA_REPO_BRANCH}"]],
                                extensions: [
                                    [$class: 'CleanCheckout'],
                                    [$class: 'CloneOption', depth: 1, shallow: true]
                                ],
                                userRemoteConfigs: [[url: env.QA_INFRA_REPO]]
                            ])
                        }

                        // Checkout Tests repository for Dockerfile access
                        dir('./tests') {
                            logInfo('Cloning tests repository for Docker build')
                            checkout([
                                $class: 'GitSCM',
                                branches: [[name: "*/${params.RANCHER_TEST_REPO_BRANCH}"]],
                                extensions: [
                                    [$class: 'CleanCheckout'],
                                    [$class: 'CloneOption', depth: 1, shallow: true]
                                ],
                                userRemoteConfigs: [[url: env.RANCHER_TEST_REPO_URL,]]
                            ])
                        }

                        // Configure credentials and build environment
                        withCredentials(getCredentialsList()) {
                            generateDestructionEnvironmentFile()
                            setupSSHKeys()
                            buildDestructionDockerImage()
                            createSharedVolume()
                        }
                    }

                    // Retrieve Terraform State
                    script {
                        logInfo('Retrieving Terraform state from S3 backend for destruction')

                        def stateRetrieved = retrieveStateFromS3()

                        if (!stateRetrieved && !params.FORCE_DESTROY) {
                            error('Could not retrieve Terraform state from S3 and FORCE_DESTROY is not enabled')
                        } else if (!stateRetrieved && params.FORCE_DESTROY) {
                            logWarning('S3 state retrieval failed but FORCE_DESTROY is enabled - proceeding with caution')
                        }

                        // Validate state if retrieved
                        if (stateRetrieved) {
                            validateStateForDestruction()
                        }
                    }

                    // Plan Destruction
                    script {
                        logInfo('Planning infrastructure destruction')

                        try {
                            planDestruction()

                            // Archive the destruction plan
                            archiveDestructionPlan()

                            if (params.DRY_RUN) {
                                logInfo('DRY_RUN mode enabled - destruction plan completed without execution')
                                currentBuild.result = 'SUCCESS'
                                return
                            }
                        } catch (Exception e) {
                            logError("Destruction planning failed: ${e.message}")
                            throw e
                        }
                    }

                    // Execute Destruction (only if not DRY_RUN)
                    script {
                        if (!params.DRY_RUN) {
                            logInfo('Executing infrastructure destruction')

                            def proceedWithDestruction = true

                            // Final confirmation step
                            if (!params.FORCE_DESTROY) {
                                timeout(time: 5, unit: 'MINUTES') {
                                    try {
                                        proceedWithDestruction = input(
                                            message: "Proceed with destruction of workspace: ${env.TARGET_WORKSPACE}?",
                                            ok: 'Destroy',
                                            parameters: [
                                                booleanParam(
                                                    name: 'CONFIRM_DESTRUCTION',
                                                    defaultValue: false,
                                                    description: 'I understand this will permanently destroy the infrastructure'
                                                )
                                            ]
                                        )
                                    } catch (Exception e) {
                                        logWarning('Destruction cancelled by user or timeout')
                                        currentBuild.result = 'ABORTED'
                                        return
                                    }
                                }
                            }

                            if (proceedWithDestruction || params.FORCE_DESTROY) {
                                executeDestruction()
                                validateDestruction()
                                logInfo('Infrastructure destruction completed successfully')
                                archiveDestructionResults()
                            } else {
                                logInfo('Destruction cancelled by user')
                                currentBuild.result = 'ABORTED'
                            }
                        }
                    }
            }
            post {
                failure {
                    script {
                        logError('Infrastructure destruction operations failed')
                        archiveDestructionFailureArtifacts()
                    }
                }
            }
        }
    }

    post {
        always {
            script {
                logInfo('Starting post-destruction cleanup')

                // Archive important artifacts
                archiveBuildArtifacts([
                    'destruction-plan.txt',
                    'destruction-summary.json',
                    'destruction-logs.txt'
                ])

                // Cleanup containers and volumes
                cleanupContainersAndVolumes()
            }
        }

        success {
            script {
                logInfo('Destruction pipeline completed successfully')
                sendSlackNotification([
                    color: 'good',
                    message: "✅ Infrastructure destruction succeeded for workspace: ${env.TARGET_WORKSPACE}"
                ])
            }
        }

        failure {
            script {
                logError('Destruction pipeline failed')
                sendSlackNotification([
                    color: 'danger',
                    message: "❌ Infrastructure destruction failed for workspace: ${env.TARGET_WORKSPACE}"
                ])
            }
        }

        aborted {
            script {
                logWarning('Destruction pipeline was aborted')
                sendSlackNotification([
                    color: 'warning',
                    message: "⚠️ Infrastructure destruction aborted for workspace: ${env.TARGET_WORKSPACE}"
                ])
            }
        }
    }
}

/**
 * DESTRUCTION-SPECIFIC HELPER FUNCTIONS
 */

def getShortJobName() {
    def jobName = "${env.JOB_NAME}"
    if (jobName.contains('/')) {
        def lastSlashIndex = jobName.lastIndexOf('/')
        return jobName.substring(lastSlashIndex + 1)
    }
    return jobName
}

def getCredentialsList() {
    return [
        string(credentialsId: 'AWS_ACCESS_KEY_ID', variable: 'AWS_ACCESS_KEY_ID'),
        string(credentialsId: 'AWS_SECRET_ACCESS_KEY', variable: 'AWS_SECRET_ACCESS_KEY'),
        string(credentialsId: 'SLACK_WEBHOOK', variable: 'SLACK_WEBHOOK')
    ]
}

def generateDestructionEnvironmentFile() {
    logInfo('Generating environment file for destruction containers')

    // Build environment content securely without direct interpolation of secrets
    def envLines = [
        '# Environment variables for infrastructure destruction containers',
        "TARGET_WORKSPACE=${env.TARGET_WORKSPACE}",
        "BUILD_NUMBER=${env.BUILD_NUMBER}",
        "JOB_NAME=${env.JOB_NAME}",
        "QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH}",
        "TERRAFORM_VARS_FILENAME=${env.TERRAFORM_VARS_FILENAME}",
        "TF_STATE_BUCKET=${env.TF_STATE_BUCKET}",
        "TF_STATE_KEY_PREFIX=${env.TF_STATE_KEY_PREFIX}",
        "TF_STATE_REGION=${env.TF_STATE_REGION}",
        "AWS_REGION=${env.AWS_REGION}",
        '',
        '# AWS Credentials for OpenTofu'
    ]

    // Add credentials securely
    envLines.add('AWS_ACCESS_KEY_ID=' + env.AWS_ACCESS_KEY_ID)
    envLines.add('AWS_SECRET_ACCESS_KEY=' + env.AWS_SECRET_ACCESS_KEY)
    envLines.add('')
    envLines.add('# Terraform Variables for OpenTofu (TF_VAR_ prefix for automatic variable population)')
    envLines.add('TF_VAR_aws_access_key=' + env.AWS_ACCESS_KEY_ID)
    envLines.add('TF_VAR_aws_secret_access_key=' + env.AWS_SECRET_ACCESS_KEY)
    envLines.add('TF_VAR_aws_region=' + env.AWS_REGION)

    def envContent = envLines.join('\n')
    writeFile file: env.ENV_FILE, text: envContent
    logInfo("Environment file created: ${env.ENV_FILE}")
}

def setupSSHKeys() {
    if (env.AWS_SSH_PEM_KEY && env.AWS_SSH_KEY_NAME) {
        logInfo('Setting up SSH keys')

        dir('./tests/.ssh') {
            def decodedKey = new String(env.AWS_SSH_PEM_KEY.decodeBase64())
            writeFile file: env.AWS_SSH_KEY_NAME, text: decodedKey
            sh "chmod 600 ${env.AWS_SSH_KEY_NAME}"
        }

        logInfo('SSH keys configured successfully')
    }
}

def buildDestructionDockerImage() {
    logInfo("Building destruction Docker image: ${env.IMAGE_NAME}")

    dir('./') {
        sh './tests/validation/configure.sh || echo "Configure script not found, continuing..."'
        sh """
            # Use the same Dockerfile as the main pipeline for consistency
            docker build . \
                -f ./tests/validation/Dockerfile.tofu.e2e \
                -t ${env.IMAGE_NAME} \
                --build-arg BUILD_DATE=\$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
                --build-arg VCS_REF=\$(git rev-parse --short HEAD 2>/dev/null || echo 'unknown') \
                --label "pipeline.build.number=${env.BUILD_NUMBER}" \
                --label "pipeline.job.name=${env.JOB_NAME}" \
                --label "pipeline.purpose=destruction"
        """
    }

    logInfo('Destruction Docker image built successfully')
}

def createSharedVolume() {
    logInfo("Creating shared volume: ${env.VALIDATION_VOLUME}")
    sh "docker volume create --name ${env.VALIDATION_VOLUME}"
}

def executeScriptInContainer(scriptContent, extraEnv = [:]) {
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-${timestamp}"
    def scriptFile = "destroy-script-${timestamp}.sh"

    writeFile file: scriptFile, text: scriptContent

    def envVars = ''
    extraEnv.each { key, value ->
        envVars += " -e ${key}=${value}"
    }

    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            -v ${pwd()}/${scriptFile}:/tmp/script.sh \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TARGET_WORKSPACE} \
            ${envVars} \
            ${env.IMAGE_NAME} \
            sh /tmp/script.sh
    """

    sh "rm -f ${scriptFile}"
}

def retrieveStateFromS3() {
    logInfo("Retrieving Terraform state directly from S3 (bypassing workspace selection)")

    try {
        def retrieveScript = '''
cd ''' + env.QA_INFRA_WORK_PATH + '''

echo '🚀 Direct State Retrieval Approach'
echo '================================='
echo 'Target workspace: ''' + env.TARGET_WORKSPACE + ''''
echo 'S3 bucket: ''' + env.TF_STATE_BUCKET + ''''
echo 'Key prefix: ''' + env.TF_STATE_KEY_PREFIX + ''''
echo 'Region: ''' + env.TF_STATE_REGION + ''''
echo

# Step 1: Download state file directly from S3 (try both .tfstate and .json extensions)
LOCAL_STATE_FILE="tofu/aws/modules/airgap/terraform.tfstate"

# Ensure target directory exists
mkdir -p tofu/aws/modules/airgap/

echo "📥 Attempting to download state file from S3..."

# Try .tfstate extension first
STATE_KEY="env:/''' + env.TARGET_WORKSPACE + '''/''' + env.TF_STATE_KEY_PREFIX + '''/terraform.tfstate"
echo "Trying .tfstate extension: s3://''' + env.TF_STATE_BUCKET + '''/$STATE_KEY"
if aws s3 cp "s3://''' + env.TF_STATE_BUCKET + '''/$STATE_KEY" "$LOCAL_STATE_FILE" --region ''' + env.TF_STATE_REGION + ''' --quiet; then
    echo "✅ State file downloaded successfully with .tfstate extension"
else
    echo "❌ .tfstate extension failed, trying .json extension..."
    
    # Try .json extension
    STATE_KEY_JSON="env:/''' + env.TARGET_WORKSPACE + '''/''' + env.TF_STATE_KEY_PREFIX + '''/terraform.json"
    echo "Trying .json extension: s3://''' + env.TF_STATE_BUCKET + '''/$STATE_KEY_JSON"
    if aws s3 cp "s3://''' + env.TF_STATE_BUCKET + '''/$STATE_KEY_JSON" "$LOCAL_STATE_FILE" --region ''' + env.TF_STATE_REGION + ''' --quiet; then
        echo "✅ State file downloaded successfully with .json extension"
    else
        echo "❌ Both .tfstate and .json extensions failed"
        
        # Explore what files actually exist in the workspace directory
        echo "🔍 Exploring files in workspace directory..."
        WORKSPACE_PATH="env:/''' + env.TARGET_WORKSPACE + '''/''' + env.TF_STATE_KEY_PREFIX + '''/"
        echo "Listing contents of s3://''' + env.TF_STATE_BUCKET + '''/$WORKSPACE_PATH"
        
        aws s3 ls "s3://''' + env.TF_STATE_BUCKET + '''/$WORKSPACE_PATH" --region ''' + env.TF_STATE_REGION + ''' || echo "Could not list workspace directory contents"
        
        # Try to find the actual location by exploring the S3 structure
        echo "🔍 Searching for state file in alternative locations..."
    
    # First, try the old format as fallback (try both extensions)
    OLD_STATE_KEY_TFSTATE="''' + env.TF_STATE_KEY_PREFIX + '''/''' + env.TARGET_WORKSPACE + '''/terraform.tfstate"
    OLD_STATE_KEY_JSON="''' + env.TF_STATE_KEY_PREFIX + '''/''' + env.TARGET_WORKSPACE + '''/terraform.json"
    
    echo "Trying old format (.tfstate): s3://''' + env.TF_STATE_BUCKET + '''/$OLD_STATE_KEY_TFSTATE"
    if aws s3 cp "s3://''' + env.TF_STATE_BUCKET + '''/$OLD_STATE_KEY_TFSTATE" "$LOCAL_STATE_FILE" --region ''' + env.TF_STATE_REGION + ''' --quiet; then
        echo "✅ Successfully downloaded using old path format (.tfstate)"
    elif echo "Trying old format (.json): s3://''' + env.TF_STATE_BUCKET + '''/$OLD_STATE_KEY_JSON" && aws s3 cp "s3://''' + env.TF_STATE_BUCKET + '''/$OLD_STATE_KEY_JSON" "$LOCAL_STATE_FILE" --region ''' + env.TF_STATE_REGION + ''' --quiet; then
        echo "✅ Successfully downloaded using old path format (.json)"
    else
        echo "❌ Old format failed for both extensions"
        
        # List available workspaces under env:/ prefix
        echo "🔍 Listing workspaces under env:/ prefix..."
        
        # Parse AWS S3 ls output more carefully
        aws s3 ls "s3://''' + env.TF_STATE_BUCKET + '''/env:/" --region ''' + env.TF_STATE_REGION + ''' > /tmp/s3_listing.txt
        echo "Raw S3 listing:"
        cat /tmp/s3_listing.txt
        
        # Extract workspace names properly (handle "PRE" prefix and whitespace)
        AVAILABLE_WORKSPACES=$(cat /tmp/s3_listing.txt | grep "PRE" | awk "{print \\$NF}" | sed "s|/||g" | sed "s|PRE ||g" | tr -d " " | sort || echo "")
        
        if [ -n "$AVAILABLE_WORKSPACES" ]; then
            echo "Available workspaces found (cleaned):"
            echo "$AVAILABLE_WORKSPACES" | while read -r workspace; do
                echo "  → [$workspace]"
            done
            
            # Check if any contain our target workspace
            MATCHING_WORKSPACE=$(echo "$AVAILABLE_WORKSPACES" | grep "''' + env.TARGET_WORKSPACE + '''" | head -1 || echo "")
            if [ -n "$MATCHING_WORKSPACE" ]; then
                # Clean up any remaining whitespace
                MATCHING_WORKSPACE=$(echo "$MATCHING_WORKSPACE" | tr -d " " | tr -d "\\t")
                echo "Found matching workspace (cleaned): [$MATCHING_WORKSPACE]"
                
                # Try both .tfstate and .json extensions for alternative location
                ALT_STATE_KEY_TFSTATE="env:/$MATCHING_WORKSPACE/''' + env.TF_STATE_KEY_PREFIX + '''/terraform.tfstate"
                ALT_STATE_KEY_JSON="env:/$MATCHING_WORKSPACE/''' + env.TF_STATE_KEY_PREFIX + '''/terraform.json"
                
                echo "Trying alternative state key (.tfstate): s3://''' + env.TF_STATE_BUCKET + '''/$ALT_STATE_KEY_TFSTATE"
                if aws s3 cp "s3://''' + env.TF_STATE_BUCKET + '''/$ALT_STATE_KEY_TFSTATE" "$LOCAL_STATE_FILE" --region ''' + env.TF_STATE_REGION + ''' --quiet; then
                    echo "✅ Successfully downloaded from alternative location (.tfstate)"
                elif echo "Trying alternative state key (.json): s3://''' + env.TF_STATE_BUCKET + '''/$ALT_STATE_KEY_JSON" && aws s3 cp "s3://''' + env.TF_STATE_BUCKET + '''/$ALT_STATE_KEY_JSON" "$LOCAL_STATE_FILE" --region ''' + env.TF_STATE_REGION + ''' --quiet; then
                    echo "✅ Successfully downloaded from alternative location (.json)"
                else
                    echo "❌ Alternative download failed for both extensions"
                    echo "Debug: Tried both:"
                    echo "  - $ALT_STATE_KEY_TFSTATE"
                    echo "  - $ALT_STATE_KEY_JSON"
                    
                    # List actual files in the workspace directory
                    echo "🔍 Listing actual files in workspace directory:"
                    aws s3 ls "s3://''' + env.TF_STATE_BUCKET + '''/env:/$MATCHING_WORKSPACE/''' + env.TF_STATE_KEY_PREFIX + '''/" --region ''' + env.TF_STATE_REGION + ''' || echo "Could not list workspace files"
                    exit 1
                fi
            else
                echo "❌ No matching workspaces found in env:/ prefix"
                
                # Last resort: try without env: prefix in case structure varies
                echo "🔍 Trying direct workspace search..."
                DIRECT_WORKSPACES=$(aws s3 ls "s3://''' + env.TF_STATE_BUCKET + '''/" --region ''' + env.TF_STATE_REGION + ''' | grep "PRE.*''' + env.TARGET_WORKSPACE + '''" | awk "{print $2}" | sed "s|/||g" | head -1 || echo "")
                
                if [ -n "$DIRECT_WORKSPACES" ]; then
                    echo "Found direct workspace match: $DIRECT_WORKSPACES"
                    DIRECT_STATE_KEY="$DIRECT_WORKSPACES/''' + env.TF_STATE_KEY_PREFIX + '''/terraform.tfstate"
                    
                    echo "Trying direct state key: s3://''' + env.TF_STATE_BUCKET + '''/$DIRECT_STATE_KEY"
                    if aws s3 cp "s3://''' + env.TF_STATE_BUCKET + '''/$DIRECT_STATE_KEY" "$LOCAL_STATE_FILE" --region ''' + env.TF_STATE_REGION + ''' --quiet; then
                        echo "✅ Successfully downloaded using direct path"
                    else
                        echo "❌ All attempts failed"
                        exit 1
                    fi
                else
                    echo "❌ No workspaces found at all"
                    exit 1
                fi
            fi
        else
            echo "❌ No workspaces found in S3 bucket under env:/ prefix"
            exit 1
        fi
    fi
fi

# Step 2: Validate and process the downloaded state file
echo
echo "🔍 Validating downloaded state file..."

STATE_SIZE=$(stat -c%s "$LOCAL_STATE_FILE" 2>/dev/null || echo 0)
echo "State file size: $STATE_SIZE bytes"

if [ "$STATE_SIZE" -eq 0 ]; then
    echo "❌ ERROR: Downloaded state file is empty"
    exit 1
elif [ "$STATE_SIZE" -lt 50 ]; then
    echo "⚠️ WARNING: State file is very small - might be corrupted"
    echo "File contents:"
    cat "$LOCAL_STATE_FILE" | head -5
    exit 1
fi

# Check file type and magic bytes
echo "🔍 Analyzing file format..."
FILE_TYPE=$(file "$LOCAL_STATE_FILE" 2>/dev/null || echo "unknown")
echo "File type: $FILE_TYPE"

# Show first few bytes in hex to identify format
echo "First 16 bytes (hex): $(xxd -l 16 -p "$LOCAL_STATE_FILE" 2>/dev/null || echo "unable to read")"
echo "First few readable characters: $(head -c 100 "$LOCAL_STATE_FILE" 2>/dev/null | tr -cd "[:print:][:space:]" | head -c 50)..."

# Check if file is gzip compressed
if echo "$FILE_TYPE" | grep -q "gzip"; then
    echo "🗜️ File is gzip compressed - decompressing..."
    TEMP_FILE="${LOCAL_STATE_FILE}.decompressed"
    
    if gunzip -c "$LOCAL_STATE_FILE" > "$TEMP_FILE" 2>/dev/null; then
        echo "✅ Successfully decompressed file"
        mv "$TEMP_FILE" "$LOCAL_STATE_FILE"
        echo "Decompressed file size: $(stat -c%s "$LOCAL_STATE_FILE") bytes"
    else
        echo "❌ ERROR: Failed to decompress gzip file"
        rm -f "$TEMP_FILE"
        exit 1
    fi
elif echo "$FILE_TYPE" | grep -E -q -i "json|text"; then
    echo "📄 File appears to be text/JSON format"
else
    echo "⚠️ Unknown file format - attempting to process as text"
fi

# Validate JSON structure after potential decompression
echo "🔍 Validating JSON structure..."
if python3.11 -c 'import json, sys; data=json.load(open("'"$LOCAL_STATE_FILE"'", "r")); print("✅ State file is valid JSON"); print("JSON keys:", list(data.keys()) if isinstance(data, dict) else "Not a JSON object")' 2>/dev/null; then
    echo "JSON validation successful"
else
    echo "❌ ERROR: State file is not valid JSON after processing"
    echo "File size after processing: $(stat -c%s "$LOCAL_STATE_FILE") bytes"
    echo "First few lines of processed file:"
    head -5 "$LOCAL_STATE_FILE" 2>/dev/null || echo "Unable to read file"
    echo "Last few lines of processed file:"
    tail -5 "$LOCAL_STATE_FILE" 2>/dev/null || echo "Unable to read file"
    
    # Try to identify the issue
    if grep -q "Access Denied" "$LOCAL_STATE_FILE" 2>/dev/null; then
        echo "🚨 ERROR: AWS Access Denied - check S3 permissions"
    elif grep -q "<Error>" "$LOCAL_STATE_FILE" 2>/dev/null; then
        echo "🚨 ERROR: AWS S3 error response detected"
        echo "S3 Error details:"
        grep -A 3 -B 3 "<Error>" "$LOCAL_STATE_FILE" 2>/dev/null || echo "Unable to extract error details"
    elif [ "$(wc -c < "$LOCAL_STATE_FILE")" -gt 1000000 ]; then
        echo "⚠️ File is very large ($(wc -c < "$LOCAL_STATE_FILE") bytes) - might be corrupted"
    fi
    
    exit 1
fi

# Count resources in the state file
RESOURCE_COUNT=$(python3.11 -c 'import json; data=json.load(open("'"$LOCAL_STATE_FILE"'", "r")); print(len(data.get("resources", [])))' 2>/dev/null || echo 0)

echo "Resources in state: $RESOURCE_COUNT"

if [ "$RESOURCE_COUNT" -eq 0 ]; then
    echo "⚠️ WARNING: No resources found in state file"
    echo "This might mean infrastructure was already destroyed"
    
    # Check if FORCE_DESTROY is enabled
    if [ "''' + (params.FORCE_DESTROY ?: 'false') + '''" != "true" ]; then
        echo "❌ Refusing to proceed with empty state (set FORCE_DESTROY=true to override)"
        exit 1
    else
        echo "⚠️ FORCE_DESTROY=true, proceeding despite empty state"
    fi
else
    echo "✅ Found $RESOURCE_COUNT resources ready for destruction"
fi

# Step 3: Configure local backend (no workspace selection needed)
echo
echo "⚚ Configuring OpenTofu backend for direct state access..."

cat > tofu/aws/modules/airgap/backend.tf << 'EOF'
terraform {
  backend "local" {
    path = "terraform.tfstate"
  }
}
EOF

echo "✅ Using local backend configuration (no workspace selection required)"

# Step 4: Initialize with local backend
echo
echo "🔧 Initializing OpenTofu with local backend..."
if tofu -chdir=tofu/aws/modules/airgap init -input=false -reconfigure; then
    echo "✅ OpenTofu initialized successfully"
else
    echo "❌ ERROR: Failed to initialize OpenTofu"
    exit 1
fi

# Step 5: Verify state is loaded correctly
echo
echo "🔍 Verifying state is loaded correctly..."
LOADED_RESOURCES=$(tofu -chdir=tofu/aws/modules/airgap state list 2>/dev/null | wc -l || echo 0)
echo "Resources loaded in OpenTofu: $LOADED_RESOURCES"

if [ "$LOADED_RESOURCES" -ne "$RESOURCE_COUNT" ]; then
    echo "⚠️ WARNING: Resource count mismatch (state: $RESOURCE_COUNT, loaded: $LOADED_RESOURCES)"
fi

if [ "$LOADED_RESOURCES" -eq 0 ]; then
    echo "❌ ERROR: No resources loaded in OpenTofu state"
    exit 1
fi

echo "✅ State loaded successfully - $LOADED_RESOURCES resources ready for destruction"

# Show some sample resources
echo "Sample resources in state:"
tofu -chdir=tofu/aws/modules/airgap state list | head -5 | while read -r resource; do
    echo "  → $resource"
done

echo
echo "✅ SUCCESS: State retrieval completed using direct approach"
echo "   - Bypassed workspace selection entirely"
echo "   - Downloaded state directly from S3"
echo "   - Configured local backend"
echo "   - Ready for destruction planning"
'''

        executeScriptInContainer(retrieveScript)
        logInfo('✅ State successfully retrieved using direct approach (no workspace selection needed)')
        return true
    } catch (Exception e) {
        logError("❌ Failed to retrieve state from S3: ${e.message}")
        
        // Provide helpful context for troubleshooting
        logError("💡 Troubleshooting suggestions:")
        logError("   1. Verify TARGET_WORKSPACE parameter: ${env.TARGET_WORKSPACE}")
        logError("   2. Check S3 bucket access: ${env.TF_STATE_BUCKET}")
        logError("   3. Confirm key prefix: ${env.TF_STATE_KEY_PREFIX}")
        logError("   4. Run workspace diagnosis script for detailed analysis")
        
        return false
    }
}

def validateStateForDestruction() {
    logInfo('Validating state for destruction')

    try {
        def validationScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Validating Terraform configuration...'
tofu -chdir=tofu/aws/modules/airgap validate

echo 'Checking state resources...'
RESOURCE_COUNT=\$(tofu -chdir=tofu/aws/modules/airgap state list | wc -l)
echo "Resources to be destroyed: \$RESOURCE_COUNT"

if [ "\$RESOURCE_COUNT" -eq 0 ]; then
    echo 'WARNING: No resources found in state'
    exit 1
fi

echo 'Listing resources to be destroyed:'
tofu -chdir=tofu/aws/modules/airgap state list

echo 'State validation completed successfully'
"""

        executeScriptInContainer(validationScript)
        logInfo('State validation completed')
    } catch (Exception e) {
        logWarning("State validation failed: ${e.message}")
        if (!params.FORCE_DESTROY) {
            throw new RuntimeException('State validation failed and FORCE_DESTROY is not enabled', e)
        }
    }
}

def planDestruction() {
    logInfo('Creating destruction plan')

    def planScript = '''
cd ''' + env.QA_INFRA_WORK_PATH + '''

echo 'Generating destruction plan...'

# For destroy operations, we don't need the original tfvars file
# OpenTofu can read the current state and plan destruction without variable files
# We'll create minimal vars only if they're absolutely required by the configuration

echo 'Attempting direct destruction planning without tfvars...'
if tofu -chdir=tofu/aws/modules/airgap plan -destroy -input=false -out=destroy-plan 2>/dev/null; then
    echo '✅ Destruction plan created without tfvars file'
else
    echo 'Direct planning failed, creating minimal tfvars...'
    
    # Create minimal tfvars for destruction planning
    cat > ''' + env.TERRAFORM_VARS_FILENAME + ''' << 'EOFVARS'
# Minimal configuration for destruction
# The actual values don't matter for destroy operations
# OpenTofu will read from the current state
aws_region = "''' + env.AWS_REGION + '''"
aws_access_key = "placeholder"
aws_secret_access_key = "placeholder"
# Add other common variables that might be required
instance_type = "t3.medium"
node_count = 1
EOFVARS

    echo 'Created minimal tfvars file:'
    cat ''' + env.TERRAFORM_VARS_FILENAME + '''
    echo
    
    echo 'Attempting destruction planning with minimal tfvars...'
    if tofu -chdir=tofu/aws/modules/airgap plan -destroy -input=false -var-file=''' + env.TERRAFORM_VARS_FILENAME + ''' -out=destroy-plan; then
        echo '✅ Destruction plan created with minimal tfvars'
    else
        echo '❌ Destruction planning failed even with tfvars'
        echo 'Checking what variables are actually required...'
        
        # Try to get more info about required variables
        tofu -chdir=tofu/aws/modules/airgap plan -destroy -input=false -var-file=''' + env.TERRAFORM_VARS_FILENAME + ''' 2>&1 | grep -i "required" || echo "No variable requirements found"
        
        echo 'Attempting plan without output file to see detailed error...'
        tofu -chdir=tofu/aws/modules/airgap plan -destroy -input=false -var-file=''' + env.TERRAFORM_VARS_FILENAME + ''' || echo "Detailed planning failed"
        
        exit 1
    fi
fi

# Verify plan file was created
if [ ! -f tofu/aws/modules/airgap/destroy-plan ]; then
    echo '❌ ERROR: destroy-plan file was not created'
    echo 'Contents of module directory:'
    ls -la tofu/aws/modules/airgap/
    exit 1
fi

PLAN_SIZE=$(stat -c%s tofu/aws/modules/airgap/destroy-plan 2>/dev/null || echo 0)
echo "Plan file size: $PLAN_SIZE bytes"

echo 'Showing destruction plan summary...'
if tofu -chdir=tofu/aws/modules/airgap show -no-color destroy-plan > destruction-plan-summary.txt; then
    echo 'Destruction plan summary generated successfully'
    
    echo 'Plan summary (first 50 lines):'
    head -50 destruction-plan-summary.txt
    
    echo
    echo 'Resources to be destroyed:'
    grep -c "will be destroyed" destruction-plan-summary.txt || echo "No destroy actions found in plan"
    
else
    echo '❌ ERROR: Failed to show destruction plan'
    exit 1
fi

echo '✅ Destruction plan created and validated successfully'
'''

    executeScriptInContainer(planScript)
}

def archiveDestructionPlan() {
    logInfo('Archiving destruction plan')

    try {
        sh """
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/destruction-plan-summary.txt ./destruction-plan.txt || true
        """

        archiveArtifacts artifacts: 'destruction-plan.txt', allowEmptyArchive: true

        logInfo('Destruction plan archived')
    } catch (Exception e) {
        logError("Failed to archive destruction plan: ${e.message}")
    }
}

def executeDestruction() {
    logInfo('Executing infrastructure destruction')

    def destroyScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Starting infrastructure destruction...'
echo "Target workspace: ${env.TARGET_WORKSPACE}"
echo "Timestamp: \$(date -u +%Y-%m-%dT%H:%M:%SZ)"

# Execute the destruction
tofu -chdir=tofu/aws/modules/airgap apply -auto-approve -input=false destroy-plan

echo 'Verifying destruction completion...'
REMAINING_RESOURCES=\$(tofu -chdir=tofu/aws/modules/airgap state list | wc -l)

if [ "\$REMAINING_RESOURCES" -eq 0 ]; then
    echo 'SUCCESS: All resources have been destroyed'

    # Clean up the workspace
    echo 'Cleaning up Terraform workspace...'
    tofu -chdir=tofu/aws/modules/airgap workspace select default || echo 'Could not switch to default workspace'
    tofu -chdir=tofu/aws/modules/airgap workspace delete ${env.TARGET_WORKSPACE} || echo 'Could not delete workspace'

else
    echo "WARNING: \$REMAINING_RESOURCES resources still remain in state"
    echo 'Remaining resources:'
    tofu -chdir=tofu/aws/modules/airgap state list
    exit 1
fi

echo 'Infrastructure destruction completed successfully'
"""

    executeScriptInContainer(destroyScript)
}

def validateDestruction() {
    logInfo('Validating destruction results')

    try {
        def validationScript = """
cd ${env.QA_INFRA_WORK_PATH}

echo 'Final validation of destruction...'

# Check if any resources remain
RESOURCE_COUNT=\$(tofu -chdir=tofu/aws/modules/airgap state list | wc -l || echo 0)

if [ "\$RESOURCE_COUNT" -eq 0 ]; then
    echo 'SUCCESS: Destruction validation passed - no resources remain'
else
    echo "WARNING: \$RESOURCE_COUNT resources still exist in state"
    tofu -chdir=tofu/aws/modules/airgap state list
fi

# Generate destruction summary
cat > destruction-summary.json << EOF
{
    "workspace": "${env.TARGET_WORKSPACE}",
    "destruction_timestamp": "\$(date -u +%Y-%m-%dT%H:%M:%SZ)",
    "build_number": "${env.BUILD_NUMBER}",
    "job_name": "${env.JOB_NAME}",
    "remaining_resources": \$RESOURCE_COUNT,
    "status": "\$([ \$RESOURCE_COUNT -eq 0 ] && echo 'COMPLETED' || echo 'INCOMPLETE')"
}
EOF

echo 'Destruction validation completed'
"""

        executeScriptInContainer(validationScript)
        logInfo('Destruction validation completed')
    } catch (Exception e) {
        logWarning("Destruction validation failed: ${e.message}")
    }
}

def archiveDestructionResults() {
    logInfo('Archiving destruction results')

    try {
        sh """
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/destruction-summary.json ./ || true
        """

        logInfo('Destruction results archived')
    } catch (Exception e) {
        logError("Failed to archive destruction results: ${e.message}")
    }
}

def archiveDestructionFailureArtifacts() {
    logInfo('Archiving destruction failure artifacts')

    try {
        def debugCommands = [
            "cd ${env.QA_INFRA_WORK_PATH}",
            'tofu -chdir=tofu/aws/modules/airgap workspace list > workspace-list.txt 2>&1 || echo "No workspace list available"',
            "tofu -chdir=tofu/aws/modules/airgap state list > remaining-resources.txt 2>&1 || echo 'No state available'",
            "echo 'Destruction failure artifact collection completed'"
        ]

        executeInContainer(debugCommands)

        sh """
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/workspace-list.txt ./ || true
            docker cp \$(docker ps -aqf "name=${env.BUILD_CONTAINER_NAME}"):${env.QA_INFRA_WORK_PATH}/remaining-resources.txt ./ || true
        """

        archiveArtifacts artifacts: 'workspace-list.txt,remaining-resources.txt', allowEmptyArchive: true
    } catch (Exception e) {
        logError("Failed to archive failure artifacts: ${e.message}")
    }
}

def executeInContainer(commands) {
    def commandString = commands.join(' && ')
    def timestamp = System.currentTimeMillis()
    def containerName = "${env.BUILD_CONTAINER_NAME}-${timestamp}"
    def scriptFile = "destroy-commands-${timestamp}.sh"

    writeFile file: scriptFile, text: commandString

    sh """
        docker run --rm \
            -v ${env.VALIDATION_VOLUME}:/root \
            -v ${pwd()}/${scriptFile}:/tmp/script.sh \
            --name ${containerName} \
            -t --env-file ${env.ENV_FILE} \
            -e QA_INFRA_WORK_PATH=${env.QA_INFRA_WORK_PATH} \
            -e TF_WORKSPACE=${env.TARGET_WORKSPACE} \
            ${env.IMAGE_NAME} \
            sh /tmp/script.sh
    """

    sh "rm -f ${scriptFile}"
}

def cleanupContainersAndVolumes() {
    logInfo('Cleaning up Docker containers and volumes')

    try {
        sh """
            # Stop and remove containers
            docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker stop || true
            docker ps -aq --filter "name=${env.BUILD_CONTAINER_NAME}" | xargs -r docker rm -v || true

            # Remove the Docker image
            docker rmi -f ${env.IMAGE_NAME} || true

            # Remove the shared volume
            docker volume rm -f ${env.VALIDATION_VOLUME} || true

            # Clean up dangling resources
            docker system prune -f || true
        """
    } catch (Exception e) {
        logError("Docker cleanup failed: ${e.message}")
    }
}

def archiveBuildArtifacts(artifacts) {
    try {
        archiveArtifacts artifacts: artifacts.join(','), allowEmptyArchive: true
        logInfo("Artifacts archived: ${artifacts.join(', ')}")
    } catch (Exception e) {
        logError("Failed to archive artifacts: ${e.message}")
    }
}

def sendSlackNotification(config) {
    if (env.SLACK_WEBHOOK) {
        try {
            def payload = [
                channel: '#rancher-qa',
                username: 'Jenkins-Destroyer',
                color: config.color,
                title: 'Infrastructure Destruction Pipeline',
                message: config.message,
                fields: [
                    [title: 'Job', value: env.JOB_NAME, short: true],
                    [title: 'Build', value: env.BUILD_NUMBER, short: true],
                    [title: 'Workspace', value: env.TARGET_WORKSPACE, short: true],
                    [title: 'State Source', value: 'S3 Backend', short: true]
                ]
            ]

            httpRequest(
                httpMode: 'POST',
                url: env.SLACK_WEBHOOK,
                contentType: 'APPLICATION_JSON',
                requestBody: groovy.json.JsonOutput.toJson(payload)
            )

            logInfo('Slack notification sent successfully')
        } catch (Exception e) {
            logError("Failed to send Slack notification: ${e.message}")
        }
    }
}

/**
 * LOGGING FUNCTIONS
 */

def logInfo(message) {
    echo "ℹ️ [INFO] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logError(message) {
    echo "❌ [ERROR] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logWarning(message) {
    echo "⚠️ [WARNING] ${new Date().format('HH:mm:ss')} - ${message}"
}

def logDebug(message) {
    if (params.LOG_LEVEL == 'DEBUG' || params.LOG_LEVEL == 'VERBOSE') {
        echo "🔍 [DEBUG] ${new Date().format('HH:mm:ss')} - ${message}"
    }
}
